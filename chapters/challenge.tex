\chapter{Challenges and Propositions}
In Chapter 2, we examined the definition of research and its implications, and in Chapter 3, we provided an overview of past efforts related to the automation of research. In this chapter, based on these, we will reorganize the challenges towards realizing an autonomous and general artificial intelligence capable of conducting research.



\section{Challenges}

 \subsection{General and Autonomous Question Construction, Hypothesis Generation, and Hypothesis Verification}

 In Chapter 2, we explained that in order to create an AI capable of conducting any research, it is deemed necessary to realize the formulation of questions, generation of hypotheses, and validation of these hypotheses as a combination of universal skills applicable to all research. In this section, we will revisit and organize the potential challenges in achieving an AI that can conduct each of these processes.

 \subsubsection{Common Challenges}
One of the major challenges that can be a common issue for any process, as pointed out in prior research \cite{coley2020autonomousII}, is how to execute these tasks in open-ended situations. For instance, in the automation of experiments, robots use experimental equipment selected, prepared, and set up by humans. However, humans do these tasks from scratch with their own hands. Humans do not use a given corpus of papers; instead, they search for and use them on their own. Candidates for hypotheses are not explicitly provided; humans begin by identifying potential hypotheses. Even when formulating questions that serve a particular goal, humans set that goal themselves. 

In many cases in research automation, these elements are pre-determined by humans. How to let machines autonomously perform these tasks starting only with the same initial information given to humans is crucial in realizing an autonomous artificial researcher. Moreover, having this kind of freedom is essential to achieving a general artificial researcher as well. This is because if we impose constraints on AI to research only within specific research questions or hypothesis spaces defined by humans, it cannot become an AI capable of conducting arbitrary research. Therefore, a significant challenge is how to make AI acquire complex foundational skills and fundamental reasoning abilities to realize these capacities.

\subsubsection{Question Construction}

The first issue discussed in Chapter 2 is the problem of determining the unknown nature of the answer to a question. Given that research is an endeavor to produce new knowledge, it is necessary for the answer to the question to be unknown. Therefore, there is a need to generate such questions or later verify that the answer to the question is indeed unknown.

The second challenge is the issue of how to make a machine generate a ``good'' question. Firstly, what researchers consider as a ``good'' question is not always consistently agreed upon among them. Furthermore, we pointed out that the ``goodness'' of a question is inherently a concept relative to the individual or society. Hence, there seems to be a need to clearly define what constitutes a good question and think about how to effectively integrate these definitions.

The third challenge is that as we demand more autonomy from AI, the automation of question formulation becomes more difficult. Inherently, questions are constructed based on various motivations, such as pure intellectual curiosity or for specific objectives. It is very challenging to automate the construction of questions without defining which of these motivations should be the source. Moreover, as mentioned in Chapter 2, the construction of questions encounters the problem of infinite regression when pursued with strict autonomy. Even if not taken to that extreme, setting higher-order objectives behind questions for AI is an exceptionally difficult task.

It seems that the automation of question formulation has received relatively less attention compared to other processes. Since the formulation of questions is an essential element in conducting research, it would be desirable for more focus to be directed towards the research on automating this process.z

% Realizing AI that construct a ``good'' question in a generic way is challenging. As discussed in Section \ref{section:the-relativity-of-knowledge-production-to-society}, research is relative to society and different criteria can be considered for what makes a ``good'' question. Thus, some human perspective on the ``goodness'' of a question must be incorporated. We need to discuss what we consider good, what we should prioritize, and how to incorporate the value to AI.

% \textcolor{red}{TODO}

% Moreover, determining inputs to the question construction module is not trivial. In hypothesis generation, the question is the primary input, whereas in verification, it's the hypothesis. However, question formation take any input. Once you seriously try to identify the origin of question, you will encounter infinite regress. This is a unique problem that arises when aiming for a general-purpose and autonomous artificial researcher. This is because the issue revolves around how much input can be assumed while still being considered autonomous, given that it can potentially take any input.

% \cite{wang2023skillqg}

% neural question generation \cite{pan2019recent}


\subsubsection{Hypothesis Generation}

One challenge in creating an intelligence capable of hypothesis generation, not just as a tool for humans, is the need to empower the machine itself to form plausible hypotheses for questions to which even the machine doesn't know the answer. Current machine learning models have been criticized for potentially not knowing what they don't know \footnote{
In our discussion with Wataru Kumagai, we were reminded once again of the importance of self-awareness in creating an AI capable of conducting research.
}. 
Moreover, they are known to confidently provide answers or fabricate falsehoods about topics they are ignorant of. Therefore, it seems essential to first accurately recognize what is unknown, either for oneself or the world at large, as told in sections of question construction. Upon facing an unknown subject, there's a need to reduce uncertainty and approach understanding. As mentioned in Chapter 2, humans attempt to understand uncertain subjects by gathering information from papers, experiments, or by reframing questions. While it may not be necessary to adopt the exact same approach, it seems essential to enable machines to autonomously adopt strategies to reduce uncertainties.

% Outputs from machine learning models are essentially inferences tinged with uncertainty. From this perspective, one could posit that these models are already inherently generating hypotheses. Indeed, they are already employed for hypothesis generation in numerous scientific investigations.

% However, while these hypotheses might be hypotheses in the sense that the answers are unknown to humans, they might be self-evident to the machine learning model. When we talk about AI generating hypotheses in the context of AI conducting research, the ultimate expectation is for the AI to provide plausible answers to what is unknown to AI itself. This remains an unresolved issue.

As one of the promising approaches for tacking unknowns, it seems crucial for AI to acquire systematic thinking to realize this, as humans developed systems like language and mathematics, allowing them to infer about subjects beyond their experience. Systematic thinking is not only important for out-of-distribution generalization but is also valued for interpretability, causal inference, logical reasoning, mathematical processing, and planning.

\textcolor{red}{TODO}

\subsubsection{Hypothesis Verification}

In Chapter 2, we highlighted several challenges in realizing an AI capable of verification. First and foremost, the AI itself needs to understand what verification is, and by what criteria a sequence of actions qualifies as verification. Ideally, it would be preferable for the AI to contemplate and understand from scratch what verification is. However, many humans don't do this either, and as discussed in Chapter 2, the philosophical debate on precisely defining verification is still unresolved. Therefore, it's harsh to demand this of a machine. At the very least, the machine needs to thoroughly understand and proficiently use verification concepts that humans employ, such as statistical hypothesis testing, from first principles.


Second, the AI must be able to formulate detailed and complex plans to verify a hypothesis. With the advancements in language models in recent years, we are now much more capable of formulating superior plans than before. However, devising detailed plans remains a challenging issue.

Third, it has to be prepared to carry out these plans and execute the plan with the combination of human-like complex actions.As mentioned in Chapter 2, to achieve this, the AI must be able to search for, create, purchase, and manipulate equipment with almost the same degree of freedom as humans, requiring it to exhibit extremely sophisticated and complex behaviors. This is an immensely challenging issue, and it might even be fair to say it's one of the biggest bottlenecks in realizing an intelligence capable of generic and autonomous research. Laboratory automation have attempted to address this challenge in real world by developing robots. We will discuss the case within the computer below.

For AI to execute research on a computer, it must perform any operation within the computer. For instance, machine learning research entails, setting an environment, preparing datasets and models, and writing and executing codes. To allow AI to prepare these without human intervention, the AI itself must be able to autonomously search the web, select data, download it, and so on. Furthermore, once the AI generates code for verification, it must operate the shell to execute it.

There are ongoing initiatives to enable language models to operate browsers \cite{nakano2021webgpt,act1}. While full browser operations might seem ambitious, there are already endeavors to allow language models to conduct searches \cite{mialon2023augmented}. If we achieve browser automation, it will greatly advance research automation involving web operations. Moreover, efforts like the open interpreter \cite{openinterpreter} aim to automate any computer action. This direction holds promise for automating all research confined within a computer. Although these studies are gaining traction in the machine learning domain, they're not always linked to research automation. We advocate recognizing this as a pivotal challenge in the realm of research automation.

In the field of machine learning, it seems that the discussion on automated validation has not garnered much attention until now. However, recently, the need for verification is recognized in the machine learning community beyond outside of the context of research automation. Studies like \textit{scientific claim verification}, which received much attention during the COVID-20 pandemic \cite{wadden2020fact}, or attempts to minimize hallucination \cite{dhuliawala2023chain} are examples of them. These are not attempts to automate validation in research. Therefore, these findings cannot be directly applied to the automation of research validation. However, we expect that these studies will provide useful insights for the future development of artificial intelligence capable of understanding validation.

% Creating AI that autonomously verifies hypotheses is challenging. While current models can mimic human verification, truly understanding the verification strategy demands more work. Sometimes, they even need to devise the verification measure themselves.

% The biggest challenge for autonomous verification is the need to freely move around in the real world or within a computer, and to manipulate objects within that world at will. We believe this to be one of the greatest barriers to full research automation. Laboratory automation have attempted to address this challenge in real world by developing robots. We will discuss the case within the computer in Section \ref{section:behaviour-inside-the-computer}.

% \subsubsection{AI Capable of Peer Review}

% Given the difficulty of these challenges, automating peer review could be a strategic starting point. This is because peer review is a universal process across diverse research fields and it assesses the validity and quality of problems, hypotheses, and verification methods, which is easier than generating them. Despite some progress, full automation is still elusive \cite{yuan2022can,schulz2022future}.


% \subsection{Behaviour inside the Computer}
% \label{section:behaviour-inside-the-computer}


% Lab Notebook?
% \subsection{Dataset of Research Process}
% It is important to establish the necessary infrastructure for research automation. The two pillars of research automation are the development of basic models that incorporate academic knowledge and the construction of data sets. The development of an infrastructure model that incorporates scientific knowledge has already been proposed in many places and is actually under development, so I will not emphasize its necessity here again. Also, regarding data sets, the construction of data sets for the acquisition of scientific knowledge has been done in various places as well, so I will not emphasize that here either.

% Instead, we propose here to construct a research process dataset. A research process dataset is behavioral log data that incorporates all possible tasks throughout the entire process of the study, from start to finish. Ideally, individual tasks should be labeled as to whether they correspond to question construction, hypothesis generation, or hypothesis testing. We believe that building such a data set is important because, as explained in the Literacy section of Chapter 2, the current paper is not a data log of the entire research process. This makes it difficult to be data-driven and end-to-end learning how to do research itself. I believe that building a research process will help solve these problems and increase the likelihood of more flexible intelligent agents.

% However, building a dataset of the research process seems daunting. This is because researchers who do not currently keep research logs would have to go to the trouble of recording their research process.\footnote{
% In an experimental laboratory in the natural sciences, it is common to take research notes, so it may not be that difficult to record more detailed processes as an extension of this practice. However, in the machine learning field, the culture of taking research notes does not seem to be that common. (We think it is common to keep logs of experiments, but it seems to be rare to describe the details, for example, where and how the data was obtained.) 
% } Therefore, it seems necessary to devise a way to make it easier for researchers to keep logs. It may be to manage the research process on GitHub, or to take research notes as in natural science research, but it is important to discuss how to achieve these things.

% Being able to construct a dataset of the research process would be ideal, but may not be immediately feasible. As an alternative, it seems important to create a dataset designed to automate question construction, hypothesis generation, and hypothesis testing. At its simplest, one might start by building a dataset of papers labeled with the parts that correspond to the question, hypothesis, and test, respectively. This would be a relatively simple but important step in achieving a generic artificial researcher.

% Alternatively, instruction tuning could be done by viewing question construction, hypothesis generation, and hypothesis testing as tasks, respectively. This would produce a language model that can execute question construction, hypothesis generation, and hypothesis testing with greater fidelity. This could be the foundation for a general-purpose, autonomous artificial researcher.



\subsection{Alignment}
As discussed in Section 2, when realizing an AI that autonomously conducts research, the issue of alignment arises. 

First and foremost, it is essential to consider ways to ensure that AI does not engage in research that could harm humans. However, this is a challenging issue. The problem of ensuring that AI does not harm humans is a difficult problem in AI Alignment. Furthermore, knowledge and technology produced by research are fundamentally value-neutral. That is, the knowledge can be used for good or ill. Therefore, even if AI were to research with harmful intentions, it would be challenging to judge from the actual research results.

The remaining two issues arise in the ultra-long term when AI becomes fully autonomous in conducting research. The second issue is that to enable meaningful knowledge production for humans, there needs to be an alignment between the knowledge systems of AI and humans. As mentioned in Chapter 2, if knowledge and verification are relative concepts to society, research conducted autonomously by AI may become meaningless to humans. On the other hand, if we were to correct AI to follow human methods entirely, we might unnecessarily limit the machine's potential capabilities. Deciding how much human methodology and values to incorporate and how much freedom to allow the machine, and finding ways to achieve this, will be a significant challenge in creating research-capable AI.

The third issue concerns the alignment between AI and nature, not between humans and AI. As mentioned in Chapter 2, the fact that humans have come to understand nature is likely not unrelated to our long history of interacting with nature. It seems there's no guarantee that artificial machines like AI, which lack such experiences, would lead to an understanding of nature through their autonomously generated knowledge.

The latter two issues are problems that only arise when demanding extreme autonomy from machines and are not immediately problematic. However, when discussing the limitations and possibilities of knowledge production and natural understanding by agents independent of humans, they seem to become relevant issues.

% In the medium to long term, it's essential to devise ways to ensure that AI doesn't engage in research that could be dangerous to humans. 

% In the long term, we must contemplate how to construct a knowledge system that are mutually translatable between human society and AI society. While these issues may not arise in the short term, it's crucial to engage in discussions now, looking towards the long-term future.

% \subsubsection{Understanding}

% Extensive discourse transpires concerning scientific discoveries. Yet, discussions pertaining to scientific comprehension remain relatively unexplored. Krenn et al. delve into the conundrum of what it entails for a machine learning agent to not only unearth scientific knowledge but also to comprehend it \cite{krenn2022scientific}. They adopt a human-centric stance, positing that an agent's ability to offer explanations comprehensible to human scientists signifies the existence of its scientific understanding.

sun-rise \cite{leslie2023does}

\section{Constructing Research Pipeline Prototypes}
We propose to start by building a research pipeline, connecting the modules of the knowledge production system. The research pipeline is a software system that takes input and generates knowledge as output, encompassing the sequence of processes involved in research. Since this process does not require human intervention, it can be considered as an autonomous research system. We propose this system to be composed of the sub-processes of ``question construction,'' ``hypothesis generation,'' and ``hypothesis verification.'' This creates a general system that is potentially applicable to any research. These sub-processes can be likened to abstract classes in programming. Each process automatically formulates appropriate questions, generates hypotheses, and performs verification based on the input. 

Initially, we will assume a specific research problem, and this research problem can be a simple one. And the inner workings of detailed hypothesis testing and hypothesis generation can be guided (but not hard-coded) to achieve the desired results. Anyway, the high-level concept is to create the minimum necessary to automatically execute each process of question construction, hypothesis generation, and hypothesis testing. Then, by gradually making the contents of each module autonomous and gradually loosening the restrictions on the research problem, we will lead to a general-purpose and autonomous artificial researcher.

\subsubsection{Guided but Not Hard-Coded}

It is important to note, however, that even in the prototype stage, the internal implementation of question construction, hypothesis generation, hypothesis testing, etc., should be ``guided'' and not ``hard-coded'' as much as possible. In machine learning, induction is the process of adding words to the prompt that make it easier to output the expected answer, and hardcoding is the process of actually inserting the desired processing into the algorithm. For example, if a statistical hypothesis test is expected to be used as a means of testing a hypothesis, rather than having a human write a program that contains a process for performing a statistical hypothesis test, we would instead instruct to the machine learning model with prompting, ``Statistical hypothesis testing is one of the leading methods in verification. The hypothesis is A. Verify this.'' This is a very important point to emphasize.

This is a very important point, so let me emphasize it. The reason this is important is that we do not want to automate a particular hypothesis testing process, but rather we want the machine to test the hypothesis itself. Only when you make sure that the machine decides on its own the appropriate verification method according to the hypothesis, will you be able to provide collateral evidence that the machine itself is able to verify the hypothesis. If this can be done not only in hypothesis testing, but also in all aspects of question construction and hypothesis generation, we can call it a prototype of a general-purpose, autonomous artificial researcher.

\subsubsection{Why Pipeline?}

There are two reasons why we think it is a good idea to start by building such a research process pipeline. The first is that this is one simplified representation of a generic and autonomous research system. Research is a very complex task, so when we try to automate validation, we inevitably focus on automating individual tasks. In addition, many research automation efforts are aimed at making things better, which often leads to a strong dependence on the domain, for example, in automating hypothesis generation. However, as emphasized above, what we want to achieve is not specific hypothesis generation or verification, but the ability to generate and verify hypotheses themselves. This system emphasizes that point, and once realized, it will be an example of what a general-purpose, autonomous artificial researcher could look like. The creation of such an example will serve as a guidepost for more people to become versatile and autonomous artificial researchers.

Second, building on this would further clarify the challenges in achieving a general-purpose and autonomous artificial researcher. In this paper, we have discussed the challenges that would be necessary to realize a general-purpose, autonomous artificial researcher. However, we believe that this is a very difficult task and that there are many areas where we do not even know what the problems really are. Therefore, it is important to first identify what the problems are in the first place and where the uncertainties lie. When we move toward such a complex problem, we start with a simple example to understand the structure of the problem. For example, we build toy models in physics, concrete examples in mathematics, and prototypes in programming. The research process pipeline falls under such simple examples in autonomous artificial researchers. In the process of trying to achieve this, we will discover what are the bottlenecks and what are the essentials. In this way, I think it is important to build a research process pipeline in order to first increase the resolution of the problem and clarify the issues.

\subsubsection{Where to Start?}
It is advisable to start by representing a specific research as a pipeline. Initially, creating a concrete system helps clarify the actions involved in actual research and makes the specific challenges to be addressed more tangible. When dealing with projects with high uncertainty, it is crucial to concretize the problems to be solved. Specifically, the goal is to programmatically represent the actions that researchers perform as comprehensively as possible. It is acceptable to consider certain aspects as constants if their execution is too challenging to represent as a program. Then, running the system should reproduce the original research. The next step is to progressively automate the processes and constants provided by humans to enhance autonomy. Naturally, automating a specific research pipeline alone does not guarantee the development of an autonomous pipeline. However, this approach allows for the identification of research automation challenges and paves the way for their resolution through research and development. Importantly, it is essential to express individual tasks as components or sub-processes of question construction, hypothesis generation, or hypothesis verification. This is similar to inheriting an abstract class, ensuring that the automation of these processes is achieved as individual tasks are automated.

In practice, it becomes evident that fully automating an entire research is highly challenging. Therefore, before automating specific research, it may be advantageous to start by creating simplified toy models and aiming to build systems that can execute them automatically. For example, certain parts that require obtaining and using a real dataset can be replaced with appropriately created sample datasets. The approach is similar to that of specific research pipelines, addressing research challenges while aiming to increase autonomy and generality.

\textcolor{red}{Remarks about Autores PJ}

\subsection{Which Field of Research to Start with?}
We suggested that we might start by automating specific research areas and research tasks. So what research areas should we start with? As it turns out, we think it might be a good idea to start by automating machine learning research. There is, of course, a bias due to the fact that the authors of this paper are machine learning researchers and that we are writing this paper primarily for machine learning researchers, but aiming to automate machine learning research makes a lot more sense than that. To illustrate this, let me first introduce some of the perspectives involved in decision making in the area of research to be automated.

\subsubsection{How to Choose Research Area}
The first perspective is how much automation of that research area will help achieve a versatile and autonomous artificial researcher. We believe that it would be a good idea to automate research areas that would accelerate the automation of research. For example, if there is a problem to be solved in order to generate a hypothesis, the problem itself could be set as a research problem and automation of this research could be realized. If we can automate such a task, we have not only achieved our goal of automating the entire research process, but we have also solved the problem of research automation. Such bootstrapping will accelerate the automation of the research process and allow it to reach its goals more efficiently. \footnote{
Inspired by the feedback from Hiroshi Yamakawa
}

The second aspect is feasibility. Since the objective of this project is to create a prototype, it is an important policy to start with the least difficult to realize. There are various levels of difficulty, but the most important is whether the level of difficulty is high, especially in areas other than those essential to the automation of a general-purpose research process. For example, it would be more feasible to generate hypotheses from papers now that language models have been developed than to actually construct and conduct a experiment and generate hypotheses from the observations, in the sense that it would be fully automated. Also, if we were to start with automation using a language model, it would be better not to include tasks that the language model is not good at. As emphasized above, it is better to start where it is as easy as possible here, because focusing on automation of the parts that depend on individual research tasks is not important for the goal of acquiring generalizable knowledge to achieve a general-purpose artificial researcher.

The third aspect is whether the field has an impact on many studies. First of all, an area that has an impact on many studies is one that is used as an elemental technology in those studies. This would be appropriate as a research area to automate for general-purpose artificial researchers, in the sense that it is a general-purpose technology. And if areas that affect many studies can be automated, it will also accelerate the knowledge production of those studies. The efficiency of knowledge production for humanity as a whole will increase, and research automation projects will also benefit from the knowledge produced by them. It would also increase the population of people involved, which may lead more people to pay attention to research automation. This will spawn new flows of people, money, and knowledge, and as a result, projects are expected to move forward more quickly.

\subsubsection{Automating ML Research}
We believe that automating machine learning research may be suitable to start with in terms of these decision axes. First, let's discuss bootstrapping. Many of the challenges to automating research will be how to get machines to acquire from experience what they are currently hardcoding and doing in the real world. Learning from experience is exactly what machine learning does, and in this sense, many of the challenges in realizing autonomous artificial researchers can be formulated as machine learning research challenges.

Next, let us discuss feasibility. In the first place, many machine learning studies are conducted entirely on computers. As mentioned earlier, the greatest difficulty in achieving general automation lies in the interaction with the real world. Technologies related to real-world interaction are used for hypothesis verification rather than the verification itself. This requires advancements in robotics research. Therefore, to pursue the automation of the entire research process, it may be best to set aside fields that require interaction with the real world and initially focus on automating research that can be done solely on PCs. 

Also, many attempts to automate machine learning processes have already been made. For example, in MLOps, various pipelines for automating tasks such as experiment management and training in machine learning have been proposed and put into practical use. AutoML, which is a field of machine learning research, has also produced numerous innovations in automating many of the tasks involved in machine learning. Moreover, the culture of machine learning and related engineering fields already has a wealth of knowledge and insights regarding automation. This means that we do not have to devote many resources to automating research domain-specific tasks. This allows us to focus on more essential questions in our quest to become general-purpose artificial researchers, such as ``How do we allow people to test hypotheses?'' Furthermore, many studies in machine learning and related research areas are open-source. Consequently, it is considered easier to retrieve information from papers compared to other fields. 

Finally, we would like to discuss the impact on other sectors. As you are already aware, many research fields are currently using machine learning technologies. The AI for Science initiative, which aims to automate the scientific field, also uses machine learning technology. Therefore, the automation of machine learning research and better knowledge production will accelerate all of these efforts. For these reasons, we believe it is a good approach to start by automating a specific research project in the machine learning domain.

\subsubsection{What Type of Research in Machine Learning Should We Start with and How?}
There are many different types of machine learning research, but where should we start with automation? Even though we aim to automate the construction of questions, what types of research should we guide them to do?

It seems that a example of the research appropriate as one a starting point is that on the zero-shot prompt proposal. First, the hypothesis (or proposal) in this study is the specific text of the prompt. This is much less expensive to implement, whereas many empirical machine learning proposals require composing an algorithm or architecture. Validation requires the automation of the task of preparing existing data and models, and this is certainly a difficult task. However, this is an extremely common task in machine learning research and is not unique to this research project. The ability to automate this task would benefit a significant amount of machine learning research. The validation criterion is also generic, as it is a typical validation criterion that compares the proposed group with the control group. We think we will first build a prototype by adjusting the LLM prompts, and the fact that there is no strict mathematical or logical manipulation, which language models are not good at, is another aspect that makes this research easy to do.

With this in mind, one research project in which the author of this paper is participating is in the process of building a prototype of the pipeline of research for the prompt proposal \footnote{
Link to the pipeline: \href{https://github.com/t46/mock-pipeline}{https://github.com/t46/mock-pipeline}
}. It is currently still in the pilot stage and some parts are hard-coded, but will be updated as needed.

What we have described here is just one example and a suggestion. We hope that more similar initiatives will emerge in other studies.

\subsection{Automating Peer-Review}
From a slightly different perspective than building a research pipeline, as mentioned above, automation of peer review may also be a suitable first step toward a versatile and autonomous artificial researcher. First, peer review requires judgments about novelty and validity of validation, which are necessary elements for research automation. Thus, the more automated peer review can be, the clearer the need for automation of the entire research process becomes. Second, peer review is identification, not generation, of these elements. Since identification is generally easier than generation, it seems like a good first step in terms of starting small. Third, peer review is a discipline-agnostic practice. Therefore, automating it is expected to be important in gaining insights to realize a general-purpose artificial researcher. Fourth, there is more prior research in automating peer review than in automating generic hypothesis testing or hypothesis generation. Therefore, it is an area where the hurdles for starting a new research project are relatively low. Fifth, peer review is almost always completed by text manipulation. With the development of language models, the cost of doing this has come down considerably. Finally, peer review requires a judgment of value (non-epistemic value). As mentioned above, alignment is one of the biggest barriers to ultimately achieving autonomous artificial researchers. To solve this problem in the long term, it is important to first understand how humans make value judgments in research and to collect data on value judgments. And peer review is a rare example where such non-epistemic values are explicitly expressed. Therefore, it seems to me that automating peer review is one way to start thinking about alignment solutions in earnest. For these reasons, I think it is effective to start with the automation of peer review.

One major barrier to automating peer review is the perceived lack of sufficient data for peer review. First, in many research fields, peer review is done in a closed manner and there is no access to peer review data. This makes it difficult to automate peer review in a data-driven way in those fields. However, at least in the field of machine learning, there are many peer-reviewed comments that are open to the public, so this is not so much of a problem in the machine learning field.

Second, the quality of peer review comments varies. Especially in the machine learning field, the number of reviewers is insufficient for the number of conference submissions. As a result, reviewers sometimes have to review papers in fields in which they do not specialize. This undermines our credibility as the gold standard for peer review comments and evaluations. But even if there were no such circumstances, peer review would still vary from person to person in the first place. This is because there is no clear-cut correct answer to the non-epistemic value judgment of what constitutes ``importance'' and the epistemic value judgment of what constitutes ``validity'' of verification. Currently, each researcher merely makes subjective decisions according to his or her own axis of judgment. In fact, it is known that machine learning research has shown that peer review results vary.
\textcolor{red}{(citation needed)}

However, this second point is a difficulty that occurs inherently in the process of peer review, and it is a difficulty that must be resolved in order to realize automation of research. Rather, the main issue is how to make machines acquire the value judgments that are currently tacit knowledge. Therefore, it would be useful to first analyze and discuss these value judgments, at least among humans, and then proceed to form some kind of consensus.
\textcolor{red}{TODO:(move to challenge)}