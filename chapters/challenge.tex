\chapter{Challenges}

\section{Section}

\subsection{General Question Construction, Hypothesis Generation, and Hypothesis Verification}

\subsubsection{Question Construction}

Realizing AI that construct a ``good'' question in a generic way is challenging. As discussed in Section \ref{section:the-relativity-of-knowledge-production-to-society}, research is relative to society and different criteria can be considered for what makes a ``good'' question. Thus, some human perspective on the ``goodness'' of a question must be incorporated. We need to discuss what we consider good, what we should prioritize, and how to incorporate the value to AI.

Moreover, determining inputs to the question construction module is not trivial. In hypothesis generation, the question is the primary input, whereas in verification, it's the hypothesis. However, question formation take any input. Once you seriously try to identify the origin of question, you will encounter infinite regress. This is a unique problem that arises when aiming for a general-purpose and autonomous artificial researcher. This is because the issue revolves around how much input can be assumed while still being considered autonomous, given that it can potentially take any input.


\subsubsection{Hypothesis Generation}

Outputs from machine learning models are essentially inferences tinged with uncertainty. From this perspective, one could posit that these models are already inherently generating hypotheses. Indeed, they are already employed for hypothesis generation in numerous scientific investigations.

However, while these hypotheses might be hypotheses in the sense that the answers are unknown to humans, they might be self-evident to the machine learning model. When we talk about AI generating hypotheses in the context of AI conducting research, the ultimate expectation is for the AI to provide plausible answers to what is unknown to AI itself. This remains an unresolved issue.

It seems crucial for AI to acquire systematic thinking to realize this, as humans developed systems like language and mathematics, allowing them to infer about subjects beyond their experience. Systematic thinking is not only important for out-of-distribution generalization but is also valued for interpretability, causal inference, logical reasoning, mathematical processing, and planning.


\subsubsection{Hypothesis Verification}

Creating AI that autonomously verifies hypotheses is challenging. While current models can mimic human verification, truly understanding the verification strategy demands more work. Sometimes, they even need to devise the verification measure themselves.

Although research on autonomous hypothesis verification is limited, the need for verification is recognized beyond outside of the context of research automation, such as in fact-checking. Studies like \textit{scientific claim verification}, which received much attention during the COVID-20 pandemic \cite{wadden2020fact}, or the chain-of-verification approach to minimize hallucination \cite{dhuliawala2023chain} may offer insights for enhancing automated verification.

The biggest challenge for autonomous verification is the need to freely move around in the real world or within a computer, and to manipulate objects within that world at will. We believe this to be one of the greatest barriers to full research automation. Laboratory automation have attempted to address this challenge in real world by developing robots. We will discuss the case within the computer in Section \ref{section:behaviour-inside-the-computer}.

\subsubsection{AI Capable of Peer Review}

Given the difficulty of these challenges, automating peer review could be a strategic starting point. This is because peer review is a universal process across diverse research fields and it assesses the validity and quality of problems, hypotheses, and verification methods, which is easier than generating them. Despite some progress, full automation is still elusive \cite{yuan2022can,schulz2022future}.


\subsection{Behaviour inside the Computer}
\label{section:behaviour-inside-the-computer}
For AI to execute research on a computer, it must perform any operation within the computer. For instance, machine learning research entails, setting an environment, preparing datasets and models, and writing and executing codes. To allow AI to prepare these without human intervention, the AI itself must be able to autonomously search the web, select data, download it, and so on. Furthermore, once the AI generates code for verification, it must operate the shell to execute it.

There are ongoing initiatives to enable language models to operate browsers \cite{nakano2021webgpt,act1}. While full browser operations might seem ambitious, there are already endeavors to allow language models to conduct searches \cite{mialon2023augmented}. If we achieve browser automation, it will greatly advance research automation involving web operations. Moreover, efforts like the open interpreter \cite{openinterpreter} aim to automate any computer action. This direction holds promise for automating all research confined within a computer. Although these studies are gaining traction in the machine learning domain, they're not always linked to research automation. We advocate recognizing this as a pivotal challenge in the realm of research automation.

\subsection{Dataset of Research Process}
It is important to establish the necessary infrastructure for research automation. The two pillars of research automation are the development of basic models that incorporate academic knowledge and the construction of data sets. The development of an infrastructure model that incorporates scientific knowledge has already been proposed in many places and is actually under development, so I will not emphasize its necessity here again. Also, regarding data sets, the construction of data sets for the acquisition of scientific knowledge has been done in various places as well, so I will not emphasize that here either.

Instead, we propose here to construct a research process dataset. A research process dataset is behavioral log data that incorporates all possible tasks throughout the entire process of the study, from start to finish. Ideally, individual tasks should be labeled as to whether they correspond to question construction, hypothesis generation, or hypothesis testing. We believe that building such a data set is important because, as explained in the Literacy section of Chapter 2, the current paper is not a data log of the entire research process. This makes it difficult to be data-driven and end-to-end learning how to do research itself. I believe that building a research process will help solve these problems and increase the likelihood of more flexible intelligent agents.

However, building a dataset of the research process seems daunting. This is because researchers who do not currently keep research logs would have to go to the trouble of recording their research process.\footnote{
In an experimental laboratory in the natural sciences, it is common to take research notes, so it may not be that difficult to record more detailed processes as an extension of this practice. However, in the machine learning field, the culture of taking research notes does not seem to be that common. (We think it is common to keep logs of experiments, but it seems to be rare to describe the details, for example, where and how the data was obtained.) 
} Therefore, it seems necessary to devise a way to make it easier for researchers to keep logs. It may be to manage the research process on GitHub, or to take research notes as in natural science research, but it is important to discuss how to achieve these things.

Being able to construct a dataset of the research process would be ideal, but may not be immediately feasible. As an alternative, it seems important to create a dataset designed to automate question construction, hypothesis generation, and hypothesis testing. At its simplest, one might start by building a dataset of papers labeled with the parts that correspond to the question, hypothesis, and test, respectively. This would be a relatively simple but important step in achieving a generic artificial researcher.

Alternatively, instruction tuning could be done by viewing question construction, hypothesis generation, and hypothesis testing as tasks, respectively. This would produce a language model that can execute question construction, hypothesis generation, and hypothesis testing with greater fidelity. This could be the foundation for a general-purpose, autonomous artificial researcher.



\subsection{Alignment}
As discussed in Section \ref{section:the-relativity-of-knowledge-production-to-society}, when realizing an AI that autonomously conducts research, the issue of alignment arises. In the medium to long term, it's essential to devise ways to ensure that AI doesn't engage in research that could be dangerous to humans. In the long term, we must contemplate how to construct a knowledge system that are mutually translatable between human society and AI society. While these issues may not arise in the short term, it's crucial to engage in discussions now, looking towards the long-term future.
