\chapter{Landscape of Research Fields for Research Automation}
\label{chapter-literature-review}

% 本章では、研究の自動化を目指す試みを幅広く紹介します。特に、これまで同じ論文上やコミュニティ間で論じられることがなかった研究たちも含めて、「研究の自動化を目指す研究群」として統一的に紹介しようと思います。一つ一つの論文を丁寧に紹介することは現実的ではないため、あくまで本論文では各分野や研究の取り組み全体をごく簡単に紹介することに注力します。各分野での研究成果についての詳細な説明については、すでにいくつもの素晴らしいレビュー論文が出版されていますので、そちらをご参照ください。ただし、近年の言語モデルを用いた取り組みについては個別の事例も扱いながら紹介しようと思います。

% 各分野を紹介した後で、汎用的で自律的な人工研究者という観点から、それらを分類する二つの軸を提案します。一つ目が汎用性の軸で、これは各研究の自動化の取り組みが、どれぐらい広い研究領域に対して汎用的なタスクを自動化するものであるかというものです。例えば、科学研究全てで必要となるようなタスクの自動化はある特定の研究課題を自動化するようなものよりも汎用的であると言えます。二つ目が研究過程のどの部分を自動化しているか、という軸です、これは自律性の軸に対応します。例えば、ある研究は仮説生成全体を自動化しているかもしれませんし、別の研究は仮説検証の特定の過程のみを自動化しているかもしれません。全ての研究過程の作業が自動化されている場合、これは自律性が高いと言えます。

% 最後に、研究分野の紹介と軸の提案を踏まえて、研究の自動化に関するパースペクティブ論文・レビュー論文のうちいくつかについて論じます。特に、紹介されている個別の研究よりも、それらの研究がどのようにして既存研究を整理しているか、どのような提案をしているかを見ていきます。これによって、本論文による整理の位置付けを改めて明確にし、次章以降の議論に繋げていきます。

\section{Existing Discussion on Research Automation}

Attempts to automate research began soon after the advent of computers. Until then, humans had developed science by describing experiences (primary science) and by making predictions through the construction of theories (secondary science). With the advent of computers came simulation science (third science), which uses computers to automate complex scientific computations, and data-driven science (fourth science), which automates the discovery of laws from large-scale data \cite{hey2009fourth}. Within the individual academic discipline ``X,'' the third science gave rise to the field of \textit{Computational-X} and the fourth science gave rise to the field of \textit{X-infomatics}, leading to the automation of entire academic disciplines.

\subsubsection{AI for Science}

Automation of scientific research with AI, including logical AI, has been an area of interest since the advent of AI \cite{langley1987scientific}. In the early stages of research, researchers created logic AIs that mimics the problem-solving process of researchers \cite{lindsay1993dendral}.

The remarkable performance of deep neural networks has now made almost all scientific fields more or less influenced by AI. The term \textit{AI for Science}, which automates scientific research with machine learning, has appeared due to the remarkable development of machine learning technology since the 2010s. 

AI for Science is a concept that encompasses a very wide range of initiatives. All attempts to solve problems in any process within science using machine learning or to develop the foundational technologies for them can be considered within the scope of AI for Science. Indeed, a vast number of machine learning application studies have been generated in numerous scientific fields \cite{xu2021artificial}, such as AI for Material Science and AI for Medical Science, named few.
\footnote{In this paper, it is not possible to introduce each of these individually, so we will omit the introduction of application studies in each research area of AI here. There are several excellent review papers available, so if you are interested, please refer to those.}

Wang et al. \cite{wang2023scientific} have excellently summarized these activities, we will introduce existing automation efforts while borrowing the view of their work. They categorize and organize various initiatives in AI for Science by focusing on which scientific processes they are related to: data handling, hypothesis generation, and simulation and experimentation \cite{wang2023scientific}. This is based on the view that the essence of science lies in the collection, transformation, and understanding of data.

The group of studies that incorporate biases to handle scientific data on AI, giving it information about the governing physical rule, is called \textit{physics-informed machine learning} \cite{karniadakis2021physics}. The incorporated biases include the ability to handle partial differential equations (PDE), symmetry, and intuitive physics \cite{hao2022physics}. Karniadakis et al. \cite{karniadakis2021physics} and Hao et al. \cite{hao2022physics} systematically and clearly summarize existing research from the perspective of which elements of machine learning are modulated by which biases and how they are incorporated. % TODO

The ability to handle PDEs gives us the basis for both the simulation of physical models and the discovery of the law from data, which we will discuss later. Studies that aim for better inductive biases and architectures in deep learning by treating symmetry as a first principle are called \textit{geometric deep learning} \cite{bronstein2021geometric}. Given the importance of symmetry in natural sciences, this group of research also plays a significant role in AI for Science. Zhang et al.  organize existing research in AI for Science across different research domains, focusing on symmetry as one of the common foundational pillars \cite{zhang2023artificial}.

The methods for generating hypotheses vary significantly depending on the subject, so there exists a wide range of approaches to automate this process. For example, attempts to generate hypotheses from articles or from scientific data are being undertaken in all research fields. 

One long-standing approach to hypothesis generation by AI is the research focused on discovering symbolic equations that describe scientific laws from data (\textit{equation discovery}). Among the earliest pioneering studies in this area, the BACON system by Langley et al. \cite{langley1987scientific}, and subsequent studies based on it, are well-known. In particular, the research on equation discovery that is mainly studied in the machine learning community is known as \textit{symbolic regression}, which originally started from research that used genetic programming approaches to discover symbolic equations.
 Kramer provides a comprehensive overview of the history of equation discovery research, including early studies that did not utilize machine learning \cite{kramer2023automated}. Famous deep learning approaches include AI Feynman \cite{udrescu2020ai,udrescu2020ai2}, which transformed the problem itself into a simple form and discovered the fundamental physical laws selected from Feynman's physics lectures.

% Symbolic regression is a problem of exploring a combinatorial hypothesis space among hypothesis generation \cite{wang2023scientific}. 
In science, exploration plays a crucial role, as exemplified by the search for hypothesis spaces and experimental conditions mentioned later. Therefore, methodologies for better automated exploration by machines have been sought, using techniques such as active learning. There is a perspective paper of research automation by Kitano \cite{kitano2021nobel} that focuses on the importance of machine-driven exploration of hypothesis spaces. Kitano points out that current hypothesis selection is value-driven, based on human value criteria, and argues that we should aim for hypothesis generation through exhaustive machine-driven exploration that is not dependent on such human value criteria. He points out that some of the Nobel Prize-winning research is actually the result of such exhaustive exploration, emphasizing the importance of this approach.
% \subsubsection{Symbolic Regression / Equation Discovery}
% % \subsubsection{Symbolic Regression} 
% Scientists have constructed models in the form of mathematical equations that explain them from observational data. This has enabled us to go beyond observational data to understand and predict underlying phenomena. That is to say, formulating a mathematical representation that elucidates the phenomenon behind the data is an extremely critical step in science. 

% One attempt to automate this endeavor is \textit{symbolic regression} \cite{makke2022interpretable}, or \textit{equation discovery}. These are attempts to infer from the data a formula that explains it. While classical approaches to symbolic regression have traditionally employed methods such as evolutionary computation, recent years have seen the emergence of strategies utilizing deep neural networks \cite{petersen2019deep,udrescu2020ai,udrescu2020ai2,cranmer2020discovering,kamienny2022end,d2022deep}. Some researchers have proposed the frameworks \cite{landajuela2022unified,keren2023computational} and benchmarks \cite{matsubara2022rethinking} for symbolic regression. You can find a literature review of symbolic regression in \cite{makke2022interpretable}, and that of the early studies in \cite{kramer2023automated}.

Once a hypothesis is formed, it is tested through experimentation. An experiment is the act of generating observational data through a set of predefined procedures. In modern science, simulations are used to generate data that resembles observational data. To create better simulations, knowledge of scientific computing is essential. The attempt to automate the generation and analysis of scientific data by combining scientific computing and machine learning is known as \textit{Scientific Machine Learning (SciML)} \cite{baker2019basic}. In physical simulations, numerical solutions to differential equations often come into play, so physics-Informed Machine Learning is also frequently discussed in this context. Experiments and numerical calculations come with uncertainties, so there is a long history of research on quantifying these uncertainties (\textit{uncertainty quantification}). This is also an important topic of study in SciML.

There is also a long history of research applying machine learning to experimental design. In particular, research on the efficient search for experimental conditions using active learning, including Bayesian optimization (\textit{Bayesian experimental design}), has been attempted in various application fields.

% 特に科学技術計算と機械学習を組み合わせて科学データの解析を自動化する試みは Scientific Machine Learning (SciML) と呼ばれています。（シミュレーション）

% 機械学習において科学データを扱えるような帰納的バイアスを組み込む研究群は Physics-informed machine learning と呼ばれています。組み込まれるものとしては、直観物理、微分方程式を扱う能力、対称性を抽出する能力などがあります。微分方程式の取り扱いは科学計算がずっと扱ってきたものですので、微分方程式を扱う研究は SciML の文脈で議論されることも多いです。また、対称性は幾何学的構造の保存なので、これらは geometric machine learning の一つとして議論されています。

% データからそのデータの背後の法則を記述するシンボリックな方程式を推定する試みも行われてきた。機械学習を用いてデータから方程式を推論する、symbolic regression がある。方程式を発見するシステムの先駆けとして BACON がある。2000年代には単位による制約から数学的に可能な方程式を同定する研究も行われた。これらは equation discovery という名前で研究されてきました。

\subsubsection{Automated Research Workflow}
Some studies have attempted to represent the processing of calculations and the flow of data in science as a single pipeline and to automate these processes. These studies refer to such pipelines as \textit{scientific workflow} or \textit{automated research workflow} \cite{national2022automated}. The work of \cite{gil2022will} expresses an insightful perspective for research automation from the point of this scientific workflow community. She introduced the idea of workflows for automated scientific data analysis and continuous generation, verification, and update of hypotheses.

\subsubsection{Laboratory Automation}
\textit{Laboratory automation} is a program that seeks to automate empirical research involving scientific experiments that involve interaction with the physical world.

What makes this effort unique compared to other efforts to automate research is that it seeks to automate even manual labor of humans in experimentation by developing robots for experiments to automate the entire process of experimentation. A notable example includes pioneering research in genetics by Ross King, who fully automated the cycle of hypothesis generation, verification, and discovery of new hypotheses with Adam \cite{king2004functional}. Another example is A.I. Cooper, which enabled the use of the same experimental equipment as humans through autonomous robots \cite{burger2020mobile}. Many attempts at laboratory automation are specialized for specific experiments. However, efforts are underway to develop humanoid robots capable of conducting experiments \cite{yachie2017robotic}, as well as initiatives to automate the low-level behaviors of robots, towards more general automation.

% A few examples include ``Mahoro'', a general humanoid robot that can conduct various experiments \cite{yachie2017robotic}. The robot could automatically conducted cell culture tasks using \cite{ochiai2021variable}


\subsubsection{Automating Mathematics}
The automation of mathematical proof, \textit{automated theorem proving} (ATP) , has been studied for a long tius. Recently several effort has come up to improve ATP by using machine learning, and especially deep learning. The early seminal work is led by Schulz \cite{schulz2001learning} and Urban \cite{urban2004mptp,urban2008malarea}. The first work applying deep learning to ATP is \cite{irving2016deepmath}. Subsequently, numerous studies have emerged on Automated Theorem Proving (ATP) using deep learning \cite{bansal2019holist}. Recent studies on this topic are well organized in the following paper, so we recommend reading it if interested \cite{rabe2021towards}.
% TODO: more organized literature review

While research has been accumulated on ATP, there is still not much research done on the automated theorem discovery with a few exceptions \cite{gao2014systematic}. In recent years, attempts have been made to help humans to find mathematical conjectures \cite{davies2021advancing} and
automatically generate mathematical conjectures \cite{raayoni2021generating}  using machine learning.

\subsubsection{Automating Machine Learning}
The attempt to automate various tasks related to machine learning is called \textit{AutoML}. This includes hyperparameter optimization, neural architecture search (NAS), and automation of various pre- and post-processing steps in machine learning. The following website \cite{automlorg} provides a very active overview of AutoML. For literature review, the book \cite{hutter2019automated} explained well about the AutoML by 2019, the paper \cite{bischl2023hyperparameter} and \cite{lindauer2020best,white2023neural} summarizes comprehensively the current state of hyperparameter selection and NAS, respectively. Recently, research has emerged that allows machine learning tasks to be executed with text-based instructions alone \cite{vijay2023prompt}.

Additionally, there is an initiative called MLOps (Machine Learning Operations) that aims to to streamline and automate operations related to machine learning primarily in the business context. This includes automating tasks such as model deployment and continuous training, as well as experiment management. MLOps have tried to automate the laborous tasks that need to be automated to aim for the full automation, such as experiment management, versioning, and deployment. The paper \cite{kreuzberger2023machine} is a good scientific review paper on MLOps.

\subsubsection{Scholarly Document Processing}

\subsubsection{Automating Peer-Review}
There are also attempts to automate the peer-review process. Researchers have tried to automate review generation \cite{yuan2022can}, paper screening \cite{schulz2022future}, research paper assessment \cite{kousha2022artificial}, reviewer assignment \cite{zhao2022reviewer}, and more. As in other fields, recent years have seen research on the automation of peer review using large-scale language models. For traditional research on the automation of peer review, \cite{kousha2022artificial} and \cite{lin2021automated1} have conducted comprehensive literature reviews. In particular, Kousha et al. cover a wide range of topics related to the automation of various aspects of peer review.

% Many studies have tried to automate peer review generation \cite{thelwall2019artificial,li2019generating,schulz2022future,yuan2022can,yuan2022kid,lin2021automated1,lin2021automated2,kumar2022investigations,bharti2022can,uban2021generating,wang2020reviewrobot}. While not generating peer reviews directly, studies focused on automating research paper assessment  can be said to be related to the peer review automation. \cite{kousha2022artificial,li2020multi,huang2018deep}. These studies have proposed the method to assess the quality \cite{thelwall2022predicting,thelwall2022can}, novelty \cite{pelletier2022novelpy,amplayo2019evaluating,shibayama2020measuring}, soundness \cite{cabanac2022decontamination}, and significance \cite{zong2022citation,xia2023review,soni2022predicting,manghi2021new,soni2021follow,van2020schubert,mckeown2016predicting}.

% These investigations concern the automation of processes occurring subsequent to a manuscript's arrival at the hands of reviewers. Conversely, researchers also have investigated the automation before that process, such as determining the appropriate journal for submission \cite{michail2023journal} and assigning the reviewers \cite{zhao2022reviewer}.

% While not centered on automation, certain studies engage in the scientific analysis of the review process \cite{shah2022challenges,verma2021attend,bharti2022confident,bharti2022betterpr,verma2022lack,kennard2022disapere}. These investigations serve to enhance our understanding of the nature of peer review and, in turn, provide valuable insights for the design of more effective automated review methodologies. 

% 数学の定理の証明を自動化する研究は古くから、Automated Theorem Proving (ATP) という名前で研究されています。証明を変換された定理たちをノードにもつ木の探索問題に帰着させるのが基本的なアプローチです。

% より最適な実験条件の決定を自動で行う試みもあります。有名なものはベイズ最適化を用いたベイズ実験計画と呼ばれているものです。

% 学術論文の取得からの情報抽出までを自動化しようという試みも長い研究があります。Scholarly document processing などと呼ばれます。これらはもともと自然言語処理やテキストマイニング、情報検索などのコミュニティで研究されてきました。近年は大規模言語モデルの登場により、多くの課題が解決されました。

% 人間が手作業で行ってきた実験をロボットの力を借りて自動化しようという試みもあります。これらは laboratory automation と呼ばれています。

% 科学における計算の処理とデータの流れを一つのパイプラインとして表現し、それらの処理を自動化しようという研究もあります。これらの研究ではこのようなパイプラインを Scientific Workflow あるいは Automated Research Workflow と呼んでいます。

% 機械学習自体を自動化しようという試みは AutoML として知られています。ハイパーパラメータの探索やアーキテクチャの探索の最適化と自動化などが主に研究されています。また、主にビジネスにおいて機械学習に関連する諸タスクの実行を自動化する取り組みの総体は、MLOps と呼ばれています。

% Peer review を自動化しようという研究も存在します。

% 機械学習の中でも科学研究への応用の文脈でよく言及される分野があります。例えば、active learning, explainable AI, uncertainty quantification, out-of-distribution generalization, exploration、などはこれらの例の一部です。

% 記号的なAIの分野でも早くから研究の自動化の取り組みが行われてきました。例えば、DENDRAL は科学者の思考を自動化したものや、アブダクションなどの推論によって知識発見を自動化しようという試みもある。これらの取り組みは広義には Knowledge Representation and Reasoning という分野の中で盛んに研究が行われてきた。

% While there have been some excellent review articles and perspective papers on previous efforts to automate research, there have not yet been many reviews that deal with these research automation efforts in a shallow or even conservative manner. Therefore, this chapter provides the most comprehensive review possible of research on research automation to date.

% The field related to research automation is vast. While it is not possible to cover all of them, we aim to present as comprehensive an introduction as possible. For this reason, the review of each individual field will be limited to a brief overview. We will introduce survey papers and other literature in those fields, and those who wish to understand more advanced discussions should refer to those references.

% In the following, we will present the past efforts of mankind related to research automation, paying attention to what level of general ``task'' each research automation is oriented toward. This is because efforts to automate research can be interpreted as automating a set of tasks in the research process, or acquiring the ability to do so. Note that the level of generality treated here is naturally not absolute, but is set for convenience. Also, please keep in mind that this classification is for classifying human research activities, so humans are only assumed as the subject of the research. After introducing each effort, we will position these efforts in light of the formulation of the knowledge production process that this paper has dealt with.

\textcolor{red}{CAUTION: We have not read all of the literature in detail and it may contain errors. We will continue to update this paper, but if you find errors, please contact us or throw us a pull request.}

\section{Level of Generality of Task/Skill}
The first and most versatile ability is the ability to perform any task a human being can perform. This includes, for example, the ability to think, to manipulate language, and to act. Second, there are abilities that are required for any research. These include the ability to ask questions, generate hypotheses, and test hypotheses, as explained in Chapter 2. The ability to manipulate the scholarly literature and to search for information are also included in these abilities. This is because research is the activity of producing knowledge from arbitrary inputs, and information retrieval is essential for obtaining inputs, and manipulation of the academic literature is essential for processing and outputting these inputs. So far, this is the capability required for all research.

Next, there are fields of study that involve some form of quantity in order to do the research. If there are basic quantities involved, whether in the natural or social sciences, then this is the field. These research fields require the ability to manipulate mathematics in some form. In those fields that require the use of empirical methods, which are research methods for generating and analyzing data, you need to be able to use statistics and data analysis.

And there are abilities that are universally needed within each discipline, such as natural sciences, social sciences, and humanities. For example, in the natural sciences, the ability to perform experiments that interact with the physical world is an essential skill in a very broad range of natural sciences.

Below that, the generality of tasks and the ability to acquire them gradually narrows down to abilities that are widely needed within each discipline as a whole, such as physics, chemistry, biology, and medicine, and then to abilities needed in even smaller disciplines, such as condensed matter physics, organic chemistry, and molecular biology, and so on.

Fig. \ref{fig:generality_level} represents the hierarchical structure of generality of tasks we have discussed above. Of course, in actual research, the disciplines are closely related to each other, and such a hierarchical structure is not perfect. What we want to emphasize here is that there are differences in the degree of generality of the technologies to be automated and the capabilities to acquire them, and that each automation effort can be considered distinct in terms of its degree of generality. In the following, we will review the automation efforts of previous studies, focusing on these differences. To emphasize again, this chapter will focus on automation efforts in research related to science in the narrow sense, i.e., the natural sciences.


\begin{figure}[htb]
    \centering
    \includegraphics[width=\linewidth]{figs/generality_level.jpg}
    \caption{Caption}
    \label{fig:generality_level}
\end{figure}

\section{Automation of Tasks for Diverse Field of Research}

\subsection{Scholarly Document Processing}
\textit{Scholarly document processing} is a general term for research on automated processing related to scholarly articles and has been studied as part of natural language processing, text mining, and information retrieval.

\textcolor{red}{TODO: Skip for now. Need reconstruction because many of the issue discussed below are no more issue for research automation. Most of these will moved to Appendix}

\subsection{Peer Review}
Many studies have tried to automate peer review generation \cite{thelwall2019artificial,li2019generating,schulz2022future,yuan2022can,yuan2022kid,lin2021automated1,lin2021automated2,kumar2022investigations,bharti2022can,uban2021generating,wang2020reviewrobot}. While not generating peer reviews directly, studies focused on automating research paper assessment  can be said to be related to the peer review automation. \cite{kousha2022artificial,li2020multi,huang2018deep}. These studies have proposed the method to assess the quality \cite{thelwall2022predicting,thelwall2022can}, novelty \cite{pelletier2022novelpy,amplayo2019evaluating,shibayama2020measuring}, soundness \cite{cabanac2022decontamination}, and significance \cite{zong2022citation,xia2023review,soni2022predicting,manghi2021new,soni2021follow,van2020schubert,mckeown2016predicting}.

These investigations concern the automation of processes occurring subsequent to a manuscript's arrival at the hands of reviewers. Conversely, researchers also have investigated the automation before that process, such as determining the appropriate journal for submission \cite{michail2023journal} and assigning the reviewers \cite{zhao2022reviewer}.

While not centered on automation, certain studies engage in the scientific analysis of the review process \cite{shah2022challenges,verma2021attend,bharti2022confident,bharti2022betterpr,verma2022lack,kennard2022disapere}. These investigations serve to enhance our understanding of the nature of peer review and, in turn, provide valuable insights for the design of more effective automated review methodologies. 

\subsection{Cognitive }

\section{Automation of Tasks for Diverse Fields of Science}
% There are prerequisite competencies and knowledge required to conduct scientific research. And the question of how to acquire such abilities has been one of the major concerns of AI research for science. Therefore, we will first introduce these research areas. In particular, we will present research on processing scientific literature and understanding scientific knowledge.

% \subsection{Automated Theorem Proving}



% \subsection{Understanding Scientific Knowledge}

% \subsection{AI for Science}

TODO

\subsection{Scientific Language Models/Foundation Models}
In order for us to do scientific research, we must have learned prior knowledge about science. Therefore, research has been done to teach or incorporate such scientific knowledge and assumptions into machine learning models.

One of the most popular approaches today is to create foundational models in science. A foundational model is a pre-trained model that can be adapted to extremely generic downstream tasks. In particular, because language is an extremely general-purpose interface and because language models have developed by leaps and bounds, large-scale language models are now predominantly trained on vast amounts of textual data.

In science, scientific large-scale language models have also been developed by training huge amounts of scientific texts, including textbooks and papers \cite{taylor2022galactica}.
% \cite{beltagy2019scibert,singh2022scirepeval,nadkarni2021scientific,cohan2020specter,gupta2022matscibert,taylor2022galactica}.

% \subsubsection{Scientific Language Models}

Whether engaging in reading or writing, the presence of a system that comprehends natural language is indispensable. In recent years, large-scale language models, trained on extensive textual data, have achieved significant success. Concurrently, numerous language models, specifically tailored to scientific documents, have also been proposed \cite{beltagy2019scibert,singh2022scirepeval,nadkarni2021scientific,cohan2020specter,gupta2022matscibert,taylor2022galactica}.

\textcolor{red}{TODO: table for scientific lm}

\subsubsection{Scientific Understandings of GPTs}

\textcolor{red}{TODO: table for case studies to test the scientific understanding of chatgpt and gpt-4 }

\subsection{Scientific Machine Learning: Inserting Inductive Bias for Scientific Understanding}
Another prominent approach to incorporating such scientific knowledge into artificial intelligence is to incorporate inductive biases that help scientific understanding. This area has been studied typically under names such as \textit{scientific machine learning (SciML)} and \textit{physics-informed machine learning}.

Whereas methods to learn scientific knowledge from the literature are generic methods that learn scientific knowledge through the generic interface of language, in this approach, humans add biases to either the model, the data, or the optimization method that are assumptions of scientific understanding. The constraints that have been studied include the abilities to handle (differential) equations, symmetry, intuitionistic physics, and so on \cite{hao2022physics}. 

For differential equations, Physics-Informed Neural Networks \cite{raissi2019physics} and Neural Operators \cite{kovachki2021neural} are well known examples of this line of studies. These are methods that enable data-driven simulation of differential equations from data (forward problems) and differential equation discovery (inverse problems). Deep neural networks that can handle symmetry are studied under the name \textit{geometric deep learning} \cite{bronstein2021geometric}. The following survey is comprehensive in this area and should be referred to by those interested \cite{hao2022physics}.

\subsection{For Empirical Studies}
Research methods in science can be empirical or non-empirical. Empirical research is research that involves the generation of data, one of the crucial elements in science. Here, we present an effort to automate research on tasks related to scientific data. Machine learning is used in these areas in a variety of ways, including variable selection and model selection, but this section will focus specifically on those areas that have names.

\subsubsection{Laboratory Automation}
\textit{Laboratory automation} is a program that seeks to automate empirical research involving scientific experiments that involve interaction with the physical world.

What makes this effort unique compared to other efforts to automate research is that it seeks to automate the entire process of validation, and it seeks to automate even the manual labor of humans in experimentation. Specifically, they automate human tasks by creating robots that can conduct research. A few examples include ``Mahoro'', a general humanoid robot that can conduct various experiments \cite{yachie2017robotic}. The robot could automatically conducted cell culture tasks using \cite{ochiai2021variable}

\subsubsection{Bayesian Experimental Design}
In order to conduct an efficient experiment, it is necessary to properly determine which experimental. \textit{Experimental design}, which involves devising efficient methods for conducting appropriate experiments, has long been studied. \textit{Bayesian experimental design} is an attempt to optimize and automate this experimental design by using Bayesian optimization \cite{chaloner1995bayesian,shahriari2015taking}. Bayesian experimental design has been incorporated from a relatively early stage and has been used in materials science and other fields.


\subsubsection{Symbolic Regression / Equation Discovery}
% \subsubsection{Symbolic Regression} 
Scientists have constructed models in the form of mathematical equations that explain them from observational data. This has enabled us to go beyond observational data to understand and predict underlying phenomena. That is to say, formulating a mathematical representation that elucidates the phenomenon behind the data is an extremely critical step in science. 

% Modern science is composed of a cycle of observation, hypothesis generation, and hypothesis testing. In many fields, including physics, chemistry, and biology, mathematical models are often constructed as hypotheses from observational data. 

One attempt to automate this endeavor is \textit{symbolic regression} \cite{makke2022interpretable}, or \textit{equation discovery}. These are attempts to infer from the data a formula that explains it. While classical approaches to symbolic regression have traditionally employed methods such as evolutionary computation, recent years have seen the emergence of strategies utilizing deep neural networks \cite{petersen2019deep,udrescu2020ai,udrescu2020ai2,cranmer2020discovering,kamienny2022end,d2022deep}. Some researchers have proposed the frameworks \cite{landajuela2022unified,keren2023computational} and benchmarks \cite{matsubara2022rethinking} for symbolic regression. You can find a literature review of symbolic regression in \cite{makke2022interpretable}, and that of the early studies in \cite{kramer2023automated}.

% \subsection{Knowledge Representation and Reasoning}

\section{Automation of Tasks in Each Research Field}

It has become commonplace to streamline domain-specific tasks in scientific research using machine learning, resulting in a vast number of published papers. Even just to mention a few that come to mind, there are studies on molecular biology \cite{jumper2021highly,senior2020improved}, material science \cite{ramprasad2017machine}, medical science \cite{vamathevan2019applications,shorten2021deep}, quantum mechanics \cite{carleo2017solving}, cosmology \cite{carleo2019machine}, genetics \cite{libbrecht2015machine}, and nuclear physics \cite{degrave2022magnetic}. It is impossible to cover all of these applied studies of research automation of science. Therefore, in this paper, we will not go into detail about each of these studies. Instead, we will present research on automation of elements that can be applied in various fields of science. For the literature survey of domain specific automation, please refer to \cite{xu2021artificial}. \textcolor{red}{TODO: Add application studies}

\subsection{Automating Machine Learning}

\subsubsection{AutoML}
AutoML is an attempt to automate all tasks associated with machine learning. This includes hyperparameter optimization, model selection, and automation of various pre- and post-processing steps. The following website \cite{automlorg} provides a very active overview of AutoML. The book \cite{hutter2019automated} for an overview of AutoML through 2019, the paper \cite{bischl2023hyperparameter} for hyperparameter selection, and \cite{lindauer2020best,white2023neural} for the current state of the NAS are very helpful to catch up to this field.

\subsubsection{MLOps}
MLOps (Machine Learning Operations) is a general term for efforts to streamline and automate operations related to machine learning in industry. For example, it includes automating tasks such as model deployment and continuous training, as well as experiment management. To be sure, many MLOps solve problems in industry, and not all of them are related to research automation. However, when actually conducting research, we are involved in experiment management, versioning, and other tasks. While research on research automation has left out automation of these tasks, MLOps is accumulating knowledge on automation of these tasks as well.  The paper \cite{kreuzberger2023machine} is a good scientific review paper on MLOps.

\input{diagrams/ai4sci}

\section{Another Axis: Research Process}
We have presented the idea that attempts to automate research could be classified hierarchically according to how broadly they could affect research. In addition to this, we believe that these efforts can also be categorized from another angle. That is, from the perspective of what part of the research process is being automated. For example, one effort might automate only the hypothesis generation part of a broad scientific study, while another effort might automate the entire research process instead of focusing on a specific research question. Also, for example, within an effort to automate validation, one effort might automate experimentation, another might automate proofs, and yet another might automate both of these. Thus, the second axis is what part of the research process is being automated and to what degree of generality.

Along this second axis, we will review our efforts in research automation. However, since there are a vast number of examples of research automation even in one sub-process, e.g., hypothesis generation, we will not go into individual details, but rather give priority to conveying the big picture.

% \textcolor{red}{NOTE: touch briefly do not go too specific, just show interpretation}
% \section{Knowledge Production}
% The Process of Creating New Knowledge

% Modern research is constructed from three main phases: observation, hypothesis generation, and hypothesis verification <- not line but cycle

\subsection{Question Construction}
In research automation studies, questions are often given. An exception is research that automatically discovers questions and issues from the academic literature. For example, Lahav et al. have proposed a methodology for automating the discovery of prevailing challenges within the research community, as well as the emerging hypotheses to address them \cite{lahav2022search}.

\subsection{Hypothesis Generation}
It is probably fair to say that hypothesis generation is one of the most common processes studied in research automation. Prediction of 3D structures from amino acid sequences, prediction of material structures from desired physical properties, and prediction of newly applicable disease candidates from existing drugs, just to name a few, are examples of automated hypothesis generation. In the example given in the previous section, symbolic regression is another example of hypothesis generation. These studies are often aimed at automation and optimization to solve bottlenecks in problems specific to each research area.

\subsubsection{Hypothesis Generation from Scientific Papers}

One study of automated hypothesis generation that is generic to a wide range of fields is the automatic generation of hypotheses from scholarly literature. In recent years, several researchers have presented studies on automating scientific analogical reasoning for identifying the relationship between problems and their corresponding solutions \cite{kang2022augmenting,chan2018solvent}, which is hypothesis.

% For example Portenoy proposed a system that recommend researchers who are pursuing analogous research objectives via divergent approaches \cite{portenoy2022bursting}.el techniques.

% \subsubsection{Others} 

Some methods have been proposed that don't generate hypotheses directly, but rather assist humans in generating hypotheses from experimental data 
 \cite{friederich2021scientific}.

\subsection{Hypothesis Verification}
Attempts to automate the verification of hypotheses include Bayesian experimental design, laboratory automation, and automated theorem proving, if theorems are viewed as hypotheses, as mentioned above. For example, some researchers have tried to automate experimental design for quantum physics \cite{ruiz2022digital} or proposed to design workflow of scientific research as a software \cite{goble2020fair}. Others have proposed machine learning algorithms for formulating and executing experimental designs in a more abstract and simple manner \cite{herrmann2022learning}. 

% \subsubsection{Verification Design}

% Once a hypothesis is formulated, a plan is developed to test its validity. The design of this verification plan is far more flexible than that of hypothesis generation, making it more difficult to handle uniformly. To be more precise, while many sciences have standardized methods such as statistical tests for verification, there is a wide variety of methods for generating the data used for the verification. One study may require a huge machine to collide elementary particles, while another may use rats for behavioral experiments. Some studies may require the use of chemicals, while others can be simulated on a computer. Furthermore, even with standardized statistical tests, as mentioned earlier, automating their creation from scratch proves exceedingly challenging. It is readily apparent that devising standardized methodologies like statistical tests is difficult when one must not merely employ them as tools but also contemplate the very nature of what it means to verify, as well as the rationale behind adopting specific assumptions. Therefore, it may not be an overstatement to say that this aspect represents the biggest obstacle towards achieving complete automation of research in a unified manner.

% \subsubsection{Verification Execution}

% Once a verification plan has been devised, the process proceeds in accordance with it. As previously mentioned, the approach may vary considerably. However, in many scientific methodologies, statistical techniques are employed. In these instances, the verification process can be broadly divided into two stages: 1. data generation and 2. analysis of the generated data for verification.

% As previously mentioned, data generation methods span a wide range. Among these, attempts have been made to automate the work of researchers within laboratories, an endeavor known as Laboratory Automation. For instance, 
% some studies focus on automating cell culture tasks using humanoid robots \cite{ochiai2021variable},
% TODO: add more

% TODO: may differentiate the analysis for hypothesis generation from that for verification
% we interpret data processed according to a certain criterion, assessing the validity of our inferences. Here, we make an explicit distinction between analysis for verification and analysis for hypothesis generation. Modern science is composed of a cycle of observation, hypothesis generation, and hypothesis testing. It's common to generate the next hypothesis to be tested from data produced for verification. However, this merely signifies that we conduct both hypothesis generation and testing through a somewhat inductive reasoning based on data. Therefore, in this context, we will focus on data analysis for hypothesis testing, while data analysis for hypothesis generation will be included in the hypothesis generation section introduced earlier.

To validate the plausibility of assertions, we currently employ statistical methods. There is research that automate the hypothesis testing \cite{gil2016automated}. 

Some researchers have engaged on automating data visualization and analysis \cite{bavishi2021vizsmith,bavishi2022tools}.

\subsubsection{Scientific Claim Verification}

Compared to question construction and hypothesis generation, there are few attempts to automate hypothesis verification related tasks from the academic literature. Somewhat related is the field of \textit{scientific claim verification} \cite{li2019scientific,wadden2020fact,wadden2022scifact,wadden2022multivers}, which determines the validity of a scientific claim through analysis of research paper. This is not the planning or execution of validation, but it is related to the automation of validation in the sense that it seeks to understand the validity of scientific claims. Since it is an assessment of the validity of a study, the findings of this study may have implications for the automation of peer-review.

\subsection{Pipeline (All Process)}
Most research on research automation automates some tasks in the research process. In contrast, there are attempts to automate the entire research process from start to finish.

\subsubsection{Self-Driving Labs}

A seminal early works are Adam \cite{king2004functional}, and Eve \cite{williams2015cheaper}. These are closed-loop scientific discovery systems that autonomously execute everything from hypothesis generation to research planning. These systems have logic AI at their foundation. The author of the paper of Adam call these system \textit{robot scientists}, \textit{self-driving labs}, \textit{autonomous discovery}, or \textit{laboratory automation}.

\subsubsection{Scientific Workflow}

Additionally, the concept of a \textit{scientific workflow}, which represents data and computational processing pipelines in research as software, emerged in the early 2000s. The developments and advances in research related to scientific workflows are consolidated in this literature \cite{barker2008scientific,atkinson2017scientific}. Additionally, these papers \cite{deelman2019role,nouri2021exploring} discusses how machine learning contributes to streamline the each step in the scientific workflow. These are important initiatives in terms of softwareizing the research process \cite{deelman2015pegasus,gil2011semantic}.

\section{Two Axes in the Same Page}

So far we have introduced the idea that we can look at research automation from two axes: the ``research field'' axis and the ``research process'' axis. We will try to paint a conceptual picture of how research automation can be viewed from these two axes.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\linewidth]{figs/generality_matrix.jpg}
    \caption{Caption}
    \label{fig:generality_matrix}
\end{figure}

Fig. \ref{fig:generality_matrix} conceptually illustrates the position of automation according to the axes of research field and research process. The vertical axis is the research field axis and the horizontal axis is the research process axis. Closer to the vertical axis corresponds to more specific research areas, and farther away from the vertical axis corresponds to a broader range of research areas. The horizontal axis corresponds to question construction, hypothesis generation, and hypothesis testing, from left to right, and is further divided within each category into more detailed e.g. empirical and non-empirical methods. Note that this is only a conceptual diagram and not an exact classification.

As a example, the automation of protein structure prediction \cite{jumper2021highly} can be seen as the automation of a certain hypothesis generation task in a certain molecular biology study. The work of robot scientist \cite{king2004functional} can also be understood as an attempt to automate many of the steps in the study of identifying the function of genes in genetics, from hypothesis generation, to testing, to generating new hypotheses. (Explanation of the figure).

Our goal of creating a versatile and autonomous artificial researcher is to automate everything on this two-dimensional surface. The area circled by the blue qualification in this figure corresponds to that. In other words, our goal is to realize an artificial intelligence that can autonomously execute any research or any process of research.

\section{Reviews and Perspectives}
So far, we have introduced each of the areas related to research automation. In this section, we will introduce review papers and perspective papers on research related to research automation. Note that the number of review papers on automation in individual research fields is too large to cover them all, so we have only selected review papers that are more comprehensive or abstract.

\subsubsection{Scientific Workflow}
Gill presents an extremely exciting idea of conducting automated research by turning the entire scientific process into compositional and modular software with the literature review of her and her colleagues' work. \cite{gil2022will}. For example, Gill et al. have created a software of the semantic workflow of scientific data analysis and computation process  \cite{gil2011semantic}. 
Each step of this workflow modularizes the procedures in research. Not only can these make analysis more efficient, but they also allow for the analysis of the research process itself. Furthermore, common workflows can be identified from multiple workflows, enabling abstraction of cross-domain knowledge about research process. Additionally, Gill and her team have proposed DISK, a systematic framework for hypothesis testing and data analysis. DISK can automatically cycle through a series of processes, including the generation of hypotheses, the determination of data and methods to test them, the acquisition of data from shared repositories, the analysis of that data, and the modification of hypotheses. Furthermore, each hypothesis is associated with information on confidence level and analysis details, which significantly indicates the plausibility of the hypothesis. Additionally, as the hypothesis and its confidence level and analysis are continuously updated and the revision history is retained, it enables the continuous maintenance and update of scientific findings.

\subsubsection{Nobel Turing Challenge}
Kitano also harbors an ambition to automate the entirety of the research process \cite{kitano2021nobel}. This is a thought-provoking paper that is meticulously contemplated. Kitano underscores the ability of AI in automating science to execute exhaustive and thorough exploration as a significant strength. We, as humans, aim to generate hypotheses that yield impactful results (Kitano refers to this as a value-driven approach). However, the importance of research findings is context-dependent, and research that we humans deemed unimportant may become crucial if the presuppositions or the context alter. Kitano proposes to eschew this value-driven approach and implement an alternative, exploration-driven methodology to science, aiming for novel scientific discoveries that were unattainable by human capabilities. Besides, Kitano with many examples and detailed consideration, presents a plethora of stimulating ideas, such as the continuous hypothesis network update, a roadmap to achieve autonomous artificial scientists, and proposition of the Nobel Turing Challenge as a Grand Challenge to substantially advance these endeavors. We highly encourage those interested to delve into this fascinating read.

\subsubsection{Task-guided Scientific Knowledge Retrieval}
Hope et al. have written a captivating perspective paper on the automation of research, presenting a fresh and exciting viewpoint \cite{hope2022computational}. They introduce a human-centric idea aimed at efficiently extracting relevant information from the ever-expanding body of research data, tailored specifically to the tasks researchers are engaged in - a framework they term \textit{task-guided scientific knowledge retrieval}. They start by conceptualizing the act of research as an interaction between a researcher's \textit{inner cognitive world} and the \textit{outer world}, or \textit{scientific ecosystem}. Building on this, they underscore the vital role of representing and retrieving information that aligns with the inner cognitive world of researchers, deftly transforming the cognitive functions used in human research into algorithmic processes.

Extensive discourse transpires concerning scientific discoveries. Yet, discussions pertaining to scientific comprehension remain relatively unexplored. Hope et al. delve into the conundrum of what it entails for a machine learning agent to not only unearth scientific knowledge but also to comprehend it \cite{krenn2022scientific}. They adopt a human-centric stance, positing that an agent's ability to offer explanations comprehensible to human scientists signifies the existence of its scientific understanding.

\section{Others}

Upon the completion of a study, the drafting of a manuscript, and its successful navigation of the peer-review process, the resulting findings are deemed to possess a degree of credibility as knowledge. Naturally, it would be hasty to assert that this alone births ``correct'' knowledge, as research demands iterative verification to confirm its validity. We convey such knowledge to others through various means, one of which is the presentation of research findings. To effectively communicate these outcomes, we create slides that elucidate our work. Studies also exist that strive to automate this aspect of the dissemination process \cite{sefid2019automatic}.

\section{Conclusion}