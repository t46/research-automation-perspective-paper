\section{Conceptual Characterization of Research}
\label{section-what-is-research}

Understanding the fundamental nature of research is crucial for creating an agent capable of autonomous research. This section will therefore speculatively consider how the act of research can be characterized.

The aim of this section is not to establish a universal and singular definition of research, a task that exceeds the scope of this paper. Rather, it explores some characteristics of research to provide a provisional basis for discussions on the development of an artificial researcher. 

As such, the definition of research presented here should be regarded as tentative and operational, and the ensuing discussion is just one example of an endeavor to characterize research. Refining our understanding of research through in-depth discussions in the future is essential for the development of agents capable of conducting research. 

\subsection{Research as Knowledge Production}

While finding a unified, all-encompassing definition of research or science remains infeasible \cite{chalmers2013thing,sep-scientific-method}, various interpretations exist. For instance, one view posits that research occurs ``whenever we gather information to answer a question that solves a problem'' \cite{booth2003craft}, while another describes research (and development) as comprising ``creative and systematic work undertaken in order to increase the stock of knowledge'' \cite{manual2015guidelines}. Additionally, some perceive the science as ``processes that maximize the evidence for a generative model of the sensed and measured world'' \cite{balzandistributed}. These descriptions highlight different crucial aspects of research, with none being entirely incorrect or absolutely definitive.

Among these, a broadly recognized definition can be that \textbf{research is an endeavor to generate new knowledge}. Since this characterization seems to align with our research practices, regardless of the field, this definition serves as a suitable starting point for our discussion. In this paper, I adopt this interpretation as a provisional working definition. Specifically, I will regard research as the attempts to produce new knowledge for certain society. The inclusion of ``for certain society'' acknowledges the societal relativity of knowledge, a point I will elaborate on in subsequent sections.


\subsection{Knowledge Production as Belief Revision}
\label{section-knowledge-production-as-belief-revision}
Having defined research as the endeavor to generate new knowledge, it becomes important to consider what ``knowledge'' itself entails, and what constitutes its production. This section aims to explore these concepts.

Defining knowledge and the process of knowledge production rigorously remains an unsettled philosophical debate \cite{sep-epistemology}. Given that providing a precise definition of knowledge is beyond the scope of this paper, an in-depth exploration of these debates will not be undertaken here. Instead, this section aims to present a basic and preliminary conception of what knowledge might entail so that it serves as a starting point  for further discussion.

% I have defined research as the endeavor to generate new knowledge. Then, what exactly is knowledge, and what does it mean to produce knowledge? I will explore this question in this section. 

% Defining knowledge and knowledge production rigorously is a philosophical debate that has not yet been settled \cite{sep-epistemology}, and I won't delve into it deeply here. Instead, I would like to provide some primitive ideas that can serve as a starting point for further discussions.

\subsubsection{Knowledge as Belief}
The concept of knowledge has long been a subject of debate within \textit{epistemology}, a branch of philosophy. This paper will reference some basic and introductory concepts in this field as an exemplar to explore how research might be characterized.

Within epistemology, knowledge has traditionally been viewed as \textit{justified true belief (JTB)} \cite{sep-epistemology}. The term ``true'' is challenging to define rigorously; however, for the purposes of this discussion, it can be understood as something that corresponds with fact. ``Belief'' is tentatively defined as an individual's thought or conviction about a subject. ``Justified'' implies that it is reasonable to hold such a belief. The nature of justification has been a focal point of debate in epistemology, particularly following criticisms that JTB may not adequately define knowledge \cite{gettier1963justified}. Consequently, the refinement or expansion of the JTB has become a significant topic in epistemological discourse \cite{sep-epistemology}.

Although many philosophers contend that the JTB properties alone are insufficient for defining knowledge, there is some consensus that they might be necessary components \cite{sep-epistemology}. In epistemological debates, rather than discarding JTB entirely, many theorists use it as a foundational concept. Hence, this paper will tentatively adopt JTB as a preliminary basis for discussion. 

The subsequent sections will explore how research is conceptualized under this definition. Analyzing the congruences and discrepancies between the implications drawn from this characterization and our expectations of a research-capable agent will generate insights for refining the definition of research and hypothesizing the capabilities such agents should possess.


% The question of what is the thing called knowledge has been a subject of debate for a long time in the field of \textit{epistemology}, which is one of the branches of philosophy. So, for now, I would like to refer to the discussion in this field as an example and see how research can be characterized.

% In epistemology, knowledge had been classically considered to be \textit{justified true belief (JTB)} \cite{sep-epistemology}. The term ``true'' is difficult to define rigorously, but for the purpose of discussion, let's think of it as something being fact. ``Belief'' can be provisionally understood as someone's thought or conviction about something. And ``justified'' means that it is deemed reasonable to hold such a belief. What justification means has been discussed in epistemology as a central point of contention. Since the criticism that JTB is not appropriate as the definition of knowledge \cite{gettier1963justified}, how to modify or expand JTB to make it a suitable definition of knowledge seemingly has been a major discussion in epistemology \cite{sep-epistemology}. 

% While most philosophers don't appear to believe that these properties are sufficient to define knowledge, there seems to be some agreement that they may be necessary \cite{sep-epistemology}. Even in the epistemology discussion, rather than abandoning the JTB altogether, many discussions adopt JTB as a base. Therefore, let me tentatively assume that knowledge is JTB in this paper to offer a preliminary basis for discussion. In the following section, I will examine how research is perceived as an activity when adopting this definition. Examining the discrepancy and alignments between the consequences of this characterization and our expectations for a research-capable agent will provide seeds of thought for a better definition of research and hence what that agents should be able to do.

\subsubsection{Knowledge Production as Belief Updating}
In the current framework, knowledge is equated with belief. Therefore, knowledge production can be reinterpreted as the process of adopting the belief that a particular proposition is true and subsequently revising this belief based on justification. Essentially, in this framework, knowledge production equates to the updating of beliefs.

While it might initially seem counterintuitive to view research as a process of updating beliefs, this perspective gains plausibility when considering several factors. Research involves the continual revision of hypotheses and theories; inductive reasoning, unlike deduction, does not conclusively prove propositions; and, as will be discussed, knowledge is essentially subjective. The characterization of research as belief aligns well with these aspects of research. Therefore, this characterization seems reasonably valid.

The primary aim of research can be conceptualized as uncovering the unknown truths of the world. Consequently, the justification employed in research must be capable of accurately discerning the truth or falsity of propositions. This form of justification, known for its capacity to lead to truth, is termed ``truth-conducive.'' While there are varied debates on the nature of justification, it is widely accepted that justification in research should indeed be truth-conducive. Thus, knowledge production can be conceptualized as the construction of belief in new propositions about the world and ascertaining their veracity through truth-conducive justification.

% The purpose of research can be said to be revealing the unknown truths of this world. Therefore, the justification in research is demanded to be such that it determines propositions as true if they are true, and false if they are false. Such justification is called truth-conducive. There are various discussions about what justification is, but it can be said that justification in research should be truth-conducive. Therefore, producing knowledge could be said to be constructing a new proposition that refers to this world and determining its truth or falsity through such justification. 

% In the current definition, we regard knowledge as belief. Thus, the producing knowledge can be rephrased as holding the belief that a proposition is true and updating this belief through truth-conducive 
% justification. In short, the knowledge production is belief update in current definition.

% It might feel counterintuitive to think of research as an updating of beliefs, but considering that hypotheses and theories are continuously updated in research, inductive reasoning does not prove propositions as deduction does, and, as will be discussed later, knowledge depends on the subject, this characterization doesn't seem so far-fetched. 

\subsection{To Know Depends on Knowing Subjects}

Fundamentally, the concept of knowing presupposes not only the existence of the object being known but also of the subject doing the knowing. This interplay explains why the definition of knowledge incorporates the subjective element of belief. Consequently, while the notion that knowledge is a form of belief might initially seem counterintuitive, it holds validity in this context. 

Moreover, conceptualizing research as an updating of beliefs aligns closely with actual research practices. For instance, the experimental validation of a hypothesis reinforces our belief in its truth or falsity. Our confidence in a hypothesis increases as it withstands various rounds of verification. This process of iterative validation and belief reinforcement mirrors the concept of research as a continual renewal of beliefs.

Finally, since the justification in research is expected to be truth-conducive, the knowledge thus produced would have an objective quality. Therefore, in conjunction with the discussion in the previous section, it seems that the use of the subjective concept of belief is not that problematic.

% To know means we recognizing some truths or patterns of this world. In other words, the concept of knowing fundamentally presupposes the existence not only the known object but also the knowing subject. This is why the definition of knowledge involves the subjective concept of belief. Therefore, while the idea that knowledge is belief may seem counterintuitive, it appears valid in this sense. Particularly, since justification in research should be truth-conducive, the knowledge produced would be objective. In this sense, using belief, which is a subjective concept, to define research does not seem to be much of a problem.

% Moreover, viewing research as the updating of beliefs does not seem too far removed from the practice of research itself. For example, the validation of a hypothesis by an experiment would strengthen our belief that the hypothesis is true or false. We become more convinced of its validity as a hypothesis survives repeated various verifications. This research practice appears to be well aligned with the view of research as a renewal of beliefs.

\subsubsection{Knowledge for Humans}
As previously discussed, research is a pursuit dedicated to uncovering the unknown truths of the world, necessitating that the knowledge it generates be novel. This raises the question: what constitutes new or unknown knowledge?

Under the current definition, knowledge is a justified belief regarding the truth or falsity of a certain hypothesis. Thus, unknown knowledge could be a state where such a belief is either non-existent or, if it exists, lacks justification. In simpler terms, within this framework, the state of certain knowledge being unknown is essentially a state of belief.

Given that the concept of knowing is contingent on the knowing subject, the notion of the unknown is also inherently subject-dependent. In the realm of research, the term ``subject'' has seemingly encompassed humanity at large. Researchers do not deem knowledge as unknown simply because it eludes an individual; it is regarded as truly unknown only when it is beyond the collective understanding of humanity. Consequently, the knowledge produced through research is expected to contribute to the collective understanding of human society. This is the reason why the term ``for society'' is included in the definition of research.

% As mentioned earlier, research is an endeavor aimed at revealing the unknown truths of this world, and the knowledge generated there must be novel. Then, what does it mean for knowledge to be new or unknown?

% In the current definition, knowledge is a justified belief about whether a certain hypothesis is true or false. Therefore, unknown knowledge could be a state where such a belief is not held at all, or even if it is held, it is not justified. In other words, under the current definition, the state of certain knowledge being unknown can be understood as a state of belief.

% Since the concept of knowing depends on the knowing subject, naturally, the concept of the unknown is also subject-dependent. In research, it seems that so far, this ``subject'' has referred to humanity as a whole. Researchers do not consider knowledge unknown just because a single individual is unaware of it. It is only when none of us know it that we consider it truly unknown. This is why it seems that the knowledge we create through research is required to be knowledge for all of humanity. These are the reason why it seems better to include ``for society'' in the definition of research.

\subsubsection{Knowledge for Non-Humans}

Since the act of knowing is subject-dependent, it is theoretically feasible to conceive of non-human knowledge and research by considering non-human agents as knowing subjects. Naturally, there is also the unknown for these non-human agents. Such knowledge and unknowns for non-humans can naturally differ from those for humans. Therefore, when referring to ``knowledge,'' ``unknown,'' or ``novel,'' it is necessary to specify for whom these concepts apply.

While this discussion might seem like mere speculation, the idea that machines might have a different scope of the unknown compared to humans has implications for realizing an artificial researcher. This is because it suggests that merely replicating current research methodologies in AI might not necessarily yield new knowledge for humans.

Research methods essentially have been developed to uncover truths unknown to knowing subjects. Therefore, an AI mimicking these methods might only reveal truths unknown to itself, which may not align with human knowledge gaps. If we want AI to conduct research autonomously, we must find a way to ensure it understands what is unknown to humans, not just to itself, and guide it to discover knowledge that is truly unknown in the human context.

This is just a preliminary discussion. It is hoped that further discussion will continue on how to realize them for developing research-capable AI

% Thus, to develop AI that contributes to human knowledge, we could use AI just as a tool to enhance human research or we should create some methods for AI to find unknowns relevant to humans.

% Consequently, if the objective is to develop AI that contributes knowledge for humans, several approaches could be considered. AI might be utilized as just a tool to augment human research, or new methodologies could be developed that enable AI to uncover unknowns specifically relevant to humans, rather than merely emulating human techniques. Alternatively, if AI is to conduct research autonomously, it may be necessary to instruct it on the areas of ignorance specific to human understanding. 





% If the act of knowing is dependent on the subject, then it's theoretically possible to consider non-human knowledge and non-human research by assuming knowing subjects to be non-human. 

% Although it might seem insignificant since most people desire AI that produces knowledge for humans, I believe the observation that what is unknown to a machine may differ from what is unknown to humans provides implications for what we should do to realize an AI capable of conducting research.

% When what is unknown differs between humans and machines, creating a machine that can research in the same way as humans may not necessarily produce new knowledge for humans. This is because some of the methods developed by humans are aimed at revealing truths unknown to themselves, and even if a machine can mimic these methods, it would only reveal truths that are unknown to the machine, which is not necessarily unknown to human.

% Considering this, if the goal is to create AI that produces knowledge for humans, then AI should either be used as just a tool to assist human research, develop new methodologies that discover the unknown for humans through machines rather than merely mimicking human methods, or, if the AI is allowed to research autonomously, there might be a need to teach it what is unknown to humans. These are merely a list of possibilities, but it is hoped that there will be further discussion in the future about whether these could truly become issues.

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Can Truth-Conducive Justification Be Developed by Non-Human Agents?}

% While beliefs are inherently subjective, research demands that justification be truth-conducive, thereby lending an objective character to justified knowledge. In essence, the truth value of a proposition, independent of personal belief, determines the justification of that belief.

I acknowledge that we cannot definitively ``prove'' our empirical verification methods to be entirely truth-conducive. Yet, given the myriad discoveries achieved through these methods, questioning their legitimacy seems to have little merit. If agents can thoroughly grasp and effectively apply these human-developed justifications, it is poised to uncover numerous unknown truths, a prospect few researchers would dispute.

Then, what about when the agent constructs its own methods of justification? Is it possible for an agent to construct new truth-conducive justification methods on its own, instead of just mastering human-developed methods? Humans have devised tools like statistical hypothesis testing to evaluate hypotheses; can AI similarly innovate unique methodologies? Even if it were possible, how significant would those be?

Our justification methods are founded on various premises, implying diverse interpretations of ``what constitutes a truth-conducive justification'' or ``what justification entails.'' These interpretations lead to multiple methods of justification even among humans \cite{otsuka2022thinking}. Consequently, when allowing artificial agents to autonomously develop justification methods, these agents must consider what can serve as justification, navigate value judgments regarding the nature and effectiveness of justification, and thereby conceive and select optimal methodologies.

This inquiry goes beyond mere philosophical speculation. Since the current justification methodologies have not been proved to be the optimal, the potential for superior methodologies exists in theory. Machines, unfettered by human cognitive limitations, theoretically possess the possibility to discover such methods. Importantly, truth-conducive verification methods does not essentially require human value judgments to evaluate their quality, thus, there is ample potential for machines to ``autonomously'' devise them. The feasibility, realization, and significance of these possibilities remain open for exploration and debate.

% Even though beliefs are indeed subjective, in research, justification is expected to be conducive to truth, thus making justified knowledge objective. That is, whether a proposition is true or not determines whether that belief is justified, regardless of what we think.

% I admit that we cannot ``prove'' that our empirical justification methods are strictly truth-conducive. However, considering the numerous discoveries we have made through them, it would be pointless to doubt the legitimacy of them. If AI can fully master and appropriately utilize these justifications developed by humans, it would be enough for them to uncover numerous unknown truths. Few researchers would likely doubt the importance of this.

% Then, what about when the agent itself constructs its own methods of justification? Is it possible for an agent to construct new truth-conducive justification methods on its own instead of just mastering human developed methods? Human beings, for example, have developed statistical hypothesis testing as a method for evaluating hypotheses, so can AI similarly develop its own unique methods for evaluating new hypotheses? Even if it were possible, how ``significant'' would those be?

% Our justification is based on several premises. This means that we make an interpretation of ``in what sense a justification is truth-conducive'' or ``what is justification'' in some sense, and depending on that interpretation, there actually exist multiple methods of justification even in the case of humans \cite{otsuka2022thinking}. Therefore, when allowing artificial agents to autonomously construct up to the method of justification, the agent is expected to make value judgments about ``in what sense a justification is truth-conducive'' and ``what is justification,'' conceiving and selecting the optimal method of justification. 

% This is not merely a philosophical inquiry. This is because, as long as we do not understand what constitutes the most truth-conducive justification, there is a possibility that better methods of justification may exist. Moreover, machines, not bound by cognitive constraints like humans, theoretically have the potential to discover such justifications. Particularly, the quality of a truth-conducive justification can be determined regardless of whether it involves humans or machines. Therefore, in the sense that its quality can be determined without human judgment, there is a possibility that machines could autonomously construct it. If this were to happen, it might enable the production of knowledge that humans alone could not have achieved. However, whether these are realistic, how they can be realized, and how significant they actually are, remains an open question.

\subsection{Conclusion}
In this section, I have discussed a provisional working definition of research. My initial premise was the intuitive belief that research is an endeavor aimed at generating new knowledge for a particular society. The discussion subsequently delved into a speculative inquiry into the idea that that knowledge is fundamentally a form of belief and that the production of knowledge is the updating of beliefs. Building on these ideas, I presented some conjectural insights of non-human agents doing knowledge production.

It is important to note that the definition proposed here serves merely as a starting point. A more comprehensive and nuanced understanding of research can be cultivated through the collective insights of philosophers, scientists, and practitioners across various fields. This collaborative approach will enable us to delve deeper into the definition of research and develop more robust and effective guidelines to realize an artificial researcher.

\section{Question, Hypothesis, and  Verification}
\label{section-question-hypothesis-verification}
In the preceding section, I briefly examined a preliminary conceptual definition of research and its implications. This section shifts focus to the widely acknowledged fundamental components of research: question construction, hypothesis generation, and hypothesis verification. 

The objective here is to advance the discussion beyond the somewhat too abstract considerations in the previous section. By dissecting these core elements, this section seeks to offer a more concrete exploration of what constitutes research and the prospects of machines engaging in research activities. 

\subsection{Question Construction}
\label{section-question-construction}
The first essential element in research is \textit{question construction}. To produce new knowledge, it is imperative to recognize what is unknown and strive to generate that elusive knowledge. This act of identifying the unknown for investigation can be considered as the process of questioning. Subsequently, formulating potential answers for these questions constitutes hypothesis generation. Essentially, research can be reinterpreted as the act of posing and answering to questions. Furthermore, since research inherently involves lots of uncertainty, the generation of multiple questions, beyond the initial research question, is a natural part of the process. That is, in the pursuit of confronting the unknown, question construction is an inevitable aspect of research.

There have been the studies to find research questions and challenges from academic literature \cite{lahav2022search,oppenlaender2023mapping,surita2020can}, generate ideas for future work \cite{wang2019paperrobot}, and identify research trends \cite{krenn2020predicting,krenn2022predicting}. However, enabling machines to autonomously generate research questions is less common. In the domain of question answering from natural language processing (NLP) research, tasks exist for generating questions \cite{pan2019recent,zhang2021review}, but these are motivated differently from generating research questions. Research on artificial curiosity for generating non-textual questions has been conducted \cite{schmidhuber1991possibility}, yet it doesn't generate research questions akin to a human researcher, as far as I know. Recent advancements in large language models (LLMs) have led to initial attempts at generating research questions \cite{liu2023creative,lahat2023evaluating}, but this area remains nascent.

While there are efforts towards automation as shown above, the number of these attempts are relatively limited compared to those for hypothesis generation and verification. The automation of question construction, or determining the underlying goals of such automation, is recognized as a key challenge in the field of research automation \cite{coley2020autonomousII,zenil2023,kitano2021nobel}. 

In this section, I start with a speculative exploration of the nature of questioning. This will be followed by a discussion of the open challenges in enabling an artificial agent to effectively pose research questions.





% The first element is \textit{question construction}. In order to produce new knowledge, one must be aware of what they don't know and strive to generate that unknown knowledge. This process of deciding the unknown to be investigated can be regarded as questioning. And generating the candidates of the answer for that question is hypothesis generation. That is, research may be rephrased as the act of posing questions and answering them. Moreover, as long as there is an attempt to reduce uncertainty, questions are necessary, and we generate multiple questions in the process of research other than the research question. Thus, in the act of research, which confronts the unknown, question construction is inevitable.

% In relation to efforts concerning the generation of questions by machines, there are studies aimed at discovering research questions and challenges from academic literature \cite{lahav2022search,liu2023creative,oppenlaender2023mapping,surita2020can}, and others focused on identifying research trends \cite{krenn2020predicting,krenn2022predicting}. However, efforts to let machines autonomously generate questions on their own are not as prevalent. In the field of question answering, there is a task for generating questions \cite{pan2019recent,zhang2021review}, but these studies have different motivations than generating research questions. There has been research on creating artificial curiosity to generate non-textual questions \cite{schmidhuber1991possibility}, but there is yet nothing that can generate research questions like a human. With the advent of large-scale language models in recent years, there have been attempts to generate research questions \cite{liu2023creative,lahat2023evaluating}, but this field is still in the early stage.

% While the attempts for automation exist, compared to the those for generation and verification of hypotheses, these efforts are limited. Automating the construction of questions, or setting the goal behind, is recognized as a challenge that needs to be addressed in research automation \cite{coley2020autonomousII,zenil2023,kitano2021nobel}. In this section, I would like to start by speculatively exploring what questioning would be. Then, I would extend the discussions to open problems to realize an agent to pose questions.

\subsubsection{What is Questioning?}
Asking questions is often characterized as an information-seeking behavior \cite{watson_2021,taylor1962process}. This behavior typically involves two distinct steps: firstly, recognizing an \textit{information need}, and secondly, undertaking actions to acquire the desired information \cite{wilson1997information,case2016looking}. While not all information-seeking behaviors necessitate linguistic expressions \cite{watson_2021}, in the context of research, queries are typically formulated in text. This textual formulation occurs between the stages of information need recognition and the initiation of information-seeking behavior. Specifically, in research, the process of question construction is generally understood as the journey leading to the formulation of such queries. Thus, for the purposes of this paper, question construction is regarded as the process culminating in the formulation of a query. The subsequent steps of information seeking are considered part of hypothesis generation and verification.

Recognizing an information need seems to involve at least two sub-processes: identifying the knowledge gap and deciding to address it (judging that the missing information is a ``need'').\footnote{
In this discussion, the process of recognizing an information need is described as initially identifying something as unknown and then deciding whether to formulate a question about it. However, the sequence of these steps is not fixed. For instance, one might first have a desire to know something and only afterward ascertain that it is indeed unknown. The critical aspect is that the process encompasses these two elements.
} Therefore, to enable an artificial agent to autonomously construct questions, it is necessary to consider how to imbue it with these capabilities. The following sections will delve into a speculative consideration and exploration of these steps.\footnote{
It is important to note that questions in research are not personal but societal in nature. This societal aspect may introduce slight variations in the question construction process. This point will be revisited later in the paper.
}


% Asking questions seems to be characterized as an information-seeking behavior \cite{watson_2021,taylor1962process}. The act of seeking information is considered to consist of two steps: recognizing an \textit{information need} and then taking action to acquire that information \cite{wilson1997information,case2016looking}. Not all information-seeking behaviors involve linguistic expressions \cite{watson_2021}, but in research, we always form a query expressed in text between the steps of the information need recognition and the onset of information seeking behavior. Especially, in research, the process of question construction generally seems to refer to the process leading up to this query formulation. Therefore, in this paper, we regard question construction as the process leading up to the query formulation. The subsequent process of seeking information will be treated as part of hypothesis generation and verification.

% The process of recognizing an information need appears to involve at least two sub-processes: recognizing the missing knowledge and deciding to fill it (judging that missing information is ``need'').\footnote{
% Here, I explained the process of recognizing information need as first determining something as unknown and then deciding if you construct question about the unknown. However, the order doesn't matter. For instance, there may be knowledge that you want to know first, and then you confirm subsequently that it is indeed unknown. What matters is that the process involves these two elements.
% } Therefore, to have an agent to autonomously construct questions, it would be necessary to consider how to instill these abilities to it. In the following sections, I will engage in speculative analysis and investigation of these steps.\footnote{
% Please note that the question in research is not a personal one, but a question for society. This difference can bring about slight variations in the process of constructing questions. I will touch upon this point again later.
% }

\subsubsection{Recognizing Unknowns}
Recognizing that certain knowledge is unknown typically involves an initial attempt to access that knowledge. This process usually entails referring to our personal knowledge base and, upon not finding the information, deeming it as unknown. For an individual, this knowledge base is essentially the memory stored within the brain. However, in the realm of research, the unknowns that researchers aim to elucidate are those unknown to a specific society, not just to an individual researcher. That is, a research-capable agent does not need to judge whether it is unknown to itself, but rather it can directly determine whether it is unknown to certain society. In this context, the knowledge base extends beyond the agent's memory to encompass societal knowledge sources, such as a collection of research papers.\footnote{
As mentioned earlier, something being unknown implies either the absence of a proposition or the presence of an unverified belief. Therefore, accurately determining the unknown from academic papers requires an assessment of whether each paper has been appropriately justified, meaning whether its verification processes are sound.
}

% \textcolor{red}{論文のコーパス（のグラフ表現とか）からまだ探索されていない領域を同定する研究は絶対あるので、載せる。あとは、論文の取得を自動でやってくる研究についてもここで述べる。}

As outlined in Section \ref{section-what-is-research}, for machines to generate new knowledge beneficial to humans, they must be capable of identifying what is unknown to humans, not to themselves. While this task might initially seem as straightforward as conducting a literature survey as humans do, the reality may necessitate more complex approaches. The specific requirements for achieving this goal merit further discussion.

An additional consideration arises regarding the reliance on a machine's judgment to determine what is unknown to us. If an AI has been pre-trained on an extensive corpus of scholarly papers, its judgment might appear credible. However, as previously mentioned, an AI's determination of unknowns does not necessarily coincide with human unknowns. Therefore, it is not certain whether it is appropriate to unconditionally believe that what AI has determined to be unknown is indeed unknown. This issue becomes increasingly pertinent and significant as AI amass more knowledge and enhance their capabilities.

% To recognize that certain knowledge is unknown to you, it seems necessary to first attempt to refer to that knowledge. It appears that when we refer to our own knowledge base and do not find the knowledge, we judge it to be unknown. For an individual, the knowledge base is the memory within the brain. On the other hand, the unknowns researchers wish to clarify are unknowns to a certain society. That is, a research-capable agent does not need to judge whether it is unknown to itself, but rather it can directly determine whether it is unknown to certain society. Therefore, the knowledge base can be not only its own memory but also the knowledge base of the society, e.g. a collection of research papers.\footnote{
% As previously mentioned, being unknown means that a proposition either does not exist or, even if it does, it is not accompanied by a justified belief. Therefore, it seems that in order to precisely determine unknowingness from academic papers, it seems to be necessary to judge whether each paper has been justified, that is, whether verification has been appropriately conducted. 
% }

% As stated in Section \ref{section-what-is-research}, if we want machines to generate new knowledge for humans, they must identify unknowns for humans, not for themselves. This might be as simple as conducting a literature survey, as previously mentioned, but it might require more than that. What is needed to achieve this seems to be a topic for further discussion.

% There is also a question as to whether we should consider something as unknown to us if a machine determines it to be unknown based solely on its own memory. Such judgment may sound reliable if the AI was pre-trained with all scholarly papers. However, as mentioned before, just because AI deems something unknown, it doesn't guarantee that it's unknown to humans. This topic would become increasingly realistic and important as AI accumulates more knowledge and becomes capable of handling more intelligent tasks.

\subsubsection{Deciding What Knowledge to Seek}
\label{section-deciding-what-knowledge-to-seek}
While we encounter numerous unknowns, we do not formulate questions for each one, as not all unknowns hold equal ``importance'' or ``interest.'' Instead, we construct questions for matters we are eager to understand. This process involves assessing the ``value'' of questions based on certain criteria to determine their worthiness of pursuit. For individuals, this can be a largely subconscious process. However, in research, this need not be an internal process, as long as that is the value judgments of questions.

Knowledge, in itself, is value-neutral. The ``value,'' ``significance,'' or ``goodness'' of knowledge is ascribed by its users. A noteworthy aspect here is that the criteria for determining ``value'' are subjective and arbitrary. Hence, if we aim for artificial agents to autonomously pose questions meaningful to humanity, it is crucial to identify what constitutes ``good'' or ``significant'' questions for us and instill these values in the agents.

On the other hand, it is also vital to recognize that certain questions deemed ``unimportant'' by us may actually hold importance under different criteria. Fundamental research, for example, often yields knowledge initially perceived as ``useless'' but later proves pivotal for innovations. Human cognitive limitations may sometimes hinder our ability to fully appreciate the potential utility of such knowledge. Moreover, social factors unrelated to the initial purpose of knowledge production can influence our value judgments, implying that these human judgments are not always optimal.

Given that machines are not inherently limited by such constraints, they could theoretically make more effective value judgments. Therefore, while providing some guidance to ensure that the generated question is relevant to humans is crucial, developing agents capable of autonomously constructing these value criteria themselves may also be fruitful. How to achieve this forms a significant open challenge in developing research-capable agents.\footnote{
Kitano has described the approach where humans apply their value judgment criteria to determine questions and hypotheses as \textit{value-driven science} \cite{kitano2021nobel}. He advocates for the advancement of \textit{exploration-driven science}, which prioritizes extensive and comprehensive exploration. While a completely value-neutral exploration is unattainable, the notion of employing diverse and extensive criteria is indeed significant for the future of research. By embracing a wider range of criteria, we can expand the exploration space of knowledge.
}

% We do not always formulate questions for everything we don't know since not all unknowns are equally ``important'' or ``interesting'. Instead, we construct questions for things we wish to know the answers to. This means that we assess some ``value'' of questions using some criteria to determine if it is worth pursuing. For individual, this can be an unconscious internal process, but for research, this doesn't need to be so as long as it is some value judgment process.

% Knowledge in itself is value-neutral. The ``value'', ``significance'', or ``goodness'' of knowledge is determined by those who using it. The crucial point here is that the criteria for determining ``value'' are arbitrary. Therefore, if we want agents to autonomously pose questions that are meaningful to humanity, we should recognize what is ``good'' or ``significant'' questions for us and instill and make them adhere to such values. 

% However, we should also be mindful that there might be questions that we would judge as ``unimportant'' but are actually ``important'' under some criteria. For instance, there is a myriad of knowledge born from fundamental research that, at first glance, might seem ``useless'' but actually leads to later innovations. Due to human cognitive limitations, there might also be instances where we cannot fully assess the utility of that knowledge. Additionally, in human society, sometimes social factors unrelated to the original purpose of the knowledge production influence value judgments. That is, our value judgments are not necessarily always optimal.

% Since machines are not bound by such constraints in theory, there's a possibility they can make better value judgments. Therefore, while it might be essential to provide some minimal guidance to ensure they generates questions meaningful to humans, it would be good to aim for the development of agents that can autonomously construct good value criteria by themselves. How to create such agents seems to be one of the important open problem in building an agents capable of research.\footnote{
% Kitano referred to the science in which humans adopt their own value judgment criteria to determine questions and hypotheses as \textit{value-driven science} \cite{kitano2021nobel}. He argued that advancing \textit{exploration-driven science}, which focuses on more comprehensive and thorough exploration rather than criteria based on specific human values, is important for societal development. Although a completely value-neutral system would be impossible, I agree with the idea that employing new and diverse criteria would matter for future research. By adopting more diverse and extensive criteria, we could expand the exploration space of knowledge.
% } 

\subsubsection{Origin of Information Need}
I previously outlined that question formation begins with the recognition of an information need. This leads to the question: what triggers the recognition of an information need?

The initiation of this process can be attributed to various factors. Some researchers may generate questions through logical contemplation aimed at achieving a specific goal. Others might identify questions upon noticing anomalies in experimental data or inconsistencies between theoretical assumptions and actual observations. Researcher also sometimes search questions that can be answered by techniques that you have. Furthermore, humans typically do not rely on a singular criterion for value judgment. Instead, multiple criteria are often intricately combined and weighted according to the context, culminating in a complex value assessment process. To develop an agent capable of autonomously constructing research questions as humans do, therefore, it appears necessary to create a system with a general methodology for questioning applicable across these diverse scenarios.

The process in humans that connects various factors to an information need, and the development of an agent capable of emulating this process, remains an open question. Researchers in the field of curiosity, which is broadly conceptualized as a ``drive state for information'' \cite{kidd2015psychology}, have been investigating this challenge. Curiosity is often characterized as a precursor to information need in information-seeking processes \cite{case2016looking}. In reinforcement learning, efforts to instill curiosity or knowledge-based intrinsic motivation in AI have been explored. Here, curiosity is defined in terms of novelty, information gain, or prediction error, and is considered a catalyst for exploration \cite{aubret2019survey}.

These efforts provide insights into implementing mechanisms that drive AI towards question formation. However, we are still distant from realizing a system that autonomously constructs research questions under complex value judgments, as humans do. A significant challenge lies in identifying the minimal input required for question generation; namely, while the minimal input is clear for hypothesis generation and hypothesis verification, it remains unclear for the construction of questions. Designing a complex, contextually adaptive internal driving force for questioning remains a significant hurdle. Identifying the prerequisites for an AI system with such a mechanism is an ongoing challenge.



% I explained that the question begins with the recognition of an information need. So, what causes the recognition of an information need (or the sub-processes of the recognition of unknowns and the judgment of value) in the first place?

% Various factors can be considered as triggers. Some people may generate research questions as they logically think about how to achieve a goal. Others might come up with a question upon noticing some anomaly while observing experimental data or realizing that there might be something wrong with the underlying assumptions based on a discrepancy between results deduced from some assumptions and actual observational data. Furthermore, in reality, humans do not evaluate based on a single criterion of value judgment. It seems that they combine these criteria in a complex manner, weighting them according to the situation, before arriving at a final value judgment.
% If one wants to create an agent that can autonomously construct research questions like humans, it seems necessary to develop an agent with a general methodology that can construct questions in any of these situations.

% How these various factors are connected to information need in humans, and how we can create an agent capable of this, remains open question. Researchers studying curiosity have been tackling this difficult problem. Curiosity, while it is difficult to precisely define, is viewed as \textit{a drive state for information} \cite{kidd2015psychology}. In this sense, curiosity can be considered as something that gives rise to an information need. Indeed, especially in the process of information-seeking, it is characterized as one of the precursors of information need \cite{case2016looking}. Efforts to instill curiosity \cite{schmidhuber1991possibility} or knowledge-based intrinsic motivation \cite{oudeyer2007intrinsic} in AI have been researched in the field of reinforcement learning. There, curiosity is formulated as novelty, information gain, or prediction error, and is perceived as something that encourages exploration \cite{aubret2019survey}.

% These efforts have provided guidelines on how to implement mechanisms that drive intelligence towards questions. However, we are still halfway to realizing a system that autonomously construct research questions under complex value judgments in various situations, as humans do. Especially, while a question becomes the minimum input in hypothesis generation, and a hypothesis in hypothesis validation, in question generation, it's unclear what the minimum input should be. Need to design a complex internal driving force adaptive in various situations seems to be a major difficulty for creating an autonomous research questioner. Identifying what is necessary to realize such AI is an open problem.

\subsubsection{Examples of Criteria for Evaluating Research Questions}

Thus far, I have discussed abstract concepts related to questioning in general. Now, I will move on to focusing specifically on the characteristics pertinent to research questions.

The ``quality'' of a research question can be evaluated against various criteria. Here, I will briefly explore some examples to illustrate how humans seemingly appraise the value of a research question. It is important to note that these examples are only a few of the many criteria utilized and do not represent a comprehensive list. This discussion aims to contribute to a deeper understanding of how humans ascertain the value of a question.

One widely accepted criterion within the research community is that a question is important if it offers new perspectives, understandings, or conceptual advances, particularly those that challenge our common assumptions. For example, Alvesson and Sandberg emphasize the significance of such questions and discuss strategies for their construction \cite{alvesson2013constructing}. This criterion rests on the idea that a valuable question is one that significantly impacts our current knowledge. This seems to be a value that aligns with the highest-level objectives of the endeavor of research.

No matter how significant a question may be, if it is nearly impossible to address with current technology, deriving meaningful research outcomes from it may be unfeasible. Consequently, the feasibility of answering a question is considered a vital aspect of its quality \cite{hulley2007designing,alon2009choose,huntington2021effect}. Assessing feasibility involves complex decision-making, taking into account factors like available resources, researcher capabilities, deadlines, and technological constraints. An agent engaged in research would need the capacity for such multifaceted evaluations.

Another prevalent view is that research questions should stem from individual intellectual curiosity. Given that curiosity drives exploration \cite{oudeyer2018computational}, curiosity-driven research can foster exploration in the research theme space. Research can be seen as an exploration of the world's truths, making value standards that encourage exploration essential. However, curiosity is not the sole criterion for exploration; there may be better criteria for uncovering unknown truths. If agents can adopt value judgments on such criteria, it might surpass human efficiency in uncovering truths.

In contrast to bottom-up curiosity-driven research, questions that contribute to achieving specific top-down goals are also considered valuable. For example, in corporate or government-led research, questions aligned with predetermined objectives are prioritized. Since we expect that agents capable of autonomous research will contribute to human-set goals, ability to make such value judgments deemed important.

% Lastly, Alon posits that a good research problem is one that personally interests the individual and matches their difficulty level \cite{alon2009choose}.

In practice, the value of a research question is determined by integrating multiple criteria. Hulley et al. suggest that questions which are feasible, interesting, novel, ethical, and relevant (FINER) are considered valuable \cite{hulley2007designing}. Huntington-Klein argues that a good research question is one that is answerable and whose answer enhances our understanding of the world \cite{huntington2021effect}. As mentioned above, autonomous agents are also expected to determine the questions they should pursue based on such complex value judgments.

As emphasized, these criteria represent only a portion of the value judgments humans make in question formulation. Future discussions should further investigate the nature of these judgments, their role in scientific discovery, and how they can be replicated in artificial researcher.

% So far, I have discussed somewhat abstract topics related to questions in general. Now, I would like to discuss the characteristics related to research questions specifically. 

% The ``quality'' of a research question can be judged based on various criteria. I will introduce some examples from among them to make it clearer how humans seemingly have determined the value of a research question. Please note that the following examples are just a few of the many criteria humans use and are far from comprehensive. I hope this will aid in further deepening the discussion on how humans determine the value of a question.

% The idea that questions which would bring about new perspective or understanding, or \textit{conceptual advance}, especially which would overturn our common sense or underlying assumptions are important is widely accepted within the research community. As an example, Alvesson and Sandberg point out the importance of these kind of questions and discuss the strategies to construct them \cite{alvesson2013constructing}. 
% This criterion is based on the premise that a good question is one that produces knowledge which has a significant impact on our current body of knowledge.

% No matter how significant a question is, if it's nearly impossible to address with current technology, producing meaningful research outcomes from that question may be infeasible. Therefore, some argue that the feasibility of answering a question should be considered when evaluating its quality, with questions that are not overly implausible being deemed good ones \cite{hulley2007designing,alon2009choose,huntington2021effect}. To determine feasibility, it seems that complex decision-making is necessary, as it requires consideration of various factors such as the resources and funding currently accessible, the capabilities of the researchers, deadlines, and even the limitations of the technology currently available to humanity. An AI capable of conducting research would likely need to be able to make such complex decisions.

% The notion that research questions should be based on an individual's intellectual curiosity also seems to be widely accepted. Curiosity is the driver of exploration \cite{oudeyer2018computational}, so curiosity-driven research might have promoted exploration in the research theme space. Research can be seen as an exploration of the space of truths in this world, hence it sounds reasonable that value standards that promote exploration are important.
% To discover things that are so unknown they are not even known to be unknown, exploration is essential as an entire endeavor of research.
% Conversely, the criteria should not necessarily be curiosity as long as it promotes the exploration in the space of knowledge. The exploration may be merely a byproduct of curiosity, and there may exist better heuristics for exploration. If agents acquire such better heuristics or value judgement, they might be able to unravel truths more efficiently than humans have done.

% Contrary to research driven by bottom-up curiosity, the notion that questions contributing to the achievement of specific goals set in a top-down manner is valuable is equally common. For instance, for those aiming to realize human-like AI, questions about how to create elements deemed necessary for such AI would be significant for them, even if it is not interesting or incremental. Especially in corporate research or government-led research, there are likely many studies aimed at achieving goals set in a top-down manner. It is assumed that many people expect AI capable of conducting research autonomously to contribute to goals set by humans. Therefore, the ability of AI to make this kind of value judgment is an important requirement.

% Lastly, there is also a perspective that emphasizes the value for individual. Alon expresses the view that a good research problem is one that is interesting to the individual and has an appropriate level of difficulty for them \cite{alon2009choose}.

% In reality, instead of adopting just one of these criteria, we determine the value of the research question by comprehensively considering multiple criteria. For example, Hulley et al. suggest that questions that is feasible, interesting, novel, ethical, and relevant (FINER) should be considered good ones \cite{hulley2007designing}. Huntington-Klein presents the view that good research question is answerable and the answer to the question will improve our understanding of this world \cite{huntington2021effect}.

% As already mentioned, these are just a part of the value judgments that humans make in determining questions. I hope that future discussions will delve deeper into what kind of value judgments humans make, what function they serve in scientific discovery, and how we can realize these functions in AI.

\subsection{Hypothesis Generation}

The second integral element of research is hypothesis generation. Research inherently involves posing questions and endeavoring to answer them. Typically, researchers bifurcate the answering process into two phases: generating hypotheses and verifying them. Hypothesis generation entails predicting the answer to a posed question, while hypothesis verification involves examining the plausibility of that prediction. This two-stage approach is adopted because researchers address questions to which no one in this world knows the answer, making it challenging to immediately ascertain definitive answers. Therefore, the separation of hypothesis generation and verification represents a human-developed methodology for uncovering truths in a context of high uncertainty.

Hypothesis generation is often seen as a showcase of human creativity in research. The long-standing belief that human creativity defies analysis has led to the assumption that both question construction and hypothesis generation are inherently unanalyzable \cite{sep-scientific-discovery}. However, efforts to characterize this creative process began to emerge in the mid-20th century. Notable concepts include the role of abduction in generating hypotheses for ``why'' questions \cite{hanson1965patterns,magnani2011abduction}, the significance of analogical reasoning \cite{gentner2002analogy}, the interpretation of scientific discovery as a form of search problem \cite{langley1987scientific}, and the conceptualization of hypothesis generation as probabilistic sampling \cite{dasgupta2017hypotheses}.
% hesse1965models

The potential for machines to generate hypotheses has been a focal point in artificial intelligence research. Pioneering attempts to develop machines capable of hypothesis generation date back to the early 20th century \cite{langley1987scientific,lindsay1993dendral}. By the mid-2000s, advancements led to the creation of machines capable of making autonomous scientific discoveries \cite{king2004functional}.


% The second element is hypothesis generation. Research involves posing questions and attempting to answer them. Researchers often divide the process of answering these questions into two parts: generating hypotheses and verifying them. Generating a hypothesis is predicting an answer to a question, and verifying a hypothesis is the operation of checking whether it is actually plausible. Dividing the process of answering a question into these two stages is because research questions are such that no one in humanity knows the answers, making it practically difficult to hit upon the answer at once, and because an individual's thinking is not necessarily truth-promoting. In other words, the separation of hypothesis generation and verification is a methodology developed by humans to reveal the truth of this world under very high uncertainty.

% The generation of hypotheses has been recognized as a place where human creativity in research is exhibited. The idea that human creativity cannot be analyzed has led to the long-held view that constructing questions and generating hypotheses are difficult to analyze \cite{sep-scientific-discovery}. However, attempts to characterize this creative activity have emerged since the mid-20th century. For instance, the importance of abduction in generating hypotheses for why questions \cite{hanson1965patterns,magnani2011abduction}, the importance of analogical reasoning in hypothesis generation \cite{hesse1965models,gentner2002analogy}, the interpretation of scientific discovery as exploration \cite{langley1987scientific}, and the formulation as probabilistic sampling \cite{dasgupta2017hypotheses} have been pointed out. Hypothesis generation by machines has been one of the greatest interests since the advent of artificial intelligence research, and attempts at its realization have been made early on. As early examples, the development of machines that generate hypotheses was attempted as early as the 1900s \cite{langley1987scientific,lindsay1993dendral}, and by the mid-2000s, machines capable of autonomously making scientific discoveries were developed \cite{king2004functional}. 

\subsubsection{Hypothesis Generation and Machine Learning}
Generating hypotheses is predicting answers to questions from existing knowledge. This process aligns closely with machine learning, particularly question-answering. As it involves predicting answers that even nobody knows, it can also be viewed as a prediction under significant distribution shifts.

Indeed, machine learning have become increasingly prominent in scientific hypothesis generation \cite{xu2021artificial,zhang2023artificial,wang2023scientific}. Predicting protein structures \cite{jumper2021highly}, new materials \cite{merchant2023scaling}, and drug candidates are all examples of hypothesis generation.\footnote{
Since there are a vast number of studies, I will skip the introduction of individual studies here.
}

The sources for hypotheses, the nature of the hypothesis space, and the representation of hypotheses differ across research fields. For instance, hypotheses can be represented combinatorially, and machines can be employed to explore these spaces to find hypotheses \cite{coley2020autonomous}. Some studies represent hypotheses as symbolic equations and try to discover them from scientific data \cite{kramer2023automated}, while others endeavor to generate or extract textual hypotheses from academic papers \cite{kang2022augmenting,chan2018solvent,wang2023learning,xu2023exploring,yang2023large}. The advent of LLMs has spurred efforts to generate hypotheses from the models' internal knowledge, without relying on direct information from academic papers \cite{park2023can,ai4science2023impact}.

While the specifics of hypothesis generation vary, a unified description can be drawn from certain perspectives. Viewing the hypothesis space as a human-defined and fixed entity, scientific discoveries can often be framed as search problems \cite{coley2020autonomous}. 
Since the hypothesis space is often combinatorially vast, strategies for efficient exploration in the space deemed necessary \cite{coley2020autonomousII,zenil2023future}, and efforts have been made to optimize exploration with techniques such as active learning. As another perspective, Wang et al. provide a categorization of how AI is utilized in scientific hypothesis generation, highlighting its applications in black box prediction, aiding hypothesis space exploration, and finding solutions within a differentiable hypothesis space \cite{wang2023scientific}.

As such, integration of machine learning to hypothesis generation has progressed significantly compared to question formulation and hypothesis testing. The examples cited here represent only a segment of the extensive research in this area. Although this paper cannot delve into each study in detail, those interested are encouraged to refer to survey papers in their respective fields.

While machine learning's application in hypothesis generation is notable, the development of AI capable of generating complex hypotheses in response to varying questions remains a challenge. Achieving such capability may require abilities to generate hypothesis in versatile and flexible manner and to construct hypothesis spaces themselves. Future discussions are expected to further explore how to realize these capabilities in AI.

% Generating hypotheses involves predicting answers to unknown questions from existing knowledge. This can be seen as making predictions about unseen data from data already seen, and can thus be reduced to the formulation of machine learning. In particular, since it involves answering a question, it can be directly equated to the question-answering tasks in machine learning. Furthermore, as it involves predicting answers that nobody knows, it can also be viewed as a machine learning prediction problem in situations with significant distribution shifts.

% Indeed, machine learning models are widely used for hypothesis generation in science \cite{xu2021artificial,zhang2023artificial,wang2023scientific}. Examples include predictions of new proteins, drug candidates, or new physical properties. All such scientific discoveries made without the verification of machine learning models can be interpreted as applications of machines in scientific hypothesis generation. The specific methods of hypothesis generation in each application vary greatly, but they all share the function of generating hypotheses in the process of knowledge creation.

% What is used as the basis for generating hypotheses, the nature of the hypothesis space, and how hypotheses are expressed, vary across research fields. For instance, hypotheses may be generated from papers, scientific data, or a predefined search space. They might be expressed as combinations of multiple elements, as mathematical models represented by equations, or in text form. In chemistry, for example, hypotheses are often combinatorially represented, and the discovery of hypotheses by machines has been attempted by exploring this chemical design space \cite{coley2020autonomous}. Research has been conducted to find symbolic equations that describe the laws behind scientific data \cite{kramer2023automated}. There are also many studies that generate or extract hypotheses as text from groups of papers \cite{kang2022augmenting,chan2018solvent,wang2023learning,xu2023exploring,yang2023large}.

% In recent years, with the rise of large-scale language models, there have been efforts to generate hypotheses solely from the internal knowledge of the language models, without directly providing information from papers \cite{park2023can,ai4science2023impact}.

% While the specifics of individual hypothesis generation vary, it is possible to uniformly describe them to some extent from a certain viewpoint. For example, if we assume that the hypothesis space is provided and fixed by humans, we could say that many scientific discoveries can be seen as search problems \cite{coley2020autonomous}. Especially in science, the hypothesis space is often combinatorially vast. Therefore, it is considered important to efficiently explore such vast search spaces \cite{coley2020autonomousII,zenil2023future}, and attempts have been made to achieve efficient exploration through methods like active learning. As an another perspective, Wang et al. have organized studies applying machine learning to hypothesis generation. They have categorized and organized how AI is being used for scientific hypothesis generation from the perspective of using it for black box prediction, aiding in the exploration of hypothesis space, and finding solutions in a differentiable hypothesis space \cite{wang2023scientific}.

% As such, the application of machine learning to hypothesis generation has progressed significantly compared to question formulation and hypothesis testing. The examples mentioned here are just a fraction of the extensive research that uses machine learning for hypothesis generation. Although this paper cannot delve into each study in detail, those interested are encouraged to refer to survey papers in their respective fields.

% There are indeed numerous instances where machine learning has been applied to hypothesis generation. However, how to realize AI that can generate hypotheses in response to questions remains an open question. To achieve such AI, as mentioned earlier, it may be necessary to appropriately switch the expression and design methods of hypotheses according to the question, or to design the hypothesis space from scratch. Further discussion on how to realize these capabilities is expected to deepen in the future.


\subsubsection{Speculation on Key Aspects of Hypothesis Generation by Machines}
It can be said that autonomous hypothesis generation in general manner by AI has already gained considerable attention, compared to question generation and hypothesis verification. That's largely because, as previously mentioned, predicting answers to questions is a problem already central to many machine learning researchers. Therefore, many challenges in aiming for AI that generates hypotheses as flexibly as humans overlap with the challenges of pursuing an artificial general intelligence (AGI). These include systematic thinking such as deduction, out-of-distribution generalization, causal inference, efficient exploration, and problem decomposition, all crucial for autonomous flexible hypothesis generation and considered fundamental in the pursuit of AGI as well.

In this section, I will preliminary explore elements deemed important for AI's ability to generate hypotheses. However, due to the circumstances mentioned in the previous paragraph, this discussion might intersect with existing debates in the realm of AGI, potentially lacking novelty. Nonetheless, I will explore two aspects that appear vital for the development of an artificial hypothesis generator.

Firstly, it's important to note that even AI might not know the answers to the research questions. It's not always true that a question unknown to humans is also unknown to machines, as has been repeatedly emphasized. However, once the answer is unknown to both humans and the machine, hypothesis generation can be a challenging task even for AGI. I acknowledge that this is essentially a problem of out-of-distribution generalization, but it's particularly challenging because no agents in this world know the answer. To solve such problems, machines, like humans, may need to recognize their ignorance of the answer, reduce uncertainty step-by-step, and gradually approach the answer. Current AI still does not even understand what it doesn't know \cite{guo2017calibration,maynez2020faithfulness}. How AI capable of reasoning under such high uncertainty can be realized remains an open question.

Secondly, the role of mathematics in hypothesis generation cannot be overstated. The first point to note is that the power of mathematics in hypothesis generation lies significantly in its deductive nature. Deduction ensures that if the premises are true, the resulting conclusions are also true, even if they may seem counterintuitive. This aspect gives AI, which largely depends on experiential inferences, a substantial advantage. Furthermore, as humans do by the hypothetico-deductive method, deduction enables the evaluation of hypotheses that are not directly testable. If deductive results are rejected, the hypothesis is deemed false; acceptance, conversely, strengthens its plausibility. This plays a crucial role in expanding the empirical knowledge boundaries in research. 

The abstract nature of mathematics is also important. Since ancient times, even before the formalization of deductive methods, mathematics engaged with concepts such as numbers, which are fundamentally abstract and have long captivated human interest \cite{david2010history}. The introduction of symbolic representation and manipulation has further amplified its abstract nature. Significantly, mathematics not only abstracts real-world objects but also engages in a cycle of further abstraction. By abstracting already abstracted concepts, it has developed highly sophisticated systems \cite{bochner1968role}. This level of abstraction allows for the reference to subjects not directly experienced, facilitating the progress in science \cite{heisenberg2008abstraction}. 

These characteristics render mathematics an indispensable tool in the process of hypothesis generation. AI capable of doing mathematics has not yet been realized, but related research attempts have made steady progress \cite{rabe2021towards,imani2023mathprompter}.

While these two elements are discussed separately, systematic thinking seems necessary for both, reinforcing the widely acknowledged importance of systematic or high-level thought in AI development. However, due to the extensive existing discourse on this topic \cite{goyal2022inductive}, I will not delve deeper into it here.

Due to my limitations, this paper only scratches the surface of this topic. I would appreciate any feedback from those with insights into elements not widely recognized in the machine learning community but deemed essential for autonomous hypothesis generation.

\subsection{Hypothesis Verification}
The final critical element in the research process is the verification of hypotheses. We justify our belief in the truth or falsehood of a hypothesis by confirming the plausibility of our prediction in response to a question through verification. Thus, verification is essential for generating knowledge.

Verification hinges on the nature of the question and hypothesis posed. For instance, a ``why'' question demands verification methods that elucidate causal relationships. Questions about the physical world require empirical interaction for verification. In cases where hypotheses are amenable to mathematical proof, such proof constitutes verification. This necessitates an agent capable of verification to possess an understanding of what constitutes verification and to develop suitable verification methods tailored to the specific question and hypothesis.

While there has been extensive discussion on AI in hypothesis generation, its involvement in verification is less explored. Certainly, some studies have utilized AI in aspects of verification, such as experimental design \cite{chaloner1995bayesian} and scientific simulations \cite{baker2019basic}. However, initiatives enabling AI to fully comprehend and independently execute verification processes akin to human scientific research are still limited. 

In machine learning, research focusing on the validation of scientific claims \cite{wadden2020fact}, factual accuracy of predictions \cite{guo2022survey}, evidence search to support hypotheses \cite{koneru2023can}, and self-verification of machine responses \cite{dhuliawala2023chain} aligns with aspects of verification. Nevertheless, none of them aim to construct and execute verification as humans do in a scientific research. The automation of peer review \cite{kousha2022artificial,lin2021automated1} is also related to verification in the sense that it demands judgment on the validity of the verification, but it does not generate verification.

In this section, I aim to delve into the concept of verification to stimulate further contemplation. Having already addressed the nature of verification, or justification, in Section \ref{section-what-is-research}, I will omit that discussion here. Instead, I will focus on experimentation, an essential aspect of human-like verification in scientific inquiry.


% Compared to hypothesis generation, there's less discussion about letting AI itself perform verification. While there have been many studies utilizing AI for parts of verification tasks, such as experimental design \cite{chaloner1995bayesian} and simulations in science \cite{baker2019basic}, initiatives that make AI understand what verification is and think from scratch about what needs to be done to verify hypotheses are still not widespread. Certainly, in machine learning research, studies on judging the validity of scientific claims \cite{wadden2020fact}, confirming whether predictions are factual \cite{guo2022survey}, searching for evidence to support hypotheses \cite{koneru2023can}, and studies making machines self-verify their answers \cite{dhuliawala2023chain} are strongly related to verification, but none of them aim to construct and execute verification like human scientific research. The automation of peer review \cite{kousha2022artificial,lin2021automated1} is also related to understanding verification in the sense that it demands judgment on the validity of the verification proposed in papers, but it does not generate verification.

% In this section, I will briefly explore the concept of verification to provide seeds of thought. Since I have already discussed what verification, i.e., justification, is in Section \ref{section-what-is-research}, I will skip that discussion here. Instead, in this section, I will discuss experimentation that is inevitable when conducting human-like verification in science.

\subsubsection{Experimentation}
\label{section-experimentation}
No researcher would deny the importance of experiments. An experiment involves the planning and execution of a series of procedures to empirically test a hypothesis, essentially constituting the process of verification in empirical science. Therefore, any agent capable of verification must necessarily possess the ability to conduct experiments.

In experiments, phenomena that are difficult to observe, or the effects of various conditions, are precisely investigated. This is achieved by artificially generating phenomena in a controlled manner and actively intervening in them \cite{radder2009philosophy}. Such interventions create differences in the relationships and causal connections of the variables of interest. These variables are observed and recorded as experimental data, and subsequent analysis of the data determine the validity of the hypothesis.\footnote{
Experiments are not conducted solely during the verification phase but also when generating hypotheses. Furthermore, new questions and hypotheses are often formulated based on the results obtained from experiments. In these instances, the process leading up to data generation, or conducting experiments not solely for verification but for data generation and some form of data analysis, seems to be what is referred to as an experiment. This paper defines an experiment as the planning, preparation, data generation, analysis, and determination of verification results. However, be aware that this definition may not always reflect actual practice.
}

To conduct an experiment, one must first design it, document the procedures, and plan its execution. This requires an understanding of what constitutes a successful hypothesis test and the ability to devise methods to realize this using existing technology. Preparations for the experiment are also essential. These preparations can include purchasing chemicals, preparing flasks, training animals, applying to ethics committees, constructing necessary equipment, and sometimes even building large apparatus like accelerators from scratch. Unfortunately, since research aims to uncover the unknown, constructing equipment from scratch for experiments is not uncommon in research. The autonomous execution of these preparations by a non-human agent from scratch seems almost infeasible.

After the preparation for the experiment is complete, the experiment is conducted according to the experimental protocol. This task also presents considerable challenges for autonomous machines. The reason is that even a single experiment requires a myriad of low-level operations such as grasping, cutting, carrying, mixing, moving, pouring, dispensing, washing, and opening lids. These operations need to be flexibly combined and executed according to the self-generated experimental protocol. An autonomous machine capable of conducting experiments must possess the ability to generate these operations flexibly in response to the experimental protocol.





% No researcher would deny the importance of experiments. An experiment is the planning and execution of a series of procedures to empirically test a hypothesis, essentially the verification itself in empirical science. Therefore, any agent capable of verification must necessarily be able to conduct experiments.

% In experiments, phenomena that are difficult to observe or the effects of various conditions are precisely investigated by artificially generating phenomena in a controlled manner and actively intervening in them \cite{radder2009philosophy}. This creates differences in the relationships and causal connections of the variables of interest. These are observed and stored as experimental data, and the analysis of this data determines whether the hypothesis is true or not.\footnote{
% Experiments are not only conducted during the verification phase but also when generating hypotheses. Moreover, new questions and hypotheses are often formulated based on the results obtained from experiments. In these instances, the process leading up to data generation, or conducting experiments not solely for verification but for data generation and some form of data analysis, seems to be what is referred to as an experiment. This paper defines an experiment as planning, preparing, generating data, analyzing it, and determining verification results. However, be aware that this definition may not always reflect actual practice
% }

% To conduct an experiment, one must first design the experiment, write down the procedures, and plan the experiment. This requires an understanding of what constitutes a successful hypothesis test and the ability to conceive of ways to realize this using existing technology. Preparations for the experiment are also essential. This can include purchasing chemicals, preparing flasks, training animals, constructing necessary equipment, sometimes even building large apparatus like accelerators from scratch, applying to ethics committees, and creating clean rooms. Unfortunately, since research aims to uncover the unknown, constructing equipment from scratch for experiments is not uncommon in research. The autonomous execution of these preparations by a non-human agent from scratch is considerably challenging.

% After the preparation for the experiment is complete, the experiment is conducted according to the experimental protocol. This is also very challenging for a machine to perform autonomously. The reason is that even for a single experiment, a myriad of low-level operations such as grasping, cutting, carrying, mixing, moving, pouring, dispensing, washing, and opening lids need to be flexibly combined to execute the experiment. An autonomous machine capable of conducting experiments needs the ability to generate these operations flexibly according to the self-generated experimental protocol.

\subsubsection{Automating Experimentation}
As we observe, the challenge of making a machine fully autonomous in planning, preparing, and executing experiments is considerable. Particularly, since the specific experiments to be conducted cannot be determined until questions and hypotheses are formulated, enabling a machine to autonomously conduct research from question construction demands the capability to accommodate many possible experimental scenarios. This, I believe, represents one of the greatest barriers to creating machines capable of autonomously conducting research.

Automating experiments is a daunting task, yet humanity has made steady progress in this area. In relation to the planning stage of experiments, the automation of exploring experimental conditions have a long-standing history, for example. Wang et al. have summarized these studies, which utilize AI to assist in experiment planning, research guidance, and generating observational data through numerical simulations \cite{wang2023scientific}.

Furthermore, there is an initiative known as \textit{laboratory automation} or \textit{self-driving lab} that aims to automate experiments, including their execution – an aspect previously mentioned as challenging \cite{holland2020automation,abolhasani2023rise}. A notable example is the research in genetics by King et al., who fully automated the cycle of hypothesis generation, verification, and the discovery of new hypotheses \cite{king2004functional}. Another example is the work of A.I. Cooper, which facilitated the use of experimental equipment by autonomous robots, similar to human researchers \cite{burger2020mobile}. These are just a few examples, and there is a vast number of studies in this field.

These examples illustrate efforts to autonomously drive the research cycle, encompassing hypothesis generation, planning and execution of experiments, and generation of new hypotheses based on experimental results. Such endeavors are referred to as the \textit{closed-loop} automation of scientific discovery \cite{zenil2023future}, representing a significant milestone in achieving high autonomy in research automation. Additionally, there are efforts to develop humanoid robots capable of conducting multiple different experiments with a single robot, considered a foundational step towards more generalized research automation \cite{yachie2017robotic}.

In recent years, there have been efforts to explore possibilities of autonomous experiment using LLMs \cite{boiko2023emergent,qin2023gpt,charness2023generation}. For instance, Boiko et al. developed an autonomous agent comprising multiple LLMs that successfully designed and executed complex scientific experiments \cite{boiko2023emergent}.

While we have primarily discussed experimental data generation process,  validation also requires interpretation of the data. Observation inherently involves theoretical underpinnings \cite{hanson1965patterns}. Hence, interpreting experimental data necessitates adequate prior knowledge. Some studies are focused on enabling machines to interpret scientific data by embedding physical prior knowledge, like symmetries, differential equations, and intuitive physics, into machine learning models \cite{hao2022physics,karniadakis2021physics}.\footnote{
Interpretation of scientific data is not solely for validation purposes. Thus, these technologies extend beyond just automating validation processes.
}

Various research efforts have significantly advanced the automation of experiments. However, it is also true that numerous challenges remain in realizing machines capable of autonomously conducting experiments. Coley et al. delve into these challenges in the automation of experimental and computational validations and the selection of experiments, while referring to studies on automated verification \cite{coley2020autonomousII}. They also point out the significance of removing hardware constraints to increase the automatability of research projects and reducing the costs associated with research automation \cite{coley2020autonomousII}.

Among these challenges, the development of robots capable of manipulating low-level actions as humans do, which is necessary to achieve a versatile automated experimental machine adaptable to diverse research tasks, is exceedingly challenging. 

% As we can see, making a machine fully autonomous in not only planning but also preparing and executing experiments is considerably difficult. Especially since what experiments should be conducted cannot be known until questions and hypotheses are formulated, enabling a machine to autonomously conduct research from the construction of questions demands the capability to accommodate all possible experimental scenarios. I consider this to be one of the greatest barriers in creating machines capable of autonomously conducting research.

% Automating experiments is a very challenging task, yet humanity has steadily made progress in this difficult endeavor. Related to the planning stage of experiments, for example, the efficiency and automation of exploring experimental conditions have a long history. Wang et al. have summarized these studies that utilize AI to assist experiments by research planning, research guidance, and generating observational data through numerical simulations \cite{wang2023scientific}. 

% Additionally, there is an initiative known as \textit{laboratory automation}, or \textit{self-driving lab} that attempts to automate experiments, including the execution of experiments, which, as mentioned earlier, is a challenging aspect \cite{holland2020automation,abolhasani2023rise}. A notable example is pioneering research in genetics by King et al., who fully automated the cycle of hypothesis generation, verification, and discovery of new hypotheses \cite{king2004functional}. Another example is A.I. Cooper, which enabled the use of the same experimental equipment as humans through autonomous robots \cite{burger2020mobile}. 

% These examples of initiatives aim to autonomously drive the research cycle, including hypothesis generation, planning and execution of experiments, and generation of hypotheses based on experimental results. Such initiatives are referred to as the closed-loop automation of scientific discovery     \cite{burger2020mobile,king2004functional}. This represents an example of achieving extremely high autonomy in the quest for research automation. Furthermore, there are efforts to develop humanoid robots for experiments, capable of conducting multiple different experiments with a single robot \cite{yachie2017robotic}. This is deemed to be a foundational step towards potentially general research automation. 

% In recent years, there have also been attempts to conduct experiments autonomously using LLMs \cite{boiko2023emergent,charness2023generation,qin2023gpt}. For example, Boiko et al. constructed an autonomous agent composed of multiple LLMs and let it autonomously conduct from designing to executing experiments, leading to successful performance on complex scientific problems \cite{boiko2023emergent}. 

% So far, we have primarily discussed the generation of experimental data, but to validate it, interpretation is necessary. Observation always entails some theory behind it \cite{hanson1965patterns}, and to analyze and interpret experimental data, sufficient prior knowledge is required. Therefore, there are studies focused on enabling machines to interpret scientific data by embedding physical prior knowledge such as symmetries, differential equations, and intuitive physics into machine learning models \cite{hao2022physics,karniadakis2021physics}.\footnote{
% The interpretation of scientific data is not always done solely for the purpose of validation. Therefore, these technologies are not limited only to the automation of validation processes.
% }

% Various research efforts have steadily advanced the automation of experiments. On the other hand, it's also true that there are still many challenges in realizing machines capable of conducting experiments autonomously. Coley et al. discuss these challenges in detail, focusing on the automation of experimental and computational validations and the selection of experiments, referencing studies on automated verification \cite{coley2020autonomousII}. In particular, to achieve a versatile automated experimental machine adaptable to various research tasks, robots that can manipulate low-level actions as humans do are necessary, which is exceedingly difficult to realize. Even short of this, efforts such as removing hardware constraints to increase the number of automatable research projects and reducing costs for research automation are also important \cite{coley2020autonomousII}.


\section{Additional Topics}

\subsection{Combining Question Formulation, Hypothesis Generation, and Hypothesis Verification}
Reflecting retrospectively on completed studies, it becomes evident that each study possesses its unique question, an accompanying hypothesis, and a process for verifying that hypothesis. Viewed from this perspective, research can be considered an endeavor that involves a sequence of constructing questions, generating hypotheses, and verifying these hypotheses, as classically described.

However, as we know, actual research is a highly complex, cyclical process of trial and error. Rarely do these tasks unfold as initially planned or occur just once in a single study. In practice, for instance, numerous questions and hypotheses might be generated even when formulating a single hypothesis, and not all of these lead to the final research outcome.\footnote{
The trial-and-error nature of activities is particularly significant in the context of discovery \cite{yanai2020hypothesis}.
} You will notice that even some major scientific discoveries throughout history were also made through these trials and errors \cite{hanson1965patterns,gribbin2022origin,whiteside1970before}.

Therefore, it is more accurate to view the construction of questions, the generation of hypotheses, and the verification of hypotheses as fundamental units for reducing uncertainty. In the research process, they are combined to gradually reduce the vast uncertainty inherent in the research endeavor. AI capable of conducting research is expected to master these flexible and complex operations. In this section, I will speculatively explore these characteristics of real research practice that have not been previously discussed

% I have been speculatively discussing the construction of questions, generation of hypotheses, and verification of hypotheses, which are the essential elements of research. Looking back at completed studies, we can indeed find that each study had its own question, a hypothesis for that question, and a verification for that hypothesis. From this perspective, it can be said that research is an endeavor consisting of the continuous process of constructing questions, generating hypotheses, and verifying hypotheses, as has been classically described.

% On the other hand, as you know, actual research is an extremely complex process of trial and error, and it is rare for these tasks to be done only once each in a single study as initially anticipated. In reality, for example, countless questions and hypotheses are generated even for formulating a single hypothesis, and not all of them necessarily lead to the final research outcome. 

% Thus, it is more appropriate to view the construction of questions, generation of hypotheses, and verification of hypotheses as basic operations to reduce uncertainty, and we combine them to reduce the huge uncertainty gradually in the process of research. Especially in the work of discovery like constructing questions and generating hypotheses, these trial-and-error nature is considered to be important \cite{yanai2020hypothesis}.

% To create an AI capable of conducting research, it seems essential to seamlessly integrate the construction of questions, the generation of hypotheses, and the testing of these hypotheses, enabling it to perform complex research practices. Therefore, in this section, we will focus on characteristics of research that have not been discussed so far and examine the considerations necessary for developing such an AI.

\subsubsection{Countless Questions, Hypotheses, and Verifications in a Single Research Process}
In the course of developing a single question or hypothesis, or in planning and preparing for a single verification, we generate countless questions and hypotheses, including implicit ones. Whether it's searching for problems, contemplating why a problem hasn't been solved, considering possible hypothesis candidates, planning verification, or doing anything else, we always pose questions and formulate hypotheses whenever dealing with unknowns or uncertainties. 

% Consider, for example, the approach to resolving an unresolved issue. We might ponder why this problem remains unsolved, or whether there are any studies addressing similar challenges. In seeking answers, we might consult literature or draw upon our own memory, hypothesizing that ``This could be the reason it hasn't been solved,'' or that ``That approach might be effective in solving the current challenge.'' We repeat this process numerous times to eventually construct a solution to the original question. Similarly, in planning verification, we implicitly ask many questions and formulate various auxiliary hypotheses.

We also conduct a form of verification, whether implicit or explicit, and with varying degrees of simplicity, to generate plausible hypotheses. Generating plausible hypotheses requires having sufficient grounds to believe in their validity. These grounds could include knowledge from our memory, insights from recently researched literature, opinions from other researchers, or a belief in the simplicity of natural laws. Furthermore, we might conduct simple tests or even preliminary experiments to assess their plausibility. All these function as verification for researchers to be convinced.

Agents capable of conducting research should autonomously generate numerous questions and hypotheses as needed, and select the more plausible hypotheses through simple verifications during the knowledge production process. These are inevitable as long as uncertainties exist. How to realize such flexible agents remains an open question.







% We generate countless questions and hypotheses, including implicit ones, for the purpose of creating a single question or hypothesis, or for planning and preparing for single verification. It appears that historically, some of the major scientific discoveries were also brought about through such a process \cite{hanson1965patterns,gribbin2022origin,whiteside1970before}.

% For example, when questioning how an unresolved issue can be solved, we might ask why this problem hasn't been solved so far, or if there are any studies of similar challenges being addressed. In response, we might consult literature or recall our own memory, hypothesizing that ``This could be the reason it hasn't been solved,'' or that ``This could be useful in solving the current challenge.'' We repeat this process innumerably to eventually construct an answer to the original question. Similarly, when planning verification, we implicitly pose many questions and formulate numerous auxiliary hypotheses.

% To generate a plausible hypothesis, there must be sufficient grounds to believe it is valid. These grounds could be knowledge from our own memory, descriptions from newly researched literature, opinions from other researchers, or some belief, such as natural law should be simple. In addition, to examine the validity of the hypothesis, we might try simple tests. We sometimes even conduct preliminary experiments to assess the plausibility of a hypothesis. In other words, each time a plausible hypothesis is generated, it undergoes a sort of verification, whether implicit or explicit, and to varying degrees of simplicity.

% In this way, to conduct research, we pose countless questions and hypotheses and conduct several simple  experiments to verify the plausibility of the hypothesis if necessary. We could say that research is a hierarchical composition of question construction, hypothesis generation, and hypothesis verification. 

% These numerous question, hypotheses and verification stem from the fact that research contains a lot of uncertainties and they are required for gradual reduction of these uncertainties. Therefore, agents capable of conducting research should autonomously be able to generate numerous questions and hypotheses as needed and choose more plausible hypotheses through simple verification during the knowledge production process.

\subsubsection{Operations Apparently Unrelated to Knowledge Production}
\label{section-countless-seemingly-unrelated-operations-to-knowledge-production}

Research comprises numerous operations that may initially seem unrelated to knowledge production.\footnote{
Latour's anthropological study of daily practices in laboratories aptly illustrates these realities \cite{latour1987science}.
} In Section \ref{section-experimentation}, we argue that such tasks are essential in the context of experimentation. Most researchers would concur that daily academic activities are primarily characterized by these operations.

The construction of questions, generation of hypotheses, and verification of these hypotheses represent the core aims and functions in the knowledge production process. To implement these functions, performing operations like those mentioned above and combining them effectively to achieve desired objectives is crucial. Appropriately integrating these varied operations poses a significant challenge, even when tailored to a specific research question \cite{coley2020autonomousII}. 
To develop an agent capable of autonomously executing the entire research process, starting from question generation, replicating the flexibility of human action is indispensable.

% Research consists of numerous operations that may seem unrelated to the production of knowledge at first glance. In Section \ref{section-experimentation}, we discussed that such tasks are necessary in the context of experimentation. While Latour illustrates these realities in his study \cite{latour1987science}, it should be undoubtedly clear to many researchers that daily academic activities are shaped by these operations, even without referring to such literature.

% The construction of questions, the generation of hypotheses, and the verification of these hypotheses are the goals we aim to achieve and functions in the knowledge production process, not their implementations. To implement these functions, it is essential to perform operations like those mentioned above and to combine them appropriately to achieve the desired objectives. Combining these various operations appropriately is a challenging task, even when specialized for a specific research question \cite{coley2020autonomousII}. If we aim to create an agent that can autonomously execute the entire research process, starting from generating questions, the ability to produce these actions as flexibly as humans would be essential.

\subsubsection{Discovering New Questions}

Researchers often begin with a specific question, only to discover an entirely unrelated question during their investigation. This new question, divergent from the original and its underlying purpose, can lead to a shift in research focus and potentially significant scientific breakthroughs. Given the inherent uncertainty in research, it is not unusual to encounter unforeseen developments. Consequently, this discovery and redirection of focus are not rare phenomena.

However, if an agent designed for conducting research were tasked with a singular objective, such serendipitous discoveries might be overlooked. This is because the agent, focused on its predefined goal, may disregard new questions not aligned directly with its initial objective, regardless of their scientific value. To facilitate the agent's identification of such unrelated questions, it may be beneficial to assign multiple objectives or a broader, overarching goal that accommodates both the original and emergent questions.

On the other hand, having a common high-level goal alone is not sufficient. For an agent to transition from its current question to a newly discovered one, it must be capable of evaluating which question is more valuable. The decision-making process regarding the value of a question, as discussed in Section \ref{section-deciding-what-knowledge-to-seek}, should encompass comparing multiple questions that share higher-order objectives. The development of such evaluative capabilities remains a challenging and open question.

% Researchers often set out to solve one question, only to find themselves discovering an entirely unrelated question in the process. This new question, unrelated to the original question and even its underlying purpose, may lead them to pivot their research focus and potentially make significant scientific discoveries. Since research is full of uncertainty, it's not uncommon to be unable to foresee everything from the start. Thus, this discovery and shift of question is not rare.

% If an agent capable of conducting research were tasked with achieving a single objective, such serendipitous discoveries might not occur. This is because any new questions it finds, no matter how intriguing or scientifically important, may not be directly relevant to achieving its predefined goal. Therefore, to encourage the agent to uncover such unrelated questions, it might be necessary to set multiple objectives or a broader high-level goal that encompasses both original and newly found questions. 

% Furthermore, it is not sufficient to just have a common high-level goal.
% To switch from the current question to a new one, the agent would need to evaluate which of the two questions holds more value. Therefore, as discussed in Section \ref{section-deciding-what-knowledge-to-seek}, the decision-making process regarding the value of a question should not only determine whether to ask a particular question but also be capable of comparing multiple questions, including those that share higher-order objectives. How to realize such capabilities remains an open question.

\subsubsection{Incorporating Feedback from Verification Result}

In research, it is uncommon that the initial hypothesis is the answer of the posed question. Typically, the process entails revising the hypothesis based on verification results and conducting subsequent rounds of testing. This iterative cycle of hypothesis revision and retesting is critical for scientific discovery. Therefore, an agent designed for conducting research should possess the ability to revise its hypotheses based on these outcomes of verification.

Efforts to automate scientific discovery, incorporating feedback from verification results, include studies in laboratory automation \cite{king2004functional} and automation with scientific workflow \cite{gil2022will}. These have significantly contributed to automating the hypothesis revision cycle.

Despite these advancements, challenges persist in developing machines that autonomously analyze and respond to verification results like humans. When verification results are negative, pinpointing the exact cause is complex. This complexity arises because verification relies on a web of implicit and explicit hypotheses, any of which could contribute to the result \cite{sep-scientific-underdetermination}. The cause might be the primary hypothesis, underlying premises, auxiliary hypotheses, observations, experimental instruments, or a combination of these. A research-conducting agent must be capable of discerning the likely cause among these numerous candidates. Although it seems that humans do this well \cite{ren2023autonomous}, it is a challenging task for machines to do this autonomously.

Moreover, appropriate interpretation of experimental data is essential. Interpretations can vary based on the researcher's beliefs, prior knowledge, theoretical framework, and expectations \cite{hanson1965patterns}. Thus, verification results may undergo multiple reinterpretations, each potentially altering the hypothesis in need of revision. Additionally, as previously mentioned, researchers sometimes derive entirely different questions from these results and may temporarily halt their research. Current machines have yet to match this level of complex interpretation and adaptability in handling verification results that humans exhibit. An ideal autonomous research agent would be expected to possess these capabilities.


% In research, it's not always common for the initial hypothesis to directly answer the question posed. Rather, the process typically involves revising the hypothesis based on the results of verification, followed by additional rounds of testing. This cycle of hypothesis revision and retesting is crucial in the journey toward finding answers to the posed questions, especially when seeking unknown answers, as mentioned earlier. Consequently, it seems necessary for an agent capable of conducting research to have the ability to revise its hypotheses based on the outcomes of these verifications.

% As attempts to automate scientific discovery in a closed-loop manner, taking into account feedback from verification results, there are studies based on laboratory automation \cite{king2004functional} and scientific workflow \cite{gil2022will}. Such research has made a significant contribution by automating the core scientific activity of revising hypotheses based on verification results.

% Despite such advanced examples, there still seem to be many challenges in realizing machines that can autonomously provide feedback from verification results like humans. For instance, when outputting feedback to a machine from verification results, what to reflect these results on and what to modify in response are mostly predetermined by humans. 

% In reality, when the result for verification were negative, identifying the cause of the result is not that straightforward. This is because the verification relies on numerous implicit and explicit hypotheses and all of them can be the cause of the result \cite{sep-scientific-underdetermination}. The cause may be the proposed main hypothesis, a premise behind the hypothesis, an auxiliary hypothesis, an observation, an experimental instrument, or all of them. An agent that can conduct research must identify which of these possibilities is the cause. Once the candidates for the cause are determined, the agent has to generate a more plausible hypothesis based on the results of verification, as we have discussed so far.

% Furthermore, to identify the cause, it would be necessary to appropriately interpret the data generated by experiments. However, what one reads from the data can change depending on the individual's beliefs, prior knowledge, theory, and what they expect to find \cite{hanson1965patterns}. Therefore, these verification results may be reinterpreted multiple times, and with each reinterpretation, the hypothesis that needs to be revised may change. Additionally, as mentioned in the previous section, humans sometimes come up with totally different questions based on verification results and stop the research for a while. Current machines still fall short of achieving these abilities of complex interpretation of verification results that humans are capable of. Ideally, agent capable of conducting research are expected to have such capabilities.


\subsection{Common Topics Across Question Formulation, Hypothesis Generation, and Hypothesis Verification}
In the preceding sections, I have speculatively examined various key elements integral to research and their interplay. In this section, I aim to delve into topics that are universally relevant to these elements. Additionally, I will address certain aspects that have not yet been explored in this paper. These topics have been selected for their potential to provide further insight into the broader discourse of research methodologies and autonomous research systems. 

\subsubsection{Language Models}
The rapid advancement of language models in recent years, as documented by Zhao et al. \cite{zhao2023survey}, has opened new frontiers in research. The future of research agents is undoubtedly intertwined with the insights provided by these models. This section explores various initiatives investigating the potential of language models in research.

Beginning with the transformative impact of the Transformer \cite{vaswani2017attention} and BERT \cite{devlin2018bert}, the concept of ``scaling law'' \cite{kaplan2020scaling} and ``foundation model'' \cite{bommasani2021opportunities} has catalyzed the development of large scale models pre-trained on extensive corpora. This has led to the creation of scientific language models like SciBERT \cite{beltagy2019scibert} and others \cite{cohan2020specter,singh2022scirepeval,nadkarni2021scientific,gupta2022matscibert,taylor2022galactica,azerbayev2023llemma,xie2023darwin,luo2022biogpt,yang2022gatortron,deng2023learning}. Given that scientific data is multimodal, attempts are emerging to construct general-purpose models using multimodal data \cite{li2023llava,tu2023towards,takeda2023foundation,nguyen2023climax}.

The development of GPTs, including GPT-3 \cite{brown2020language}, InstructGPT \cite{ouyang2022training}, and GPT-4 \cite{GPT4} and the advent of the web application called ChatGPT  \cite{ChatGPT} marked significant milestones. Their ability to perform various intellectual tasks has spurred research into their scientific applications. Emerging research examines the potential of LLMs, especially these GPTs, in various research fields, including the natural sciences \cite{ai4science2023impact,boiko2023emergent,qin2023gpt,bran2023chemcrow,white2022large,hatakeyama2023prompt,jablonka202314,guo2023can,zheng2023large,qian2023can,wysocka2023large,nori2023capabilities,wang2023large,singhal2023large}, mathematics and engineering \cite{bordt2023chatgpt,wu2023empirical,pursnani2023performance,zheng2023can,zhang2023automl,vijay2023prompt}, and social sciences \cite{koneru2023can,wang2023survey,bail2023can,ziems2023can,park2023generative,horton2023large,korinek2023generative,aher2023using}.

Additionally, there are efforts applicable to all research fields, which involve using GPTs for processing academic documents \cite{alzaabi2023chatgpt}. Some of them include paper search and reading \cite{elicit,scispace}, paper writing \cite{transformer2022can}, abstract generation \cite{gao2023comparing}, literature review generation \cite{aydin2022openai}, and peer review \cite{wexin2023can,liu2023reviewergpt,robertson2023gpt4}.\footnote{
Hosseini and Horbach discuss the influence of LLMs on the role of peer review \cite{hosseini2023fighting}.
}

The scope of applications of LLMs ranges from generating hypotheses to generating research questions finding research challenges \cite{liu2023creative,oppenlaender2023mapping,lahat2023evaluating}. Some studies even attempted to automate experimentation \cite{boiko2023emergent,qin2023gpt}. 

% The innovative capability of these models have generated considerable discussion within the scientific community \cite{birhane2023science}.

While this overview highlights some of the key developments, it is important to recognize that research and development in the field of language models are advancing rapidly. The potential applications for automating research are vast and constantly evolving, warranting further exploration and critical assessment of their impact on the scientific method.


% The rapid development of language models in recent years has led to numerous innovative achievements \cite{zhao2023survey}. It is unimaginable that future research agents will not utilize the insights of language models. In this section, I will look over some attempts at scientific discoveries using language models.

% Since the advent of the Transformer \cite{vaswani2017attention} and its successor BERT \cite{devlin2018bert}, it has become common to pre-train language models on large-scale corpora. In particular, with the introduction of the concept of a \textit{foundation model}, pre-trained models that can be used for many downstream tasks \cite{bommasani2021opportunities}, there has been an acceleration in efforts to construct such foundational models. In the field of science too, there have been attempts to create scientific language models pre-trained on scientific texts and to build foundational models for science \cite{beltagy2019scibert,singh2022scirepeval,nadkarni2021scientific,cohan2020specter,gupta2022matscibert,taylor2022galactica,azerbayev2023llemma,xie2023darwin,luo2022biogpt,li2023llava}. Moreover, as scientific data is not just textual but requires multiple modalities, there have been efforts to create scientific foundation models pre-trained on such multimodal data \cite{singhal2023towards,takeda2023foundation,nguyen2023climax}.

% When OpenAI developed GPT-3 \cite{brown2020language}, ChatGPT (GPT-3.5) \cite{ChatGPT}, and GPT-4 \cite{GPT4} (I will refer to them as GPTs), these models garnered significant attention for their ability to perform a wide range of intellectual tasks with considerable accuracy. Following this, there was an increase in research examining the scientific understanding of GPTs, as well as studies attempting to use GPTs directly for scientific tasks \cite{bordt2023chatgpt,white2022large}. Particularly, with the initiation of efforts to connect these GPTs to form pipelines or autonomous agents, studies also emerged that involved implementing scientific tasks through such agents \cite{wang2023survey}.

% There have been various attempts to use large language models for automating all processes of knowledge discovery across various fields. In terms of research areas, this includes applications in natural sciences  \cite{ai4science2023impact,bran2023chemcrow,white2022large,hatakeyama2023prompt,jablonka202314,guo2023can,boiko2023emergent,charness2023generation,qin2023gpt,zheng2023large,qian2023can,wysocka2023large,lee2023benefits,nori2023capabilities,wang2023large,singhal2023large,yang2022gatortron,deng2023learning,merchant2023scaling}, applications in mathematics and engineering \cite{wu2023empirical,pursnani2023performance,zheng2023can,zhang2023automl}, and applications in social sciences \cite{wang2023survey,bail2023can,ziems2023can,park2023generative,horton2023large,koneru2023can}. Additionally, there are efforts applicable to all research fields, which involve using GPTs for processing academic documents \cite{alzaabi2023chatgpt}. Some of them include paper processing \cite{elicit,scispace,van2023chatgpt}, paper search \cite{elicit,scispace}, paper writing \cite{transformer2022can}, abstract generation \cite{gao2023comparing}, literature review generation \cite{aydin2022openai}, and peer review \cite{wexin2023can,liu2023reviewergpt,robertson2023gpt4,hosseini2023fighting}. 

% In the process of automating research, there are examples ranging from models that generate hypotheses, to those that discover and create research topics and research questions \cite{oppenlaender2023mapping,lahat2023evaluating}, and even to those used in the entire research process, including experiments \cite{boiko2023emergent,charness2023generation,qin2023gpt}. The innovative performance of such language models and their rapid spread into scientific research have sparked much debate within the scientific community \cite{birhane2023science}.

% These are just a few examples of the use of language models. Furthermore, research and development on language models are progressing rapidly on a daily basis. It is hoped that further exploration will be made into the potential applications of these technologies for automating research.

\subsubsection{Incorporating Scientific Knowledge}

While discussing the challenges of enabling machines to conduct research, it's pertinent to acknowledge that even humans do not embark on research from a completely zero starting point. Firstly, humans are inherently equipped with brains and bodies evolved and developed for interpreting the world. Moreover, before engaging in research, we study the fundamental knowledge of the research fields. Thus, it would be reasonable to assume that agents should also possess basic world knowledge before they begin conducting research. The advancement of language models has brought a wealth of knowledge to machines, but it is still considered necessary for them to acquire the knowledge required for research.

This is embodied in the concept of \textit{physics-informed machine learning} \cite{karniadakis2021physics}, where biases and scientific knowledge are integrated into AI to process scientific data. Such biases might include handling partial differential equations, symmetry, and intuitive physics \cite{hao2022physics}. Karniadakis et al. \cite{karniadakis2021physics} and Hao et al. \cite{hao2022physics} provide a systematic overview of research in this domain. As previously discussed, imparting scientific knowledge through training on textual and multi-modal data is also a prevalent strategy.

Furthermore, just as humans continuously update their scientific knowledge, it's imperative for machines to not only embed knowledge through pre-training and inductive biases or retrieval during inference but also to continually update this knowledge. Specifically, it is crucial to acknowledge that knowledge produced by research is perpetually evolving. Thus, an agent must assimilate new knowledge, retain and update existing knowledge, and adapt to revisions in previously learned concepts. While the methodology for achieving this remains an open question, it is a subject of increasing debate \cite{kitano2021nobel,zenil2023future}.

% I have been discussing the challenges of enabling machines to conduct research, but it's important to note that in the first place it's nearly impossible even for humans to conduct research from complete zero. 

% In the first place, we humans inherently possess brains and bodies that are suited to thinking about this world, shaped through the process of evolution and development. Moreover, before conducting research, we study the academic field we are interested in and acquire basic knowledge in that area. Therefore, it would be reasonable to assume that agents should also have previously acquired fundamental knowledge about the world before it starts conducting research.

% The group of studies that incorporate such biases or scientific knowledge to handle scientific data on AI is called \textit{physics-informed machine learning} \cite{karniadakis2021physics}. The incorporated biases include the ability to handle partial differential equations (PDE), symmetry, and intuitive physics \cite{hao2022physics}. Karniadakis et al. \cite{karniadakis2021physics} and Hao et al. \cite{hao2022physics} systematically organize existing research in this field. As discussed in the previous section, efforts to impart scientific knowledge through pre-training on textual and multi-modal data also common.

% Moreover, we humans continue to update our scientific knowledge continuously through study parallel to research, even after initially learning the basics. It is important for machines not only to embed knowledge through pre-learning and functional biases or to search during inference, but also to continuously update their knowledge through such learning processes.

% Especially in the context of knowledge acquisition in research, it's crucial to recognize that the knowledge generated in research is always being updated. Therefore, an agent must not only assimilate new knowledge but also maintain the knowledge that has been generated, be aware of how previously learned knowledge is being revised, and reflect these modifications. While it still remains an open question, there are growing discussions on this topic \cite{kitano2021nobel,zenil2023future}.

\subsubsection{Autonomy, Generality, and Open-Endedness}

As previously emphasized, ongoing efforts are being made to enable machines to autonomously generate research questions, formulate hypotheses, and validate these hypotheses. However, the significant challenge remains in achieving this autonomy with minimal human intervention. Even in the realm of closed-loop research automation, which represents a substantial stride towards autonomy, full automation of all research processes is still an unrealized goal \cite{zenil2023,coley2020autonomous,coley2020autonomousII}.

This problem becomes particularly serious when attempting to enable machines to independently formulate research objectives, problems, and questions. If machines are to autonomously generate goals and questions, they must also be capable of independently generating and validating corresponding hypotheses. This necessitates a versatile approach to hypothesis generation and validation, adaptable to a wide range of questions.

In such scenarios, humans cannot provide predefined methods, potential hypotheses, or necessary information. Consequently, machines must be equipped to extract pertinent information from an open-ended environment, mirroring the human approach to hypothesis generation and validation. Research, in essence, is a process of seeking information from the vast outer world of scientific data and processing it within the agent's cognitive framework, as highlighted in \cite{hope2022computational}. Assuming an open-ended environment means minimizing human-imposed constraints on this outer world and allowing the agent maximum freedom in selecting and processing information from the outer world.

Given these considerations, the extent to which autonomy should be expected from machines and the level of constraints that can be imposed without stifling their potential for autonomous hypothesis generation and validation, remains a critical and open question.

% As repeatedly stated, attempts to make machines generate questions, hypotheses, and validate these hypotheses already exist. The challenge lies in executing these tasks autonomously by machines with as little human intervention as possible. Closed-loop research automation represents a highly autonomous attempt at automating research, yet even in such cases, it is said that full automation of all processes of science has yet to be realized \cite{zenil2023,coley2020autonomous,coley2020autonomousII}. 

% One of the biggest issues is to let machines autonomously generate even the objectives, problems, and questions of research by themselves \cite{coley2020autonomousII}. This is because, as repeatedly stated, if machines autonomously generate goals and questions, they must also autonomously generate and validate appropriate hypotheses in response. Therefore, machines must be able to execute hypothesis generation and validation in a versatile manner that can adapt to various scenarios.

% In such situations, humans cannot provide specific methods for hypothesis generation, potential hypotheses, or the necessary information in advance. Therefore, machines must be able to extract appropriate information from an open-ended environment, similar to the one humans operate in, to perform hypothesis generation and validation. Research can be understood as a process of searching for information from the outer world of scientific information and processing it in the agent's inner cognitive world, as described in \cite{hope2022computational}. Assuming an open-ended environment equates to minimizing human constraints on the scope of this outer world, and allowing the agent itself to decide as much as possible what to extract from that outer world.

% Considering these autonomy-related issues, how much autonomy should be expected of machines, and to what extent constraints can be set without overly suppressing the machine's potential capabilities for autonomous hypothesis generation and validation, remains an open question.


\subsubsection{Scientific Understanding}
While the primary focus of this paper has been on knowledge discovery, it's crucial to also consider another important goal of research: understanding. As Krenn et al. highlight, scientific discoveries can be made without understanding \cite{krenn2022scientific}, suggesting that facilitating scientific understanding in humans by automated machines demands more than the things discussed so far.

Scientific understanding in humans involves comprehending theories or hypotheses – both their nature and their underlying rationale. Therefore, an additional requirement seems necessary in the context of hypothesis generation. It remains unclear whether this pertains to the representation of generated hypotheses, the description of their generation process, or anything else. Identifying what is needed to be added in this process to foster scientific understanding, and how to implement it, is a significant issue.

Krenn et al. propose two conditions for AI to achieve scientific understanding: 1. the ability to recognize characteristic consequences of a theory qualitatively and apply them in new contexts, and 2. the capacity to transfer this understanding to human experts \cite{krenn2022scientific}.  As previously mentioned, the belief systems of humans and AI may differ. Thus whether AI having scientific understanding is necessary for bringing new scientific understanding to humans is unclear. Nonetheless, as per the second condition, the capability to communicate understanding to humans is essential for bringing scientific understanding to humans. The explanation of machine prediction results has already been extensively researched and discussed as explainable AI \cite{arrieta2020explainable}, and its importance has already been widely pointed out in AI for Science research, so I will not delve further into it here.\footnote{
In considering how machine-driven scientific discoveries can facilitate human understanding, it might be worth exploring not only the enhancement of machine capabilities but also the expansion of human cognitive boundaries. While delving into this might border on speculative, it's a discussion that could yield valuable insights in the scientific community.
}

% So far, I have mainly discussed scientific discovery, but I have barely touched upon another important goal in science: scientific understanding. Since scientific discoveries can be made without understanding \cite{krenn2022scientific}, bringing new scientific understanding to humans requires additional demands beyond what has been discussed so far.

% In humans, scientific understanding involves grasping theories, or hypotheses in this paper – what they are and why they hold. Therefore, among the elements of research I discussed, the additional demand seems to be necessary for hypothesis generation. Whether this demand concerns the representation of the generated hypotheses or the description of the process of generating them is unclear, but what additional requirements are needed in this process to bring about scientific understanding and how to realize them is an important issue.

% Krenn et al. propose two conditions for us to say that an AI gains scientific understanding: 1. it can recognize qualitatively characteristic consequences of a theory without performing exact computations and use them in a new context, and 2. it can transfer its understanding to a human expert. As previously mentioned, the belief systems of humans and AI may differ, so whether AI having scientific understanding is necessary for bringing new scientific understanding to humans is unclear, but it is expected to be more helpful if it does. In any case, for bringing scientific understanding to humans, it seems necessary to have the ability to transfer understanding to a human in some way, as suggested as the second condition above. The explanation of machine prediction results has already been extensively researched and discussed as explainable AI \cite{arrieta2020explainable}, and its importance has already been widely pointed out in AI for Science research, so I will not delve further into it here.\footnote{
% This might sound like a far-fetched conceptual idea, but to bring about human scientific understanding through machine-driven scientific discoveries, it might be worth considering not only improving the machine's capabilities but also expanding the range of human comprehension. I stop this discussion since it might lean towards not solidly grounded conjecture, but I believe it's worth discussion in scientific community.
% }

\subsubsection{Alignment}
Alignment is a critical concern in the development of autonomous AI researchers, akin to other areas of AI research. The primary concern is ensuring that these autonomous agents do not harm humans, a priority that becomes increasingly significant as we seek greater autonomy in machines. Given that knowledge is inherently value-neutral and can be used for benevolent or malevolent purposes, addressing this challenge is complex and necessitates ongoing discourse.

As previously discussed in Section \ref{section-question-construction}, alignment with human values and worldviews is crucial not only for safety but also for the relevance and effectiveness of AI-generated knowledge for humans. AI agents need to make value judgments aligned with human assessments of question quality and discern what is unknown and comprehensible from a human perspective, not just from their own standpoint.

These value judgments are often not explicitly stated in human-generated texts, indicating a need for proactive teaching of these values to AI. The methodology for implementing such teaching and ensuring alignment in a broader sense remains a complex issue that warrants further discussion and exploration.

This topic's complexity is amplified by the varying and evolving nature of human values and worldviews. As AI continues to advance, the challenge of continuously adapting these systems to align with human ethics and understanding becomes more pronounced. Future discussions should focus on developing robust frameworks and methodologies to achieve and maintain this alignment, ensuring that autonomous AI researchers contribute positively and safely to the scientific community.



% Similarly to other AI research, alignment is an important topic in creating autonomous AI researchers as well. First and foremost, it is necessary to ensure that autonomous researchers do not harm humans. The more autonomy is sought in machines, the more important this issue becomes. Particularly, since knowledge itself is value-neutral and can be used for good or ill, as mentioned earlier, this solving this issue challenging. This problem requires ongoing discussion.

% Furthermore, as I have repeatedly stated, aligning AI with human values and worldviews is important not only for safety reasons. For example, as mentioned in Section \ref{section-question-construction}, in order to produce knowle2dge meaningful to humans, agents also need to make value judgments aligned with human judgments about the quality of questions. Similarly, agents must judge what is unknown and what is comprehensible not from their perspective but from the human perspective. Especially, these value judgments are not always explicitly expressed in existing human-generated texts, and in that sense, there is a need to actively teach these value judgments. How this will be realized is a topic that should be discussed more in the future.


\section{Ideas for Prototyping}
Realizing an autonomous intelligent agent capable of conducting research is an exceptionally challenging goal, one that will likely require a significant amount of time to achieve. The challenges discussed so far represent merely the tip of the iceberg found in speculative discussions; undoubtedly, many more critical issues remain unidentified. Therefore, it is crucial to begin by identifying these unknown challenges. A practical starting point might be the development of a simplified prototype of a research-capable agent. Such a prototype would allow us to explore and understand the challenges inherent to our goal during the prototyping process. In this section, I aim to discuss, in a speculative and brief manner, what might constitute such prototyping.

% Realizing an intelligent agent that can conduct research is an exceptionally challenging goal that will likely take a long time to achieve. The challenges discussed so far are just the tip of the iceberg found in speculative discussions, and there are undoubtedly many more yet to be identified critical issues. Therefore, it seems crucial to start by identifying and addressing unknown challenges in the first place. A good starting point might be to develop a simplified prototype of an agent capable of research so that we can explore the challenges for our goal in the process of prototyping. In this section, I would like to discuss speculatively and briefly what could be considered as such prototyping.

\subsection{Prototyping Agents that Conduct Research}

\subsubsection{Requirements for Prototype}
As discussed in Section \ref{section-question-hypothesis-verification}, Research seems to involve constructing questions, generating hypotheses, and verifying these hypotheses. Therefore, it appears appropriate for this prototype to incorporate these functions as distinct modules. The ``question construction'' module should take any input and formulate a question. The ``hypothesis generation'' module would then take this question as input and generate a hypothesis. Subsequently, the ``hypothesis verification'' module would take the hypothesis and provide verification results. By flexibly combining these modules at various levels, the prototype could mimic the research process.

For the prototype agent to function autonomously, human involvement in its design, implementation, and intervention should be minimized. Consequently, each module should autonomously gather information from the open-ended world, similar to how humans acquire information for research, while requiring minimal inputs. This means the agent should interact with the physical or digital realms to gather necessary information for research.

Moreover, to ensure the system's generality, the internal workings of each module should not overly rely on specific research topics. For instance, a verification method like experimentation tailored for specific physics research would not be applicable to psychological research. The human-designed elements of each module should be minimal, confined to what is essential for the module's function.

Creating a system that simultaneously meets the criteria of autonomy and generality, while effectively constructing questions, generating hypotheses, and verifying them within this abstract framework, is impractical, even in simpler scenarios. Thus, it may be necessary to introduce some constraints to this abstract framework. Discussing the nature, necessity, and potential relaxation of these constraints could shed light on the challenges in realizing an autonomous research agent. To initiate this discussion, I will present some candidates for potential constraints.

% As discussed in Section \ref{section-question-hypothesis-verification}, research, I believe, consists of constructing questions, generating hypotheses, and verifying these hypotheses. Thus, it seems appropriate for this prototype to consist of these functions as modules. The question construction module takes any input and produces a question. The hypothesis generation module takes this question as input and produces a hypothesis. The hypothesis verification module takes the hypothesis as input and provides verification results. The prototype would conduct research by flexibly combining these modules at various levels.

% For the prototype agent to be autonomous, human design, implementation, and intervention should be minimized. Consequently, each module, aside from receiving minimal inputs, should autonomously gather information from the open-ended world, which humans interact with to get information for research. That is, the agent should interact with the physical world or the digital realm to get information necessary for research, as humans do.

% Furthermore, for the system to be general, the internal workings of each module mustn't depend too much on specific research topics. For example, if the verification method is an experimentation for a specific physics research, it can't be used for psychological research. The human designed inner workings of each module should be as minimal as possible, limited to only what is necessary for the function of each module. 

% Creating a system that meets both autonomy and generality requirements while properly constructing questions, generating hypotheses, and verifying them only with this abstract class is infeasible, even in simpler scenarios. Hence, it might be necessary to impose some constraints on this abstract framework. Discussing the extent of these constraints, why they're needed, and how they can be eliminated will help elucidate the challenges in realizing a autonomous research agent. In the following, I will list up some candidates for potential constraints to provide a first step.

\subsubsection{Candidate Constraints in Prototyping}

In Section \ref{section-what-is-research}, I discussed the perspective of research as a process of updating beliefs and the potential for autonomously constructing verification from foundational concepts, as well as autonomously assessing the value of questions in autonomous research. However, these concepts are visionary and present significant challenges, making it unrealistic to expect immediate, meaningful outcomes for humans through prototyping. Therefore, it would be beneficial to start by prototyping agents that can master existing human values and research methods.

As mentioned in Section \ref{section-question-construction}, formulating questions from open-ended situations is an exceptionally challenging task, often with even no clear starting point. A pragmatic approach would be to predetermine the inputs for question construction, rather than relying on unrestricted information sources. A viable input could be a high-level goal, commonly assumed in many studies. Specifically, it would be beneficial to start with high-level goals recognized as research objectives in specific research fields.

A significant obstacle in developing a fully autonomous research agent, as discussed in Section \ref{section-countless-seemingly-unrelated-operations-to-knowledge-production}, is the need for expertise in complex low-level actions. Developing a robot capable of free physical world interaction like humans remains a formidable challenge. Hence, for prototyping, focusing initially on research confined to computational environments appears more manageable. While creating an agent capable of operating freely within a computer environment is also challenging, it is arguably more feasible than one operating in the physical world. Indeed, there have been efforts to enable language models to perform various computer operations \cite{openinterpreter,openai_chatgpt_plugins_code_interpreter_2023}, and to operate web browsers \cite{nakano2021webgpt,act1}.

The primary objective of prototyping is to concretize a concept, however rudimentary, and to identify challenges. Thus, it seems prudent to initially limit the prototype's environment to the digital realm, while waiting for advancements in foundational research that could enable free activity in the physical world.

The ideas presented here are merely initial suggestions and are neither definitive nor exhaustive. In the prototyping phase, it is crucial to discuss the extent and nature of the constraints to be applied. More suitable constraints are likely to emerge as these discussions evolve.


% In Section \ref{section-what-is-research}, I discussed the view that research can be considered as updating beliefs. I also discussed the possibility of autonomously constructing verification from its foundational concepts and autonomously contemplating the value of questions when conducting autonomous research. However, these ideas are too visionary and challenging to expect immediate, meaningful results for humans by prototyping. Therefore, it seems desirable as a prototype to aim for agents that can master the values system and verification methods humans have built so far.

% As said in Section \ref{section-question-construction}, constructing questions from open-ended situations is a too challenging task where even where to start from is not evident. Therefore, it seems prudent to start by determining in advance what the input for constructing the question should be, rather than assuming the unrestricted information sources. A candidate for the input is a high-level goal since it is 
% assumed in many studies. Particularly, it would be desirable as a first step to provide high-level goals that are recognized as a research goal in a specific research field.

% One of the biggest bottlenecks in realizing a fully autonomous research agent is the necessity for excellence at complex low-level actions, as discussed in Section \ref{section-countless-seemingly-unrelated-operations-to-knowledge-production}. Especially, developing a robot capable of acting freely in the physical world like humans is an extremely challenging task. Therefore, for prototyping purposes, it seems reasonable to first consider research that does not require interaction with physical world but is confined within a computer. Of course, realizing an agent that can freely operate within a computer is also a very challenging issue, but it seems more feasible than an agent freely operating in the physical world. In fact, there have been attempts to make language models perform any operation on a computer \cite{openinterpreter,openai_chatgpt_plugins_code_interpreter_2023}, or operating a web browser \cite{nakano2021webgpt,act1}.

% The purpose of prototyping is to materialize the concept, even if it's rudimentary, and identify challenges. Therefore, it seems desirable for prototyping to first limit the target environment to within a computer and wait for the advancement of foundational research for the realization of free activity in the physical world.

% The examples mentioned here are merely a few ideas and are neither absolute nor comprehensive. Instead, it seems important in prototyping to discuss to what extent and what kind of constraints should be applied. It is expected that more appropriate constraints will become apparent as such discussions deepen in the future.

\subsubsection{Implementing Each Module with Large Language Models}

Given the need for generality and considering the remarkable capabilities of LLMs, it seems inevitable that each module in prototypes would be instantiated as an LLM. As highlighted in previous sections, there are emerging studies focused on constructing automated research pipelines using LLMs. I propose that our initial prototyping efforts should focus on creating autonomous research agents modeled on these LLM pipelines, in alignment with current endeavors to develop autonomous agents utilizing language models \cite{wang2023survey,xi2023rise}.

Here is a provisional concept, modeled after a typical autonomous agent. The research agent begins by formulating a question based on a high-level goal provided by a human. Following the posing of this question, the agent autonomously generates hypotheses to address it, and then proceeds to verify these hypotheses. After obtaining the final verification results, they are analyzed in relation to the initial objective and research question, prompting the generation of subsequent questions. This process – comprising question formulation, hypothesis generation, and hypothesis verification – is iteratively and hierarchically repeated to execute each subprocess.

The agent is envisioned to perform four fundamental actions: 1) Formulating questions, 2) Determining task completion, 3) Verifying hypotheses, and 4) Executing low-level computer operations. The processes of question formulation, hypothesis generation, and verification primarily involve executing these low-level computer operations.

When the agent opts to generate a question, it temporarily pauses its current task, such as hypothesis verification, and initiates hypothesis generation for the new question. Upon completing hypothesis generation, the agent decides whether to proceed with verification. Following verification, it updates the hypotheses based on the results. Whether or not the hypotheses are verified, the agent then resumes the higher-level process that was previously paused, incorporating the results of the low-level process. In this way, the agent continuously cycles through lower-level tasks of question construction, hypothesis generation, and verification until the highest-level hypothesis is formulated. When the highest-level hypothesis – the response to the original question – is ready, the agent always proceeds to its verification.

To ensure the system's adaptability to a wide range of research questions, the prompts given to the LLMs should be composed of only general instructions. For example, an instruction like ``generate a hypothesis for the following question'' is sufficiently generic to apply to any research question. However, providing such instructions alone is unlikely to spontaneously yield research outcomes, so there may be a need for additional auxiliary instructions that are as general as possible; identifying these is one of the main goals of prototyping.

For open-ended operations within a computer environment, ideally, the LLMs should have access to nearly all operations on the computer. As previously mentioned, initiatives to develop language models capable of executing any action in such environments are underway \cite{openai_chatgpt_plugins_code_interpreter_2023,openinterpreter}. Minimal access to web browsers, search engines, or shells may be permissible, but reliance on custom corpora or predefined hypothesis spaces should be avoided. Successful autonomous research under these conditions would indeed demonstrate the system's capacity for independent research.

% Considering the necessity for generality and the remarkable performance of LLMs, it would be inevitable to instantiate each module as a LLM. In reality, as stated in previous sections, studies to construct automated research pipeline as LLM pipeline have emerged. I believe we should start from prototyping agents as such LLM pipelines. Particularly, I believe that we should create an autonomous research agent, in line with attempts to realize autonomous agents using language models \cite{wang2023survey,xi2023rise}.

% Here is one provisional idea modeled after a typical autonomous agent. The research agent start from formulating a question given a high-level goal input by human. Once the question is posed, the agent then automatically generates hypotheses that could answer this question and subsequently verifies them. Once the final verification results are produced, they are interpreted in light of the original objective and research question, leading to the generation of the next question. However, as described below, the agent will iteratively and hierarchically repeat the processes of question construction, hypothesis generation, and hypothesis verification to execute each of these subprocesses.

% The agent is assumed to perform essentially four actions: 1. formulating questions, 2. determining whether the task is completed, 3. verifying hypotheses, and 4. executing any low-level action on a computer. The processes of formulating questions, generating hypotheses, and verifying them are primarily realized by performing low-level actions on a computer.

% If the agent chooses to generate a question, it temporarily suspends the current task, such as hypothesis verification, and always starts generating a hypothesis for that question. Once the generation of hypotheses for that question is deemed complete, the agent chooses whether to verify them or not, and after verification, it updates the hypotheses based on the results. Regardless of whether the hypotheses were verified, the agent then resumes the higher-level process that was previously interrupted, using the outcome of the low-level process. In this manner, the agent repeats the lower-level question construction, hypothesis generation, and verification until the highest-level hypothesis is generated. However, when the highest-level hypothesis, hypothesis to the original question, is generated, the agent always starts verifying that hypothesis.

% To ensure this system is general to be adaptable to many types of research questions, prompts given to these language models should consist only of general instructions. For instance, an instruction like ``generate a hypothesis for the following question'' is so general that it can be used for any research questions. Naturally, merely providing such instructions won't automatically yield research outcome from scratch, so there may be a need to provide additional as general as possible auxiliary instructions; one of the main purposes of prototyping is to explore them. 

% For open-ended operations within a computer space, ideally, the LLMs should only be given access to nearly all operations on the computer. As mentioned above, efforts to develop language models capable of taking any action in such environments have already begun \cite{openai_chatgpt_plugins_code_interpreter_2023,openinterpreter}. Minimal access to web browsers, search engines, or shells might be acceptable, but provision of custom corpora or predefined hypothesis spaces should be avoided. If research can be autonomously conducted under such conditions, it would indeed signify that the system is capable of independent research.

\subsubsection{Agents that Conduct Machine Learning Research}
To effectively provide a high-level goal for the prototype, it is necessary to select objectives from a specific research field that align with the constraints previously outlined and are conducive to prototyping.

I propose that machine learning research is an ideal candidate for such prototyping. First, many aspects of machine learning research, including verification, can be conducted entirely on a computer, thus meeting the constraints we have established. Second, the field typically features shorter research cycles compared to other disciplines, which allows for more rapid feedback for the prototype. Third, machine learning not only forms a foundational technology across various research fields but is crucial for developing a research-capable agent itself. Automating machine learning research would thus not only contribute to the automation of research processes in numerous other areas but also advance our primary objective. Finally, there already have been significant efforts towards automation in machine learning, such as AutoML \cite{hutter2019automated,bischl2023hyperparameter,lindauer2020best,white2023neural} and MLOps \cite{kreuzberger2023machine}. Particularly in recent years, there have been attempts to utilize language models for these tasks \cite{zheng2023can,zhang2023automl,vijay2023prompt}. These existing efforts are likely to provide valuable support in developing the prototype.

In conclusion, initiating the prototyping of autonomous agents, composed of language models and given the most general instructions possible, and focusing on specific types of machine learning research appears to be a strategic choice. While such efforts are already underway, I anticipate that increased participation in this area will significantly accelerate this movement.


% To give a high-level goal, we should determine which research field's what type of objectives to provide. It seems desirable for this research field to to meet the aforementioned constraints and to be suitable for prototyping.

% I believe that machine learning research is good for such prototyping. Firstly, some machine learning research can be fully completed on a computer, meeting the aforementioned constraints. Secondly, it has a shorter research cycle compared to other fields, allowing for faster feedback cycles. Thirdly, machine learning is essential for the realization of research-capable agent and also currently serves as a foundational technology in many research fields. Thus, automation of it will advance our original goal itself, while contributing the automation across many research fields at the same time. Finally, there already have been efforts for automation, such as AutoML \cite{hutter2019automated,bischl2023hyperparameter,lindauer2020best,white2023neural} and MLOps \cite{kreuzberger2023machine}. Especially in recent years, there have been attempts to perform these tasks using language models \cite{vijay2023prompt,zheng2023can}. These accumulated achievements will likely further assist in creating agents that can conduct machine learning research.

% In summary, I believe it would be beneficial to start with the prototyping of autonomous agents consisting of language models given as generic instructions as possible, capable of conducting certain types of machine learning research. Such efforts have already begun, but I hope that more people will join in and further accelerate this movement.


\subsection{Prototyping Agents that Conduct Peer Review}
To identify challenges associated with creating agents capable of conducting research, another promising initial step could be to target the automation of the academic peer review process. This approach presents several advantages, which I will detail in the following section.

% In order to identify challenges for realizing agents capable of conducting research, aiming to automate the peer review process of academic papers might also be a good initial step. There are several reasons why it may be suitable. I'd like to explain them in the following section.

\subsubsection{Why Aim for Agents Capable of Conducting Peer Review?}

Firstly, the competencies necessary for peer review closely align with those required by a research-capable agent. This similarity arises because peer review fundamentally involves evaluating critical aspects of research, such as the soundness of the verification.

Secondly, automating peer review might present fewer challenges compared to developing a fully autonomous research agent. The distinction lies in the scope of tasks: peer review primarily entails assessing whether research incorporates the necessary elements, whereas a research-capable agent must not only evaluate but also synthesize these elements. As a preliminary step in prototyping, addressing simpler problems like peer review could effectively highlight key challenges.

Thirdly, peer review is a universal practice across various research fields. Insights gained from automating this process can thus contribute significantly to the development of a general research agent, applicable in multiple disciplines.

Fourthly, peer review predominantly involves textual analysis and does not require physical or extensive digital interactions, unlike conducting research autonomously. Although it may involve searches to review existing literature, tasks such as performing experiments are typically not necessary. Given the advancements in LLMs, we are now better equipped to handle complex textual tasks. This focus on text-based evaluation is beneficial for pinpointing specific challenges in achieving our broader objective.

Finally, peer review encompasses the evaluation of subjective aspects like the ``significance'' of a research question. As discussed in Section \ref{section-question-construction}, understanding how humans assess such value in research is crucial, especially considering that alignment with human values is a significant challenge. Peer review offers a unique opportunity to observe and analyze these value judgments explicitly. Therefore, beginning with the automation of peer reviews could provide valuable insights into human evaluative processes in research.

% First and foremost, the elements necessary for peer review are closely related to those required by a research-capable agent. This is because peer review involves judging essential aspects of research, such as the soundness of the verification.

% Secondly, automating the peer review may be relatively less challenging than realizing an agent capable of conducting research. The reason is that while peer review only requires judging whether the necessary elements for research are present, to realize a research-capable agent, it's not just about judgment but also about being able to compose those elements. It seems desirable to start by tackling simpler problems first as a prototype to highlight challenges.

% Thirdly, peer review is a widely practiced convention regardless of the research field. Therefore, the insight found during peer review automation can be beneficial to realize a general research agent. 

% Fourthly, peer review is mostly completed through text manipulation alone. There is no need for interactions with the physical world or the computer realm that are necessary for autonomously conducting research. While searches to investigate prior research might be necessary, tasks like executing experiments are, at the very least, not required. Thanks to the advancement of LLMs, we are now capable of handling text at a significant level. Therefore, we can purely focus on challenges related to the evaluation of research. This is advantageous when identifying challenges to achieve our objective.

% Finally, peer review requires a judgment of value, such as the ``significance'' of a question. As mentioned above, alignment is one of the biggest challenges. To solve this problem, it matters to first understand how humans make value judgments in research. And peer review is a rare example where such values are explicitly assessed. In this sense, the automation of peer reviews could be a good start point.

\subsubsection{Peer Review Automation}

A considerable body of research has been devoted to automating various aspects of the peer review process. Efforts have included automating the generation of reviews \cite{yuan2022can,yuan2022kid,wang2020reviewrobot}, screening papers \cite{schulz2022future}, assessing research papers \cite{kousha2022artificial}, and assigning reviewers \cite{zhao2022reviewer}, among other tasks. In line with trends across other fields, recent years have witnessed a surge in studies exploring the use of LLMs for automating peer review \cite{wexin2023can,liu2023reviewergpt,robertson2023gpt4,hosseini2023fighting}. For a more comprehensive understanding of traditional research in this area, Kousha et al. \cite{kousha2022artificial} and Lin et al. \cite{lin2021automated1} have conducted extensive literature reviews.

Considering the goals of prototyping, it is desirable that such efforts already exist. The insights and findings from these prior attempts would help further discussions on developing AI capable of conducting peer review. 

% There is a bunch of studies that have tried to automate the peer review process. Researchers have tried to automate review generation \cite{yuan2022can,yuan2022kid,wang2020reviewrobot}, paper screening \cite{schulz2022future}, research paper assessment \cite{kousha2022artificial}, reviewer assignment \cite{zhao2022reviewer}, and more. As in other fields, recent years have seen research on the automation of peer review using large language models such as GPTs \cite{wexin2023can,liu2023reviewergpt,robertson2023gpt4,hosseini2023fighting}. For traditional research on the automation of peer review,  Kousha et al. \cite{kousha2022artificial} and \cite{lin2021automated1} Lin et al. have conducted comprehensive literature reviews. 

% The existence of such efforts is important in the context of the aforementioned prototyping. It is desirable that further discussions deepen on how to realize AI capable of peer review, while referencing the insights gained from these attempts.

\section{Conclusion}
In this paper, I have undertaken a speculative exploration of the concept of an intelligent agent capable of conducting research. The initial discussion centered on defining what constitutes research, tentatively framing it as the process of updating beliefs in hypotheses. Subsequently, I delved into the critical elements of research: the construction of questions, generation of hypotheses, and their verification. Following this, I highlighted the significance of identifying challenges in realizing such agents and proposed preliminary ideas for prototyping.

It is important to acknowledge that the discussions in this paper are purely speculative. The definition of research provided is provisional, the challenges and implications discussed represent only a fraction of the myriad possibilities, and the ideas for prototyping are rudimentary, akin to early-stage experiments. Furthermore, the literature referenced is not exhaustive, omitting many pivotal works. My ability to evaluate each reference thoroughly may have been limited, potentially leading to partial perspectives or inaccuracies. Plans are in place to update this paper in the future, addressing these limitations. Feedback and corrections from readers are greatly valued and will be instrumental in refining this work.

The primary motivation for publishing this paper in its current nascent form, despite its  numerous limitations, is to lay the groundwork for future exploration into the concept of a research-capable intelligent agent. In order to realize agents capable of conducting research, there must still be many issues that need to be discussed. I hope that the discussion surrounding this concept will become more active to accelerate the development of these agents.
iii

% In this paper, I conducted a speculative examination of the concept of an intelligent agent that can conduct research. I began by discussing what it would mean to conduct research, implying that research could be seen as the act of updating beliefs in hypotheses. I then discussed the construction of questions, generation of hypotheses, and verification of hypotheses, which are seen as essential elements in research. After discussing the additional topics, I pointed out the importance of highlighting challenges in realizing such agents and shared some simple ideas for prototyping.

% The discussions in this paper are all speculative. The definition of research discussed is provisional, the challenges and implications mentioned are just a fraction of the vast possibilities, and the prototyping ideas are akin to simple toys. Also, the literature cited is far from exhaustive, with many important works not covered. My capacity to adequately evaluate each reference might have been insufficient, leading to one-sided assessments or errors. The paper is planned to be updated in the future, and these shortcomings will be addressed in these updates. Any feedback or corrections are highly appreciated.

% The reason for publishing this paper in its current, idea-stage form, despite its many insufficiencies, is to provide a starting point for thinking about the concept of a research-capable intelligent agent. I hope this paper will be of some help to researchers aiming to realize such agents and will contribute to more vibrant discussions in the future.