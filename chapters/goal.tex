\section{What Would Activities Called Research Be?}
\label{section-what-is-research}

Understanding the fundamental nature of research is crucial for creating an agent capable of autonomous research. This section will therefore speculatively consider how the act of research can be characterized.

The aim of this section is not to establish a universal and singular definition of research, a task that exceeds the scope of this paper. Rather, it explores some characteristics of research to provide a provisional basis for discussions on the development of an artificial researcher. As such, the definition of research presented here should be regarded as tentative and operational, and the ensuing discussion is just one example of an endeavor to characterize research. 

Refining our understanding of research through in-depth discussions in the future is essential for the development of agents capable of conducting research. I hope that this discussion will make a meaningful contribution to these efforts.

\subsection{Research as Knowledge Production}

While finding a unified, all-encompassing definition of research or science remains infeasible \cite{chalmers2013thing,sep-scientific-method}, various interpretations exist. For instance, one view posits that research occurs ``whenever we gather information to answer a question that solves a problem'' \cite{booth2003craft}, while another describes research (and development) as comprising ``creative and systematic work undertaken in order to increase the stock of knowledge'' \cite{manual2015guidelines}. Additionally, some perceive the science as ``processes that maximize the evidence for a generative model of the sensed and measured world'' \cite{balzandistributed}. These descriptions highlight different crucial aspects of research, with none being entirely incorrect or absolutely definitive.

Among these, a broadly recognized definition can be that research is an endeavor to generate new knowledge. Since this characterization seems to align with our research practices, regardless of the field, this definition serves as a suitable starting point for our discussion. In this paper, I adopt this interpretation as a provisional working definition. Specifically, I will regard research as the attempts to produce new knowledge for certain society. The inclusion of ``for certain society'' acknowledges the societal relativity of knowledge, a point I will elaborate on in subsequent sections.


\subsection{Knowledge Production as Belief Revision}
\label{section-knowledge-production-as-belief-revision}
Having defined research as the endeavor to generate new knowledge, it becomes important to consider what ``knowledge'' itself entails, and what constitutes its production. This section aims to explore these concepts.

Defining knowledge and the process of knowledge production rigorously remains an unsettled philosophical debate \cite{sep-epistemology}. Given that providing a precise definition of knowledge is beyond the scope of this paper, an in-depth exploration of these debates will not be undertaken here. Instead, this section aims to present a basic and preliminary conception of what knowledge might entail so that it serves as a starting point  for further discussion.

% I have defined research as the endeavor to generate new knowledge. Then, what exactly is knowledge, and what does it mean to produce knowledge? I will explore this question in this section. 

% Defining knowledge and knowledge production rigorously is a philosophical debate that has not yet been settled \cite{sep-epistemology}, and I won't delve into it deeply here. Instead, I would like to provide some primitive ideas that can serve as a starting point for further discussions.

\subsubsection{Knowledge as Belief}
The concept of knowledge has long been a subject of debate within \textit{epistemology}, a branch of philosophy. This paper will reference the discourse in this field as an exemplar to explore how research might be characterized.

Within epistemology, knowledge has traditionally been viewed as \textit{justified true belief (JTB)} \cite{sep-epistemology}. The term ``true'' is challenging to define rigorously; however, for the purposes of this discussion, it can be understood as something that corresponds with fact. ``Belief'' is tentatively defined as an individual's thought or conviction about a subject. ``Justified'' implies that it is reasonable to hold such a belief. The nature of justification has been a focal point of debate in epistemology, particularly following criticisms that JTB may not adequately define knowledge \cite{gettier1963justified}. Consequently, the refinement or expansion of the JTB has become a significant topic in epistemological discourse \cite{sep-epistemology}.

Although many philosophers contend that the JTB properties alone are insufficient for defining knowledge, there is some consensus that they might be necessary components \cite{sep-epistemology}. In epistemological debates, rather than discarding JTB entirely, many theorists use it as a foundational concept. Hence, this paper will tentatively adopt JTB as a preliminary basis for discussion. 

The subsequent sections will explore how research is conceptualized under this definition. Analyzing the congruences and discrepancies between the implications drawn from this characterization and our expectations of a research-capable agent will generate insights for refining the definition of research and hypothesizing the capabilities such agents should possess.


% The question of what is the thing called knowledge has been a subject of debate for a long time in the field of \textit{epistemology}, which is one of the branches of philosophy. So, for now, I would like to refer to the discussion in this field as an example and see how research can be characterized.

% In epistemology, knowledge had been classically considered to be \textit{justified true belief (JTB)} \cite{sep-epistemology}. The term ``true'' is difficult to define rigorously, but for the purpose of discussion, let's think of it as something being fact. ``Belief'' can be provisionally understood as someone's thought or conviction about something. And ``justified'' means that it is deemed reasonable to hold such a belief. What justification means has been discussed in epistemology as a central point of contention. Since the criticism that JTB is not appropriate as the definition of knowledge \cite{gettier1963justified}, how to modify or expand JTB to make it a suitable definition of knowledge seemingly has been a major discussion in epistemology \cite{sep-epistemology}. 

% While most philosophers don't appear to believe that these properties are sufficient to define knowledge, there seems to be some agreement that they may be necessary \cite{sep-epistemology}. Even in the epistemology discussion, rather than abandoning the JTB altogether, many discussions adopt JTB as a base. Therefore, let me tentatively assume that knowledge is JTB in this paper to offer a preliminary basis for discussion. In the following section, I will examine how research is perceived as an activity when adopting this definition. Examining the discrepancy and alignments between the consequences of this characterization and our expectations for a research-capable agent will provide seeds of thought for a better definition of research and hence what that agents should be able to do.

\subsubsection{Knowledge Production as Belief Update}
The primary aim of research can be conceptualized as uncovering the unknown truths of the world. Consequently, the justification employed in research must be capable of accurately discerning the truth or falsity of propositions. This form of justification, known for its capacity to lead to truth, is termed ``truth-conducive.'' While there are varied debates on the nature of justification, it is widely accepted that justification in research should indeed be truth-conducive. Thus, knowledge production can be conceptualized as the construction of new propositions about the world and ascertaining their veracity through such justification.

In the current framework, knowledge is equated with belief. Therefore, knowledge production can be reinterpreted as the process of adopting the belief that a particular proposition is true and subsequently revising this belief based on truth-conducive justification. Essentially, in this framework, knowledge production equates to the updating of beliefs.

While it might initially seem counterintuitive to view research as a process of updating beliefs, this perspective gains plausibility when considering several factors. Research involves the continual revision of hypotheses and theories; inductive reasoning, unlike deduction, does not conclusively prove propositions; and, as will be discussed, knowledge is subjective to some extent. This characterization of research as belief aligns well with these aspects of research. Therefore, this characterization seems reasonably valid.

% The purpose of research can be said to be revealing the unknown truths of this world. Therefore, the justification in research is demanded to be such that it determines propositions as true if they are true, and false if they are false. Such justification is called truth-conducive. There are various discussions about what justification is, but it can be said that justification in research should be truth-conducive. Therefore, producing knowledge could be said to be constructing a new proposition that refers to this world and determining its truth or falsity through such justification. 

% In the current definition, we regard knowledge as belief. Thus, the producing knowledge can be rephrased as holding the belief that a proposition is true and updating this belief through truth-conducive 
% justification. In short, the knowledge production is belief update in current definition.

% It might feel counterintuitive to think of research as an updating of beliefs, but considering that hypotheses and theories are continuously updated in research, inductive reasoning does not prove propositions as deduction does, and, as will be discussed later, knowledge depends on the subject, this characterization doesn't seem so far-fetched. 

\subsection{To Know Depends on Knowing Subjects}

Fundamentally, the concept of knowing presupposes not only the existence of the object being known but also of the subject doing the knowing. This interplay explains why the definition of knowledge incorporates the subjective element of belief. Consequently, while the notion that knowledge is a form of belief might initially seem counterintuitive, it holds validity in this context. 

Moreover, conceptualizing research as an updating of beliefs aligns closely with actual research practices. For instance, the experimental validation of a hypothesis reinforces our belief in its truth or falsity. Our confidence in a hypothesis increases as it withstands various rounds of verification. This process of iterative validation and belief reinforcement mirrors the concept of research as a continual renewal of beliefs.

Finally, since the justification in research is expected to be truth-conducive, the knowledge thus produced would have an objective quality. Therefore, in conjunction with the discussion in the previous section, it seems that the use of the subjective concept of belief is not that problematic.

% To know means we recognizing some truths or patterns of this world. In other words, the concept of knowing fundamentally presupposes the existence not only the known object but also the knowing subject. This is why the definition of knowledge involves the subjective concept of belief. Therefore, while the idea that knowledge is belief may seem counterintuitive, it appears valid in this sense. Particularly, since justification in research should be truth-conducive, the knowledge produced would be objective. In this sense, using belief, which is a subjective concept, to define research does not seem to be much of a problem.

% Moreover, viewing research as the updating of beliefs does not seem too far removed from the practice of research itself. For example, the validation of a hypothesis by an experiment would strengthen our belief that the hypothesis is true or false. We become more convinced of its validity as a hypothesis survives repeated various verifications. This research practice appears to be well aligned with the view of research as a renewal of beliefs.

\subsubsection{Knowledge for Humans}
As previously discussed, research is a pursuit dedicated to uncovering the unknown truths of the world, necessitating that the knowledge it generates be novel. This raises the question: what constitutes new or unknown knowledge?

Under the current definition, knowledge is a justified belief regarding the truth or falsity of a certain hypothesis. Thus, unknown knowledge could be a state where such a belief is either non-existent or, if it exists, lacks justification. In simpler terms, within this framework, the state of certain knowledge being unknown is essentially a state of belief.

Given that the concept of knowing is contingent on the knowing subject, the notion of the unknown is also inherently subject-dependent. In the realm of research, the term ``subject'' has seemingly encompassed humanity at large. Researchers do not deem knowledge as unknown simply because it eludes an individual; it is regarded as truly unknown only when it is beyond the collective understanding of humanity. Consequently, the knowledge produced through research is expected to contribute to the collective understanding of human society. This is the reason why the term ``for society'' is included in the definition of research.

% As mentioned earlier, research is an endeavor aimed at revealing the unknown truths of this world, and the knowledge generated there must be novel. Then, what does it mean for knowledge to be new or unknown?

% In the current definition, knowledge is a justified belief about whether a certain hypothesis is true or false. Therefore, unknown knowledge could be a state where such a belief is not held at all, or even if it is held, it is not justified. In other words, under the current definition, the state of certain knowledge being unknown can be understood as a state of belief.

% Since the concept of knowing depends on the knowing subject, naturally, the concept of the unknown is also subject-dependent. In research, it seems that so far, this ``subject'' has referred to humanity as a whole. Researchers do not consider knowledge unknown just because a single individual is unaware of it. It is only when none of us know it that we consider it truly unknown. This is why it seems that the knowledge we create through research is required to be knowledge for all of humanity. These are the reason why it seems better to include ``for society'' in the definition of research.

\subsubsection{Knowledge for Non-Humans}
If the act of knowing is subject-dependent, then theoretically, it is feasible to conceive of non-human knowledge and non-human research by considering non-human entities as knowing subjects.

While this speculation may seem peripheral, that the machines might have a different scope of the unknown compared to humans has some implications for realizing artificial researcher. This is because it suggests that merely replicating current research methodologies in the agents might not necessarily yield new knowledge for humans.

Current research methods are designed to uncover truths unknown to knowing subjects. Therefore, an agent mimicking these methods might only reveal truths unknown to itself, which may not align with human knowledge gaps. If we want AI to conduct research autonomously, we must find a way to ensure it understands what is unknown to humans, not just to itself, and guide it to discover knowledge that is truly unknown in the human context.

This is just a preliminary discussions, and it is hoped that further discussion will continue on how to realize them for developing research-capable AI.

% Thus, to develop AI that contributes to human knowledge, we could use AI just as a tool to enhance human research or we should create some methods for AI to find unknowns relevant to humans.

% Consequently, if the objective is to develop AI that contributes knowledge for humans, several approaches could be considered. AI might be utilized as just a tool to augment human research, or new methodologies could be developed that enable AI to uncover unknowns specifically relevant to humans, rather than merely emulating human techniques. Alternatively, if AI is to conduct research autonomously, it may be necessary to instruct it on the areas of ignorance specific to human understanding. 





% If the act of knowing is dependent on the subject, then it's theoretically possible to consider non-human knowledge and non-human research by assuming knowing subjects to be non-human. 

% Although it might seem insignificant since most people desire AI that produces knowledge for humans, I believe the observation that what is unknown to a machine may differ from what is unknown to humans provides implications for what we should do to realize an AI capable of conducting research.

% When what is unknown differs between humans and machines, creating a machine that can research in the same way as humans may not necessarily produce new knowledge for humans. This is because some of the methods developed by humans are aimed at revealing truths unknown to themselves, and even if a machine can mimic these methods, it would only reveal truths that are unknown to the machine, which is not necessarily unknown to human.

% Considering this, if the goal is to create AI that produces knowledge for humans, then AI should either be used as just a tool to assist human research, develop new methodologies that discover the unknown for humans through machines rather than merely mimicking human methods, or, if the AI is allowed to research autonomously, there might be a need to teach it what is unknown to humans. These are merely a list of possibilities, but it is hoped that there will be further discussion in the future about whether these could truly become issues.

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Truth-Conducive Justification Developed by Non-Human Agents?}

% While beliefs are inherently subjective, research demands that justification be truth-conducive, thereby lending an objective character to justified knowledge. In essence, the truth value of a proposition, independent of personal belief, determines the justification of that belief.

It must be acknowledged that we cannot definitively ``prove'' our empirical methods to be entirely truth-conducive. Yet, given the myriad discoveries achieved through these methods, questioning their legitimacy seems unfounded. If agents can thoroughly grasp and effectively apply these human-developed justifications, it is poised to uncover numerous unknown truths, a prospect few researchers would dispute.

Then, what about when the agent constructs its own methods of justification? Is it possible for an agent to construct new truth-conducive justification methods on its own, instead of just mastering human-developed methods? Humans have devised tools like statistical hypothesis testing to evaluate hypotheses; can AI similarly innovate unique methodologies? Even if it were possible, how significant would those be?

Our justification methods are founded on various premises, implying diverse interpretations of ``what constitutes a truth-conducive justification'' or ``what justification entails.'' These interpretations lead to multiple methods of justification even among humans \cite{otsuka2022thinking}. Consequently, when allowing artificial agents to autonomously develop justification methods, these agents must navigate value judgments regarding the nature and effectiveness of justification, thereby conceiving and selecting optimal methodologies.

This exploration extends beyond philosophical musings. Since the current justification methodologies have not been proved to be the optimal, the potential for superior methodologies exists. Machines, unfettered by human cognitive limitations, theoretically possess the capacity to discover such methods. Importantly, the efficacy of truth-conducive justification can be evaluated irrespective of who uses it. Thus, machines might autonomously construct methods of justification suitable for the production of novel knowledge that human methodologies could not easily find. The feasibility, realization, and significance of these possibilities remain open for exploration and debate.

% Even though beliefs are indeed subjective, in research, justification is expected to be conducive to truth, thus making justified knowledge objective. That is, whether a proposition is true or not determines whether that belief is justified, regardless of what we think.

% I admit that we cannot ``prove'' that our empirical justification methods are strictly truth-conducive. However, considering the numerous discoveries we have made through them, it would be pointless to doubt the legitimacy of them. If AI can fully master and appropriately utilize these justifications developed by humans, it would be enough for them to uncover numerous unknown truths. Few researchers would likely doubt the importance of this.

% Then, what about when the agent itself constructs its own methods of justification? Is it possible for an agent to construct new truth-conducive justification methods on its own instead of just mastering human developed methods? Human beings, for example, have developed statistical hypothesis testing as a method for evaluating hypotheses, so can AI similarly develop its own unique methods for evaluating new hypotheses? Even if it were possible, how ``significant'' would those be?

% Our justification is based on several premises. This means that we make an interpretation of ``in what sense a justification is truth-conducive'' or ``what is justification'' in some sense, and depending on that interpretation, there actually exist multiple methods of justification even in the case of humans \cite{otsuka2022thinking}. Therefore, when allowing artificial agents to autonomously construct up to the method of justification, the agent is expected to make value judgments about ``in what sense a justification is truth-conducive'' and ``what is justification,'' conceiving and selecting the optimal method of justification. 

% This is not merely a philosophical inquiry. This is because, as long as we do not understand what constitutes the most truth-conducive justification, there is a possibility that better methods of justification may exist. Moreover, machines, not bound by cognitive constraints like humans, theoretically have the potential to discover such justifications. Particularly, the quality of a truth-conducive justification can be determined regardless of whether it involves humans or machines. Therefore, in the sense that its quality can be determined without human judgment, there is a possibility that machines could autonomously construct it. If this were to happen, it might enable the production of knowledge that humans alone could not have achieved. However, whether these are realistic, how they can be realized, and how significant they actually are, remains an open question.

\subsection{Conclusion}
In this section, I have provided a provisional working definition of research. My initial premise was the intuitive belief that research is an endeavor aimed at generating new knowledge for a particular society. This discussion then ventured into speculative territory, examining the notions that knowledge is fundamentally a form of belief and that the production of knowledge entails the updating of beliefs. Building on these ideas, I presented a conjectural exploration of the insights for non-human agents in knowledge production.

It is important to note that the definition proposed here serves merely as a starting point. A more comprehensive and nuanced understanding of research can be cultivated through the collective insights of philosophers, scientists, and practitioners across various fields. This collaborative approach will enable us to delve deeper into the definition of research and develop more robust and effective guidelines to realize an artificial researcher.

\section{Question, Hypothesis, and  Verification}
\label{section-question-hypothesis-verification}
In the preceding section, I briefly examined a preliminary conceptual definition of research and its broader implications. This section shifts focus to the widely acknowledged fundamental components of research: question construction, hypothesis generation, and hypothesis verification. 

The objective here is to advance the discussion beyond the too abstract considerations of the previous section. By dissecting these core elements, this section seeks to offer a more concrete exploration of what constitutes research and the prospects of machines engaging in research activities. 

\subsection{Question Construction}
\label{section-question-construction}
The first essential element in research is \textit{question construction}. To produce new knowledge, it is imperative to recognize what is unknown and strive to generate that elusive knowledge. This act of identifying the unknown for investigation can be considered as the process of questioning. Subsequently, formulating potential answers for these questions constitutes hypothesis generation. Essentially, research can be reinterpreted as the act of posing and responding to questions. Furthermore, since research inherently involves lots of uncertainty, the generation of multiple questions, beyond the initial research question, is a natural part of the process. That is, in the pursuit of confronting the unknown, question construction is an inevitable aspect of research.

There have been the studies to find research questions and challenges from academic literature \cite{lahav2022search,liu2023creative,oppenlaender2023mapping,surita2020can}, and identifying research trends \cite{krenn2020predicting,krenn2022predicting}. However, enabling machines to autonomously generate questions is less common. In the domain of question answering from natural language processing (NLP) research, tasks exist for generating questions \cite{pan2019recent,zhang2021review}, but these are motivated differently from generating research questions. Research on artificial curiosity for generating non-textual questions has been conducted \cite{schmidhuber1991possibility}, yet no method currently exists that can generate research questions akin to a human researcher. Recent advancements in large language models (LLMs) have led to initial attempts at generating research questions \cite{liu2023creative,lahat2023evaluating}, but this area remains nascent.

While there are efforts towards automation as shown above, these attempts are relatively limited compared to those for hypothesis generation and verification. The automation of question construction, or determining the underlying goals of such automation, is recognized as a key challenge in the field of research automation \cite{coley2020autonomousII,zenil2023,kitano2021nobel}. 

In this section, I start with a speculative exploration of the nature of questioning. This will be followed by a discussion of the open challenges in enabling an artificial agent to effectively pose research questions.





% The first element is \textit{question construction}. In order to produce new knowledge, one must be aware of what they don't know and strive to generate that unknown knowledge. This process of deciding the unknown to be investigated can be regarded as questioning. And generating the candidates of the answer for that question is hypothesis generation. That is, research may be rephrased as the act of posing questions and answering them. Moreover, as long as there is an attempt to reduce uncertainty, questions are necessary, and we generate multiple questions in the process of research other than the research question. Thus, in the act of research, which confronts the unknown, question construction is inevitable.

% In relation to efforts concerning the generation of questions by machines, there are studies aimed at discovering research questions and challenges from academic literature \cite{lahav2022search,liu2023creative,oppenlaender2023mapping,surita2020can}, and others focused on identifying research trends \cite{krenn2020predicting,krenn2022predicting}. However, efforts to let machines autonomously generate questions on their own are not as prevalent. In the field of question answering, there is a task for generating questions \cite{pan2019recent,zhang2021review}, but these studies have different motivations than generating research questions. There has been research on creating artificial curiosity to generate non-textual questions \cite{schmidhuber1991possibility}, but there is yet nothing that can generate research questions like a human. With the advent of large-scale language models in recent years, there have been attempts to generate research questions \cite{liu2023creative,lahat2023evaluating}, but this field is still in the early stage.

% While the attempts for automation exist, compared to the those for generation and verification of hypotheses, these efforts are limited. Automating the construction of questions, or setting the goal behind, is recognized as a challenge that needs to be addressed in research automation \cite{coley2020autonomousII,zenil2023,kitano2021nobel}. In this section, I would like to start by speculatively exploring what questioning would be. Then, I would extend the discussions to open problems to realize an agent to pose questions.

\subsubsection{What is Questioning?}
Asking questions is often characterized as an information-seeking behavior \cite{watson_2021,taylor1962process}. This behavior typically involves two distinct steps: firstly, recognizing an \textit{information need}, and secondly, undertaking actions to acquire the desired information \cite{wilson1997information,case2016looking}. While not all information-seeking behaviors necessitate linguistic expressions \cite{watson_2021}, in the context of research, queries are typically formulated in text. This textual formulation occurs between the stages of information need recognition and the initiation of information-seeking behavior. Specifically, in research, the process of question construction is generally understood as the journey leading to the formulation of such queries. Thus, for the purposes of this paper, question construction is defined as the process culminating in the formulation of a query. The subsequent steps of information seeking are considered part of hypothesis generation and verification.

Recognizing an information need seems to involve at least two sub-processes: identifying the knowledge gap and deciding to address it (judging that the missing information is a ``need'').\footnote{
In this discussion, the process of recognizing an information need is described as initially identifying something as unknown and then deciding whether to formulate a question about it. However, the sequence of these steps is not fixed. For instance, one might first have a desire to know something and only afterward ascertain that it is indeed unknown. The critical aspect is that the process encompasses these two elements.
} Therefore, to enable an artificial agent to autonomously construct questions, it is necessary to consider how to imbue it with these capabilities. The following sections will delve into a speculative analysis and exploration of these steps.\footnote{
It is important to note that questions in research are not personal but societal in nature. This societal aspect may introduce slight variations in the question construction process. This point will be revisited later in the paper.
}


% Asking questions seems to be characterized as an information-seeking behavior \cite{watson_2021,taylor1962process}. The act of seeking information is considered to consist of two steps: recognizing an \textit{information need} and then taking action to acquire that information \cite{wilson1997information,case2016looking}. Not all information-seeking behaviors involve linguistic expressions \cite{watson_2021}, but in research, we always form a query expressed in text between the steps of the information need recognition and the onset of information seeking behavior. Especially, in research, the process of question construction generally seems to refer to the process leading up to this query formulation. Therefore, in this paper, we regard question construction as the process leading up to the query formulation. The subsequent process of seeking information will be treated as part of hypothesis generation and verification.

% The process of recognizing an information need appears to involve at least two sub-processes: recognizing the missing knowledge and deciding to fill it (judging that missing information is ``need'').\footnote{
% Here, I explained the process of recognizing information need as first determining something as unknown and then deciding if you construct question about the unknown. However, the order doesn't matter. For instance, there may be knowledge that you want to know first, and then you confirm subsequently that it is indeed unknown. What matters is that the process involves these two elements.
% } Therefore, to have an agent to autonomously construct questions, it would be necessary to consider how to instill these abilities to it. In the following sections, I will engage in speculative analysis and investigation of these steps.\footnote{
% Please note that the question in research is not a personal one, but a question for society. This difference can bring about slight variations in the process of constructing questions. I will touch upon this point again later.
% }

\subsubsection{Recognizing Unknown}
Recognizing that certain knowledge is unknown typically involves an initial attempt to access that knowledge. This process usually entails referring to our personal knowledge base and, upon not finding the information, deeming it as unknown. For an individual, this knowledge base is essentially the memory stored within the brain. However, in the realm of research, the unknowns that researchers aim to elucidate are those unknown to a specific society, not just to an individual researcher. That is, a research-capable agent does not need to judge whether it is unknown to itself, but rather it can directly determine whether it is unknown to certain society. In this context, the knowledge base extends beyond the agent's memory to encompass societal knowledge sources, such as a collection of research papers.\footnote{
As mentioned earlier, something being unknown implies either the absence of a proposition or the presence of an unverified belief. Therefore, accurately determining the unknown from academic papers requires an assessment of whether each paper has been appropriately justified, meaning whether its verification processes are sound.
}

% \textcolor{red}{論文のコーパス（のグラフ表現とか）からまだ探索されていない領域を同定する研究は絶対あるので、載せる。あとは、論文の取得を自動でやってくる研究についてもここで述べる。}

As outlined in Section \ref{section-what-is-research}, for machines to generate new knowledge beneficial to humans, they must be capable of identifying what is unknown to humans, not just to themselves. While this task might initially seem as straightforward as conducting a literature survey as humans do, the reality may necessitate more complex approaches. The specific requirements for achieving this goal merit further discussion.

An additional consideration arises regarding the reliance on a machine's judgment to determine what is unknown to us. If an AI has been pre-trained on an extensive corpus of scholarly papers, its judgment might appear credible. However, as previously mentioned, an AI's determination of unknowns does not necessarily coincide with human unknowns. This issue becomes increasingly pertinent and significant as AI amass more knowledge and enhance their capabilities.

% To recognize that certain knowledge is unknown to you, it seems necessary to first attempt to refer to that knowledge. It appears that when we refer to our own knowledge base and do not find the knowledge, we judge it to be unknown. For an individual, the knowledge base is the memory within the brain. On the other hand, the unknowns researchers wish to clarify are unknowns to a certain society. That is, a research-capable agent does not need to judge whether it is unknown to itself, but rather it can directly determine whether it is unknown to certain society. Therefore, the knowledge base can be not only its own memory but also the knowledge base of the society, e.g. a collection of research papers.\footnote{
% As previously mentioned, being unknown means that a proposition either does not exist or, even if it does, it is not accompanied by a justified belief. Therefore, it seems that in order to precisely determine unknowingness from academic papers, it seems to be necessary to judge whether each paper has been justified, that is, whether verification has been appropriately conducted. 
% }

% As stated in Section \ref{section-what-is-research}, if we want machines to generate new knowledge for humans, they must identify unknowns for humans, not for themselves. This might be as simple as conducting a literature survey, as previously mentioned, but it might require more than that. What is needed to achieve this seems to be a topic for further discussion.

% There is also a question as to whether we should consider something as unknown to us if a machine determines it to be unknown based solely on its own memory. Such judgment may sound reliable if the AI was pre-trained with all scholarly papers. However, as mentioned before, just because AI deems something unknown, it doesn't guarantee that it's unknown to humans. This topic would become increasingly realistic and important as AI accumulates more knowledge and becomes capable of handling more intelligent tasks.

\subsubsection{Deciding What Knowledge to Seek}
\label{section-deciding-what-knowledge-to-seek}
While we encounter numerous unknowns, we do not formulate questions for each one, as not all unknowns hold equal ``importance'' or ``interest.'' Instead, we construct questions for matters we are eager to understand. This process involves assessing the ``value'' of questions based on certain criteria to determine their worthiness of pursuit. For individuals, this can be a largely subconscious process. However, in research, this need not be an internal process, as long as that is the value judgments of questions.

Knowledge, in itself, is value-neutral. The ``value,'' ``significance,'' or ``goodness'' of knowledge is ascribed by its users. A noteworthy aspect here is that the criteria for determining ``value'' are subjective and arbitrary. Hence, if we aim for artificial agents to autonomously pose questions meaningful to humanity, it is crucial to identify what constitutes ``good'' or ``significant'' questions for us and instill these values in the agents.

On the other hand, it is also vital to recognize that certain questions deemed ``unimportant'' by us may actually hold importance under different criteria. Fundamental research, for example, often yields knowledge initially perceived as ``useless'' but later proves pivotal for innovations. Human cognitive limitations may sometimes hinder our ability to fully appreciate the potential utility of such knowledge. Moreover, social factors unrelated to the initial purpose of knowledge production can influence our value judgments, implying that these human judgments are not always optimal.

Given that machines are not inherently limited by such constraints, they could theoretically make more effective value judgments. Therefore, while providing some guidance to ensure that the generated question is relevant to humans is crucial, developing agents capable of autonomously constructing these value criteria themselves may also be fruitful. How to achieve this forms a significant open challenge in developing research-capable agents.\footnote{
Kitano has described the approach where humans apply their value judgment criteria to determine questions and hypotheses as \textit{value-driven science} \cite{kitano2021nobel}. He advocates for the advancement of \textit{exploration-driven science}, which prioritizes extensive and comprehensive exploration. While a completely value-neutral exploration is unattainable, the notion of employing diverse and extensive criteria is indeed significant for the future of research. By embracing a wider range of criteria, we can expand the exploration space of knowledge.
}

% We do not always formulate questions for everything we don't know since not all unknowns are equally ``important'' or ``interesting'. Instead, we construct questions for things we wish to know the answers to. This means that we assess some ``value'' of questions using some criteria to determine if it is worth pursuing. For individual, this can be an unconscious internal process, but for research, this doesn't need to be so as long as it is some value judgment process.

% Knowledge in itself is value-neutral. The ``value'', ``significance'', or ``goodness'' of knowledge is determined by those who using it. The crucial point here is that the criteria for determining ``value'' are arbitrary. Therefore, if we want agents to autonomously pose questions that are meaningful to humanity, we should recognize what is ``good'' or ``significant'' questions for us and instill and make them adhere to such values. 

% However, we should also be mindful that there might be questions that we would judge as ``unimportant'' but are actually ``important'' under some criteria. For instance, there is a myriad of knowledge born from fundamental research that, at first glance, might seem ``useless'' but actually leads to later innovations. Due to human cognitive limitations, there might also be instances where we cannot fully assess the utility of that knowledge. Additionally, in human society, sometimes social factors unrelated to the original purpose of the knowledge production influence value judgments. That is, our value judgments are not necessarily always optimal.

% Since machines are not bound by such constraints in theory, there's a possibility they can make better value judgments. Therefore, while it might be essential to provide some minimal guidance to ensure they generates questions meaningful to humans, it would be good to aim for the development of agents that can autonomously construct good value criteria by themselves. How to create such agents seems to be one of the important open problem in building an agents capable of research.\footnote{
% Kitano referred to the science in which humans adopt their own value judgment criteria to determine questions and hypotheses as \textit{value-driven science} \cite{kitano2021nobel}. He argued that advancing \textit{exploration-driven science}, which focuses on more comprehensive and thorough exploration rather than criteria based on specific human values, is important for societal development. Although a completely value-neutral system would be impossible, I agree with the idea that employing new and diverse criteria would matter for future research. By adopting more diverse and extensive criteria, we could expand the exploration space of knowledge.
% } 

\subsubsection{Origin of Information Need}
I previously outlined that question formation begins with the recognition of an information need. This leads to the question: what triggers the recognition of an information need?

The initiation of this process can be attributed to various factors. Some researchers may generate questions through logical contemplation aimed at achieving a specific goal. Others might identify questions upon noticing anomalies in experimental data or inconsistencies between theoretical assumptions and actual observations. Researcher also sometimes search questions that can be answered techniques you have. Furthermore, humans typically do not rely on a singular criterion for value judgment. Instead, multiple criteria are often intricately combined and weighted according to the context, culminating in a complex value assessment process. To develop an agent capable of autonomously constructing research questions as humans do, therefore, it appears necessary to create a system with a general methodology for questioning applicable across these diverse scenarios.

What is the process in humans that connect between these various factors and information, and how to develop an agent capable of emulating this process, remains an open question. Researchers in the field of curiosity, which is broadly conceptualized as a ``drive state for information'' \cite{kidd2015psychology}, have been investigating this challenge. Curiosity is often characterized as a precursor to information need in information-seeking processes \cite{case2016looking}. In reinforcement learning, efforts to instill curiosity or knowledge-based intrinsic motivation in AI have been explored. Here, curiosity is defined in terms of novelty, information gain, or prediction error, and is considered a catalyst for exploration \cite{aubret2019survey}.

These efforts provide insights into implementing mechanisms that drive AI towards question formation. However, we are still distant from realizing a system that autonomously constructs research questions under complex value judgments, as humans do. A particular challenge is identifying the minimal input for question generation; that is a question for hypothesis generation and a hypothesis for hypothesis verification, while it's unclear for question construction. Designing a complex, contextually adaptive internal driving force for questioning remains a significant hurdle. Identifying the prerequisites for such an AI system is an ongoing challenge.



% I explained that the question begins with the recognition of an information need. So, what causes the recognition of an information need (or the sub-processes of the recognition of unknowns and the judgment of value) in the first place?

% Various factors can be considered as triggers. Some people may generate research questions as they logically think about how to achieve a goal. Others might come up with a question upon noticing some anomaly while observing experimental data or realizing that there might be something wrong with the underlying assumptions based on a discrepancy between results deduced from some assumptions and actual observational data. Furthermore, in reality, humans do not evaluate based on a single criterion of value judgment. It seems that they combine these criteria in a complex manner, weighting them according to the situation, before arriving at a final value judgment.
% If one wants to create an agent that can autonomously construct research questions like humans, it seems necessary to develop an agent with a general methodology that can construct questions in any of these situations.

% How these various factors are connected to information need in humans, and how we can create an agent capable of this, remains open question. Researchers studying curiosity have been tackling this difficult problem. Curiosity, while it is difficult to precisely define, is viewed as \textit{a drive state for information} \cite{kidd2015psychology}. In this sense, curiosity can be considered as something that gives rise to an information need. Indeed, especially in the process of information-seeking, it is characterized as one of the precursors of information need \cite{case2016looking}. Efforts to instill curiosity \cite{schmidhuber1991possibility} or knowledge-based intrinsic motivation \cite{oudeyer2007intrinsic} in AI have been researched in the field of reinforcement learning. There, curiosity is formulated as novelty, information gain, or prediction error, and is perceived as something that encourages exploration \cite{aubret2019survey}.

% These efforts have provided guidelines on how to implement mechanisms that drive intelligence towards questions. However, we are still halfway to realizing a system that autonomously construct research questions under complex value judgments in various situations, as humans do. Especially, while a question becomes the minimum input in hypothesis generation, and a hypothesis in hypothesis validation, in question generation, it's unclear what the minimum input should be. Need to design a complex internal driving force adaptive in various situations seems to be a major difficulty for creating an autonomous research questioner. Identifying what is necessary to realize such AI is an open problem.

\subsubsection{What Are the Criteria for the Value of a Research Question?}

Thus far, I have discussed abstract concepts related to questioning in general. Now, I will move on to focusing specifically on the characteristics pertinent to research questions.

The ``quality'' of a research question can be evaluated against various criteria. Here, I will introduce some examples to illustrate how humans seemingly appraise the value of a research question. It is important to note that these examples are only a few of the many criteria utilized and do not represent a comprehensive list. This discussion aims to contribute to a deeper understanding of how humans ascertain the value of a question.

One widely accepted criterion within the research community is that a question is important if it offers new perspectives, understandings, or conceptual advances, particularly those that challenge our common assumptions. For example, Alvesson and Sandberg emphasize the significance of such questions and discuss strategies for their construction \cite{alvesson2013constructing}. This criterion rests on the idea that a valuable question is one that significantly impacts our current knowledge. This seems to be a value that aligns with the highest-level objectives of the endeavor of research.

No matter how significant a question may be, if it is nearly impossible to address with current technology, deriving meaningful research outcomes from it may be unfeasible. Consequently, the feasibility of answering a question is considered a vital aspect of its quality \cite{hulley2007designing,alon2009choose,huntington2021effect}. Assessing feasibility involves complex decision-making, taking into account factors like available resources, researcher capabilities, deadlines, and technological constraints. An agent engaged in research would need the capacity for such multifaceted evaluations.

Another prevalent view is that research questions should stem from individual intellectual curiosity. Given that curiosity drives exploration \cite{oudeyer2018computational}, curiosity-driven research can foster exploration in the research theme space. Research can be seen as an exploration of the world's truths, making value standards that encourage exploration essential. However, curiosity is not the sole criterion for exploration; there may be more effective heuristics for uncovering unknown truths. If agents can adopt such heuristics or value judgments, it might surpass human efficiency in uncovering truths.

In contrast to bottom-up curiosity-driven research, questions that contribute to achieving specific top-down goals are also considered valuable. For example, in corporate or government-led research, questions aligned with predetermined objectives are prioritized. The expectation is that agents capable of autonomous research will contribute to human-set goals, underscoring the importance of their ability to make such value judgments.

% Lastly, Alon posits that a good research problem is one that personally interests the individual and matches their difficulty level \cite{alon2009choose}.

In practice, the value of a research question is determined by integrating multiple criteria. Hulley et al. suggest that questions which are feasible, interesting, novel, ethical, and relevant (FINER) are considered valuable \cite{hulley2007designing}. Huntington-Klein argues that a good research question is one that is answerable and whose answer enhances our understanding of the world \cite{huntington2021effect}. As mentioned above, autonomous agents are also expected to determine the questions they should pursue based on such complex value judgments.

As emphasized, these criteria represent only a portion of the value judgments humans make in question formulation. Future discussions should further investigate the nature of these judgments, their role in scientific discovery, and how they can be replicated in artificial researcher.

% So far, I have discussed somewhat abstract topics related to questions in general. Now, I would like to discuss the characteristics related to research questions specifically. 

% The ``quality'' of a research question can be judged based on various criteria. I will introduce some examples from among them to make it clearer how humans seemingly have determined the value of a research question. Please note that the following examples are just a few of the many criteria humans use and are far from comprehensive. I hope this will aid in further deepening the discussion on how humans determine the value of a question.

% The idea that questions which would bring about new perspective or understanding, or \textit{conceptual advance}, especially which would overturn our common sense or underlying assumptions are important is widely accepted within the research community. As an example, Alvesson and Sandberg point out the importance of these kind of questions and discuss the strategies to construct them \cite{alvesson2013constructing}. 
% This criterion is based on the premise that a good question is one that produces knowledge which has a significant impact on our current body of knowledge.

% No matter how significant a question is, if it's nearly impossible to address with current technology, producing meaningful research outcomes from that question may be infeasible. Therefore, some argue that the feasibility of answering a question should be considered when evaluating its quality, with questions that are not overly implausible being deemed good ones \cite{hulley2007designing,alon2009choose,huntington2021effect}. To determine feasibility, it seems that complex decision-making is necessary, as it requires consideration of various factors such as the resources and funding currently accessible, the capabilities of the researchers, deadlines, and even the limitations of the technology currently available to humanity. An AI capable of conducting research would likely need to be able to make such complex decisions.

% The notion that research questions should be based on an individual's intellectual curiosity also seems to be widely accepted. Curiosity is the driver of exploration \cite{oudeyer2018computational}, so curiosity-driven research might have promoted exploration in the research theme space. Research can be seen as an exploration of the space of truths in this world, hence it sounds reasonable that value standards that promote exploration are important.
% To discover things that are so unknown they are not even known to be unknown, exploration is essential as an entire endeavor of research.
% Conversely, the criteria should not necessarily be curiosity as long as it promotes the exploration in the space of knowledge. The exploration may be merely a byproduct of curiosity, and there may exist better heuristics for exploration. If agents acquire such better heuristics or value judgement, they might be able to unravel truths more efficiently than humans have done.

% Contrary to research driven by bottom-up curiosity, the notion that questions contributing to the achievement of specific goals set in a top-down manner is valuable is equally common. For instance, for those aiming to realize human-like AI, questions about how to create elements deemed necessary for such AI would be significant for them, even if it is not interesting or incremental. Especially in corporate research or government-led research, there are likely many studies aimed at achieving goals set in a top-down manner. It is assumed that many people expect AI capable of conducting research autonomously to contribute to goals set by humans. Therefore, the ability of AI to make this kind of value judgment is an important requirement.

% Lastly, there is also a perspective that emphasizes the value for individual. Alon expresses the view that a good research problem is one that is interesting to the individual and has an appropriate level of difficulty for them \cite{alon2009choose}.

% In reality, instead of adopting just one of these criteria, we determine the value of the research question by comprehensively considering multiple criteria. For example, Hulley et al. suggest that questions that is feasible, interesting, novel, ethical, and relevant (FINER) should be considered good ones \cite{hulley2007designing}. Huntington-Klein presents the view that good research question is answerable and the answer to the question will improve our understanding of this world \cite{huntington2021effect}.

% As already mentioned, these are just a part of the value judgments that humans make in determining questions. I hope that future discussions will delve deeper into what kind of value judgments humans make, what function they serve in scientific discovery, and how we can realize these functions in AI.

\subsection{Hypothesis Generation}

The second integral element of research is hypothesis generation. Research inherently involves posing questions and endeavoring to answer them. Typically, researchers bifurcate the answering process into two phases: generating hypotheses and verifying them. Hypothesis generation entails predicting a response to a posed question, while hypothesis verification involves examining the plausibility of that prediction. This two-stage approach is adopted because researchers address questions to which no one in this world knows the answer, making it challenging to immediately ascertain definitive answers. Therefore, the separation of hypothesis generation and verification represents a human-developed methodology for uncovering truths in a context of high uncertainty.

Hypothesis generation is often seen as a showcase of human creativity in research. The long-standing belief that human creativity defies analysis has led to the assumption that both question construction and hypothesis generation are inherently unanalyzable \cite{sep-scientific-discovery}. However, efforts to characterize this creative process began to emerge in the mid-20th century. Notable concepts include the role of abduction in generating hypotheses for ``why'' questions \cite{hanson1965patterns,magnani2011abduction}, the significance of analogical reasoning \cite{hesse1965models,gentner2002analogy}, the interpretation of scientific discovery as a form of search problem \cite{langley1987scientific}, and the conceptualization of hypothesis generation as probabilistic sampling \cite{dasgupta2017hypotheses}.

The potential for machines to generate hypotheses has been a focal point in artificial intelligence research. Pioneering attempts to develop machines capable of hypothesis generation date back to the early 20th century \cite{langley1987scientific,lindsay1993dendral}. By the mid-2000s, advancements led to the creation of machines capable of making autonomous scientific discoveries \cite{king2004functional}.


% The second element is hypothesis generation. Research involves posing questions and attempting to answer them. Researchers often divide the process of answering these questions into two parts: generating hypotheses and verifying them. Generating a hypothesis is predicting an answer to a question, and verifying a hypothesis is the operation of checking whether it is actually plausible. Dividing the process of answering a question into these two stages is because research questions are such that no one in humanity knows the answers, making it practically difficult to hit upon the answer at once, and because an individual's thinking is not necessarily truth-promoting. In other words, the separation of hypothesis generation and verification is a methodology developed by humans to reveal the truth of this world under very high uncertainty.

% The generation of hypotheses has been recognized as a place where human creativity in research is exhibited. The idea that human creativity cannot be analyzed has led to the long-held view that constructing questions and generating hypotheses are difficult to analyze \cite{sep-scientific-discovery}. However, attempts to characterize this creative activity have emerged since the mid-20th century. For instance, the importance of abduction in generating hypotheses for why questions \cite{hanson1965patterns,magnani2011abduction}, the importance of analogical reasoning in hypothesis generation \cite{hesse1965models,gentner2002analogy}, the interpretation of scientific discovery as exploration \cite{langley1987scientific}, and the formulation as probabilistic sampling \cite{dasgupta2017hypotheses} have been pointed out. Hypothesis generation by machines has been one of the greatest interests since the advent of artificial intelligence research, and attempts at its realization have been made early on. As early examples, the development of machines that generate hypotheses was attempted as early as the 1900s \cite{langley1987scientific,lindsay1993dendral}, and by the mid-2000s, machines capable of autonomously making scientific discoveries were developed \cite{king2004functional}. 

\subsubsection{Hypothesis Generation and Machine Learning}
Generating hypotheses is predicting answers to questions from existing knowledge. This process aligns closely with machine learning, particularly question-answering. As it involves predicting answers that even nobody knows, it can also be viewed as a prediction under significant distribution shifts.

Indeed, machine learning have become increasingly prominent in scientific hypothesis generation \cite{xu2021artificial,zhang2023artificial,wang2023scientific}. Predicting new proteins, drug candidates, and novel physical properties are all examples of hypothesis generation.

The sources for hypotheses, the nature of the hypothesis space, and the representation of hypotheses differ across research fields. For instance, hypotheses can be represented combinatorially, and machines can be employed to explore these spaces to find hypotheses \cite{coley2020autonomous}. Some studies represent hypotheses as symbolic equations and try to discover them from scientific data \cite{kramer2023automated}, while others endeavor to generate or extract textual hypotheses from academic papers \cite{kang2022augmenting,chan2018solvent,wang2023learning,xu2023exploring,yang2023large}. The advent of LLMs has spurred efforts to generate hypotheses from the models' internal knowledge, without relying on direct information from academic papers \cite{park2023can,ai4science2023impact}.

While the specifics of hypothesis generation vary, a unified description can be drawn from certain perspectives. Viewing the hypothesis space as a human-defined and fixed entity, scientific discoveries can often be framed as search problems \cite{coley2020autonomous}. 
Since the hypothesis space is often combinatorially vast, strategies for efficient exploration in the space deemed necessary \cite{coley2020autonomousII,zenil2023future}, and efforts have been made to optimize exploration with techniques such as active learning. As another perspective, Wang et al. provide a categorization of how AI is utilized in scientific hypothesis generation, highlighting its applications in black box prediction, aiding hypothesis space exploration, and finding solutions within a differentiable hypothesis space \cite{wang2023scientific}.

As such, integration of machine learning to hypothesis generation has progressed significantly compared to question formulation and hypothesis testing. The examples cited here represent only a segment of the extensive research in this area. Although this paper cannot delve into each study in detail, those interested are encouraged to refer to survey papers in their respective fields.

While machine learning's application in hypothesis generation is notable, the development of AI capable of generating complex hypotheses in response to varying questions remains a challenge. Achieving such capability may require abilities to generate hypothesis in versatile and flexible manner and to construct hypothesis spaces themselves. Future discussions are expected to further explore how to realize these capabilities in AI.

% Generating hypotheses involves predicting answers to unknown questions from existing knowledge. This can be seen as making predictions about unseen data from data already seen, and can thus be reduced to the formulation of machine learning. In particular, since it involves answering a question, it can be directly equated to the question-answering tasks in machine learning. Furthermore, as it involves predicting answers that nobody knows, it can also be viewed as a machine learning prediction problem in situations with significant distribution shifts.

% Indeed, machine learning models are widely used for hypothesis generation in science \cite{xu2021artificial,zhang2023artificial,wang2023scientific}. Examples include predictions of new proteins, drug candidates, or new physical properties. All such scientific discoveries made without the verification of machine learning models can be interpreted as applications of machines in scientific hypothesis generation. The specific methods of hypothesis generation in each application vary greatly, but they all share the function of generating hypotheses in the process of knowledge creation.

% What is used as the basis for generating hypotheses, the nature of the hypothesis space, and how hypotheses are expressed, vary across research fields. For instance, hypotheses may be generated from papers, scientific data, or a predefined search space. They might be expressed as combinations of multiple elements, as mathematical models represented by equations, or in text form. In chemistry, for example, hypotheses are often combinatorially represented, and the discovery of hypotheses by machines has been attempted by exploring this chemical design space \cite{coley2020autonomous}. Research has been conducted to find symbolic equations that describe the laws behind scientific data \cite{kramer2023automated}. There are also many studies that generate or extract hypotheses as text from groups of papers \cite{kang2022augmenting,chan2018solvent,wang2023learning,xu2023exploring,yang2023large}.

% In recent years, with the rise of large-scale language models, there have been efforts to generate hypotheses solely from the internal knowledge of the language models, without directly providing information from papers \cite{park2023can,ai4science2023impact}.

% While the specifics of individual hypothesis generation vary, it is possible to uniformly describe them to some extent from a certain viewpoint. For example, if we assume that the hypothesis space is provided and fixed by humans, we could say that many scientific discoveries can be seen as search problems \cite{coley2020autonomous}. Especially in science, the hypothesis space is often combinatorially vast. Therefore, it is considered important to efficiently explore such vast search spaces \cite{coley2020autonomousII,zenil2023future}, and attempts have been made to achieve efficient exploration through methods like active learning. As an another perspective, Wang et al. have organized studies applying machine learning to hypothesis generation. They have categorized and organized how AI is being used for scientific hypothesis generation from the perspective of using it for black box prediction, aiding in the exploration of hypothesis space, and finding solutions in a differentiable hypothesis space \cite{wang2023scientific}.

% As such, the application of machine learning to hypothesis generation has progressed significantly compared to question formulation and hypothesis testing. The examples mentioned here are just a fraction of the extensive research that uses machine learning for hypothesis generation. Although this paper cannot delve into each study in detail, those interested are encouraged to refer to survey papers in their respective fields.

% There are indeed numerous instances where machine learning has been applied to hypothesis generation. However, how to realize AI that can generate hypotheses in response to questions remains an open question. To achieve such AI, as mentioned earlier, it may be necessary to appropriately switch the expression and design methods of hypotheses according to the question, or to design the hypothesis space from scratch. Further discussion on how to realize these capabilities is expected to deepen in the future.


\subsubsection{Conjectures around Hypothesis Generation by Machines}
It can be said that autonomous hypothesis generation in general manner by AI has already gained considerable attention, compared to question generation and hypothesis verification. That's largely because, as previously mentioned, predicting answers to questions is a challenge already central to many machine learning researchers. Therefore, many challenges in aiming for AI that generates hypotheses as flexibly as humans overlap with the challenges of pursuing an artificial general intelligence (AGI). These include systematic thinking such as deduction, out-of-distribution generalization, causal inference, efficient exploration, and problem decomposition, all crucial for autonomous flexible hypothesis generation and considered fundamental in the pursuit of AGI as well.

In this section, I will preliminary explore elements deemed important for AI's ability to generate hypotheses. However, due to the circumstances mentioned in the previous paragraph, this discussion might intersect with existing debates in the realm of AGI, potentially lacking novelty. Nonetheless, I will explore two aspects that appear vital for the development of an artificial hypothesis generator.

Firstly, an important aspect to note is that the answers to the questions can be unknown to even AI. It's not always the case that answer to the question unknown to humans is also unknown to machine, as repeatedly emphasized. However, if the answer is unknown to both humans and the machine, hypothesis generation becomes a challenging task even for AGI. Admittedly this essentially is a problem of out-of-distribution generalization, it's particularly challenging as no agents in this world know the answer. To solve such problems, machines, like humans, may need to recognize their ignorance of the answer, reduce uncertainty step-by-step, and gradually approach the answer. Current AI still does not even understand what it doesn't know \cite{guo2017calibration,maynez2020faithfulness}. How AI capable of reasoning under such high uncertainty can be realized remains an open question.

Secondly, the role of mathematics in hypothesis generation cannot be overstated. The first point to note is that the power of mathematics in hypothesis generation lies significantly in its deductive nature. Deduction ensures that if the premises are true, the resulting conclusions are also true, even if they may seem counterintuitive. This aspect gives AI, which largely depends on experiential inferences, a substantial advantage. Furthermore, as humans use the hypothetico-deductive method, deduction enables the evaluation of hypotheses that are not directly testable. If deductive results are rejected, the hypothesis is deemed false; acceptance, conversely, strengthens its plausibility. This plays a crucial role in expanding the empirical knowledge boundaries in research. 

The abstract nature of mathematics is also important. Since ancient times, even before the formalization of deductive methods, mathematics engaged with concepts such as numbers, which are fundamentally abstract and have long captivated human interest \cite{david2010history}. The introduction of symbolic representation and manipulation has further amplified its abstract nature. Significantly, mathematics not only abstracts real-world objects but also engages in a cycle of further abstraction. By abstracting already abstracted concepts, it has developed highly sophisticated systems \cite{bochner1968role}. This level of abstraction allows for the reference to subjects not directly experienced \cite{heisenberg2008abstraction} and facilitates the representation of general laws rather than just individual cases. These characteristics render mathematics an indispensable tool in the process of hypothesis generation.

While these elements are discussed separately, systematic thinking seems necessary for both, reinforcing the widely acknowledged importance of systematic or high-level thought in AI development. However, due to the extensive existing discourse on this topic \cite{goyal2022inductive}, I will not delve deeper into it here.

Due to my limitations, this paper only scratches the surface of this topic. I would appreciate any feedback from those with insights into elements not widely recognized in the machine learning community but deemed essential for autonomous hypothesis generation.

\subsection{Hypothesis Verification}
The final critical element in the research process is the verification of hypotheses. We justify our belief in the truth or falsehood of a hypothesis by confirming the plausibility of our prediction in response to a question through verification. Thus, verification is essential for generating knowledge.

Verification hinges on the nature of the question and hypothesis posed. For instance, a ``why'' question demands verification methods that elucidate causal relationships. Questions about the physical world require empirical interaction for verification. In cases where hypotheses are amenable to mathematical proof, such proof constitutes verification. This necessitates an agent capable of verification to possess an understanding of what constitutes verification and to develop suitable verification methods tailored to the specific question and hypothesis.

While there has been extensive discussion on AI in hypothesis generation, its involvement in verification is less explored. Certainly, some studies have utilized AI in aspects of verification, such as experimental design \cite{chaloner1995bayesian} and scientific simulations \cite{baker2019basic}. However, initiatives enabling AI to fully comprehend and independently execute verification processes akin to human scientific research are still limited. 

In machine learning, research focusing on the validation of scientific claims \cite{wadden2020fact}, factual accuracy of predictions \cite{guo2022survey}, evidence search to support hypotheses \cite{koneru2023can}, and self-verification of machine responses \cite{dhuliawala2023chain} aligns with aspects of verification. Nevertheless, none of them aim to construct and execute verification as humans do in a scientific research. The automation of peer review \cite{kousha2022artificial,lin2021automated1} is also related to verification in the sense that it demands judgment on the validity of the verification, but it does not generate verification.

In this section, I aim to delve into the concept of verification to stimulate further contemplation. Having already addressed the nature of verification, or justification, in Section \ref{section-what-is-research}, I will omit that discussion here. Instead, I will focus on experimentation, an essential aspect of human-like verification in scientific inquiry.


% Compared to hypothesis generation, there's less discussion about letting AI itself perform verification. While there have been many studies utilizing AI for parts of verification tasks, such as experimental design \cite{chaloner1995bayesian} and simulations in science \cite{baker2019basic}, initiatives that make AI understand what verification is and think from scratch about what needs to be done to verify hypotheses are still not widespread. Certainly, in machine learning research, studies on judging the validity of scientific claims \cite{wadden2020fact}, confirming whether predictions are factual \cite{guo2022survey}, searching for evidence to support hypotheses \cite{koneru2023can}, and studies making machines self-verify their answers \cite{dhuliawala2023chain} are strongly related to verification, but none of them aim to construct and execute verification like human scientific research. The automation of peer review \cite{kousha2022artificial,lin2021automated1} is also related to understanding verification in the sense that it demands judgment on the validity of the verification proposed in papers, but it does not generate verification.

% In this section, I will briefly explore the concept of verification to provide seeds of thought. Since I have already discussed what verification, i.e., justification, is in Section \ref{section-what-is-research}, I will skip that discussion here. Instead, in this section, I will discuss experimentation that is inevitable when conducting human-like verification in science.

\subsubsection{Experimentation}
\label{section-experimentation}
No researcher would deny the importance of experiments. An experiment involves the planning and execution of a series of procedures to empirically test a hypothesis, essentially constituting the process of verification in empirical science. Therefore, any agent capable of verification must necessarily possess the ability to conduct experiments.

In experiments, phenomena that are difficult to observe, or the effects of various conditions, are precisely investigated. This is achieved by artificially generating phenomena in a controlled manner and actively intervening in them \cite{radder2009philosophy}. Such interventions create differences in the relationships and causal connections of the variables of interest. These variables are observed and recorded as experimental data, and subsequent analysis determine the validity of the hypothesis from the data.\footnote{
Experiments are not conducted solely during the verification phase but also when generating hypotheses. Furthermore, new questions and hypotheses are often formulated based on the results obtained from experiments. In these instances, the process leading up to data generation, or conducting experiments not solely for verification but for data generation and some form of data analysis, seems to be what is referred to as an experiment. This paper defines an experiment as the planning, preparation, data generation, analysis, and determination of verification results. However, be aware that this definition may not always reflect actual practice.
}

To conduct an experiment, one must first design it, document the procedures, and plan its execution. This requires an understanding of what constitutes a successful hypothesis test and the ability to devise methods to realize this using existing technology. Preparations for the experiment are also essential. These preparations can include purchasing chemicals, preparing flasks, training animals, constructing necessary equipment, and sometimes even building large apparatus like accelerators from scratch. Applying to ethics committees and creating clean rooms are also integral steps. Unfortunately, since research aims to uncover the unknown, constructing equipment from scratch for experiments is not uncommon in research. The autonomous execution of these preparations by a non-human agent from scratch seems almost infeasible.

After the preparation for the experiment is complete, the experiment is conducted according to the experimental protocol. This task also presents considerable challenges for autonomous machines. The reason is that even a single experiment requires a myriad of low-level operations such as grasping, cutting, carrying, mixing, moving, pouring, dispensing, washing, and opening lids. These operations need to be flexibly combined and executed according to the self-generated experimental protocol. An autonomous machine capable of conducting experiments must possess the ability to generate these operations flexibly in response to the experimental protocol.





% No researcher would deny the importance of experiments. An experiment is the planning and execution of a series of procedures to empirically test a hypothesis, essentially the verification itself in empirical science. Therefore, any agent capable of verification must necessarily be able to conduct experiments.

% In experiments, phenomena that are difficult to observe or the effects of various conditions are precisely investigated by artificially generating phenomena in a controlled manner and actively intervening in them \cite{radder2009philosophy}. This creates differences in the relationships and causal connections of the variables of interest. These are observed and stored as experimental data, and the analysis of this data determines whether the hypothesis is true or not.\footnote{
% Experiments are not only conducted during the verification phase but also when generating hypotheses. Moreover, new questions and hypotheses are often formulated based on the results obtained from experiments. In these instances, the process leading up to data generation, or conducting experiments not solely for verification but for data generation and some form of data analysis, seems to be what is referred to as an experiment. This paper defines an experiment as planning, preparing, generating data, analyzing it, and determining verification results. However, be aware that this definition may not always reflect actual practice
% }

% To conduct an experiment, one must first design the experiment, write down the procedures, and plan the experiment. This requires an understanding of what constitutes a successful hypothesis test and the ability to conceive of ways to realize this using existing technology. Preparations for the experiment are also essential. This can include purchasing chemicals, preparing flasks, training animals, constructing necessary equipment, sometimes even building large apparatus like accelerators from scratch, applying to ethics committees, and creating clean rooms. Unfortunately, since research aims to uncover the unknown, constructing equipment from scratch for experiments is not uncommon in research. The autonomous execution of these preparations by a non-human agent from scratch is considerably challenging.

% After the preparation for the experiment is complete, the experiment is conducted according to the experimental protocol. This is also very challenging for a machine to perform autonomously. The reason is that even for a single experiment, a myriad of low-level operations such as grasping, cutting, carrying, mixing, moving, pouring, dispensing, washing, and opening lids need to be flexibly combined to execute the experiment. An autonomous machine capable of conducting experiments needs the ability to generate these operations flexibly according to the self-generated experimental protocol.

\subsubsection{Automating Experimentation}
As we observe, the challenge of making a machine fully autonomous in planning, preparing, and executing experiments is considerable. Particularly, since the specific experiments to be conducted cannot be determined until questions and hypotheses are formulated, enabling a machine to autonomously conduct research from question construction demands the capability to accommodate all possible experimental scenarios. This, I believe, represents one of the greatest barriers to creating machines capable of autonomously conducting research.

Automating experiments is a daunting task, yet humanity has made steady progress in this area. In relation to the planning stage of experiments, the automation of exploring experimental conditions have a long-standing history. Wang et al. have summarized these studies, which utilize AI to assist in experiment planning, research guidance, and generating observational data through numerical simulations \cite{wang2023scientific}.

Furthermore, there is an initiative known as \textit{laboratory automation} or \textit{self-driving lab} that aims to automate experiments, including their execution – an aspect previously mentioned as challenging \cite{holland2020automation,abolhasani2023rise}. A notable example is the research in genetics by King et al., who fully automated the cycle of hypothesis generation, verification, and the discovery of new hypotheses \cite{king2004functional}. Another example is the work of A.I. Cooper, which facilitated the use of experimental equipment by autonomous robots, similar to human researchers \cite{burger2020mobile}. These are just a few examples, and there is a vast number of studies in this field.

These examples illustrate efforts to autonomously drive the research cycle, encompassing hypothesis generation, planning and execution of experiments, and generation of new hypotheses based on experimental results. Such endeavors are referred to as the \textit{closed-loop} automation of scientific discovery \cite{zenil2023future}, representing a significant milestone in achieving high autonomy in research automation. Additionally, there are efforts to develop humanoid robots capable of conducting multiple different experiments with a single robot, considered a foundational step towards more generalized research automation \cite{yachie2017robotic}.

In recent years, there have been efforts to enable autonomous experiment conduction using LLMs \cite{boiko2023emergent,charness2023generation,qin2023gpt}. For instance, Boiko et al. developed an autonomous agent comprising multiple LLMs that successfully designed and executed complex scientific experiments \cite{boiko2023emergent}.

While we have primarily discussed experimental data generation process,  validation also requires interpretation of the data. Observation inherently involves theoretical underpinnings \cite{hanson1965patterns}. Hence, interpreting experimental data necessitates adequate prior knowledge. Some studies are therefore focused on enabling machines to interpret scientific data by embedding physical prior knowledge, like symmetries, differential equations, and intuitive physics, into machine learning models \cite{hao2022physics,karniadakis2021physics}.\footnote{
Interpretation of scientific data is not solely for validation purposes. Consequently, these technologies extend beyond just automating validation processes.
}

Various research efforts have significantly advanced the automation of experiments. However, it is also true that numerous challenges remain in realizing machines capable of autonomously conducting experiments. Coley et al. delve into these challenges, emphasizing the automation of experimental and computational validations and the selection of experiments, while referring to studies on automated verification \cite{coley2020autonomousII}. Particularly, to achieve a versatile automated experimental machine adaptable to diverse research tasks, the development of robots capable of manipulating low-level actions as humans do is essential, yet exceedingly challenging. Nonetheless, efforts aimed at removing hardware constraints to increase the automatability of research projects and reducing the costs associated with research automation are also of significant importance \cite{coley2020autonomousII}.

% As we can see, making a machine fully autonomous in not only planning but also preparing and executing experiments is considerably difficult. Especially since what experiments should be conducted cannot be known until questions and hypotheses are formulated, enabling a machine to autonomously conduct research from the construction of questions demands the capability to accommodate all possible experimental scenarios. I consider this to be one of the greatest barriers in creating machines capable of autonomously conducting research.

% Automating experiments is a very challenging task, yet humanity has steadily made progress in this difficult endeavor. Related to the planning stage of experiments, for example, the efficiency and automation of exploring experimental conditions have a long history. Wang et al. have summarized these studies that utilize AI to assist experiments by research planning, research guidance, and generating observational data through numerical simulations \cite{wang2023scientific}. 

% Additionally, there is an initiative known as \textit{laboratory automation}, or \textit{self-driving lab} that attempts to automate experiments, including the execution of experiments, which, as mentioned earlier, is a challenging aspect \cite{holland2020automation,abolhasani2023rise}. A notable example is pioneering research in genetics by King et al., who fully automated the cycle of hypothesis generation, verification, and discovery of new hypotheses \cite{king2004functional}. Another example is A.I. Cooper, which enabled the use of the same experimental equipment as humans through autonomous robots \cite{burger2020mobile}. 

% These examples of initiatives aim to autonomously drive the research cycle, including hypothesis generation, planning and execution of experiments, and generation of hypotheses based on experimental results. Such initiatives are referred to as the closed-loop automation of scientific discovery     \cite{burger2020mobile,king2004functional}. This represents an example of achieving extremely high autonomy in the quest for research automation. Furthermore, there are efforts to develop humanoid robots for experiments, capable of conducting multiple different experiments with a single robot \cite{yachie2017robotic}. This is deemed to be a foundational step towards potentially general research automation. 

% In recent years, there have also been attempts to conduct experiments autonomously using LLMs \cite{boiko2023emergent,charness2023generation,qin2023gpt}. For example, Boiko et al. constructed an autonomous agent composed of multiple LLMs and let it autonomously conduct from designing to executing experiments, leading to successful performance on complex scientific problems \cite{boiko2023emergent}. 

% So far, we have primarily discussed the generation of experimental data, but to validate it, interpretation is necessary. Observation always entails some theory behind it \cite{hanson1965patterns}, and to analyze and interpret experimental data, sufficient prior knowledge is required. Therefore, there are studies focused on enabling machines to interpret scientific data by embedding physical prior knowledge such as symmetries, differential equations, and intuitive physics into machine learning models \cite{hao2022physics,karniadakis2021physics}.\footnote{
% The interpretation of scientific data is not always done solely for the purpose of validation. Therefore, these technologies are not limited only to the automation of validation processes.
% }

% Various research efforts have steadily advanced the automation of experiments. On the other hand, it's also true that there are still many challenges in realizing machines capable of conducting experiments autonomously. Coley et al. discuss these challenges in detail, focusing on the automation of experimental and computational validations and the selection of experiments, referencing studies on automated verification \cite{coley2020autonomousII}. In particular, to achieve a versatile automated experimental machine adaptable to various research tasks, robots that can manipulate low-level actions as humans do are necessary, which is exceedingly difficult to realize. Even short of this, efforts such as removing hardware constraints to increase the number of automatable research projects and reducing costs for research automation are also important \cite{coley2020autonomousII}.


\section{Additional Topics}

\subsection{Combining Questions, Hypotheses, and Verification}
I have been speculatively discussing the construction of questions, generation of hypotheses, and verification of hypotheses, which are the essential elements of research. Looking back at completed studies, we can indeed find that each study had its own question, a hypothesis for that question, and a verification for that hypothesis. From this perspective, it can be said that research is an endeavor consisting of the continuous process of constructing questions, generating hypotheses, and verifying hypotheses, as has been classically described.

On the other hand, as you know, actual research is an extremely complex process of trial and error, and it is rare for these tasks to be done only once each in a single study as initially anticipated. In reality, for example, countless questions and hypotheses are generated even for formulating a single hypothesis, and not all of them necessarily lead to the final research outcome. 

Thus, it is more appropriate to view the construction of questions, generation of hypotheses, and verification of hypotheses as basic operations to reduce uncertainty, and we combine them to reduce the huge uncertainty gradually in the process of research. Especially in the work of discovery like constructing questions and generating hypotheses, these trial-and-error nature is considered to be important \cite{yanai2020hypothesis}.

To create an AI capable of conducting research, it seems essential to seamlessly integrate the construction of questions, the generation of hypotheses, and the testing of these hypotheses, enabling it to perform complex research practices. Therefore, in this section, we will focus on characteristics of research that have not been discussed so far and examine the considerations necessary for developing such an AI.

% 研究の構成要素である問いの構築、仮説の生成、仮説の検証について思索的に議論してきました。すでに終了した研究を振り返ると、実際にその研究の問いがあり、問い対する仮説があり、仮説に対する検証が見つけられます。この観点からすれば、研究とは、古典的に語られてきたように、問いの構築、仮説の生成、仮説の検証の連続からなる営みであるということもできます。

% 一方で、実際の研究は極めて複雑な試行錯誤的なプロセスであり、問いの構築、仮説の生成、仮説の検証が一度の研究で最初に想定していた通りそれぞれ一回ずつしか行われないということは稀です。実際にはたとえば一つの仮説を立てるのにも無数の問いや仮説を生成していますし、そのすべてが必ずしも最終的な研究成果につながるわけではありません。問いの構築、仮説の生成、仮説の検証はむしろ不確実性を削減するための基本的な操作と見る方が適切であり、それらを複雑に組み合わせてより大きな研究課題の不確実性を削減していると見る方が実際の研究の営みにも沿っているでしょう。特に、問いの構築や仮説の生成といった発見的な作業の中ではこのような試行錯誤的な要素がより重要になってくると思われています \cite{yanai2020hypothesis}。

% I believe that all endeavors to transform the unknown into the known, to some extent, inevitably involve the construction of questions, the generation of hypotheses, and the verification of these hypotheses.

% 研究ができる AI を作るためには、問いの構築、仮説の生成、仮説の検証を自在に組み合わせて、このような複雑な研究実践ができなければならないように思われます。そこで、本セクションでは、これまであげてこなかったような、研究の特徴に注目しながら、そのような AI を作るために考慮すべきであろう事項について検討していきます。

% \subsubsection{Human Research Practice and Knowledge Production System}
% In actual research, while addressing the initial question posed, another question may arise and the focus may shift to that new question. Also, before reaching the final hypothesis that gets reported, several different hypotheses are tested repeatedly. Like this, the actual practice of research is complex.\footnote{
% For example, the concept of \textit{night science} as proposed by Yanai and Lercher symbolizes the such complex reality of research practice \cite{yanai2019night}.
% } When compared to this trial-and-error process, the framework I have proposed may seem overly simplified at first glance. However, I believe that the framework I proposed encompasses these human practices as well.


\subsubsection{Countless Question, Hypothesis, and Verification in Single Research Process}


\textcolor{red}{問いや仮説や検証が組み合わされる小さな単位であり、それらは単線的なプロセスではないということを強調するポンチ絵を置く}

We generate countless questions and hypotheses, including implicit ones, for the purpose of creating a single question or hypothesis, or for planning and preparing for single verification. It appears that historically, some of the major scientific discoveries were also brought about through such a process \cite{hanson1965patterns,gribbin2022origin,whiteside1970before}.

For example, when questioning how an unresolved issue can be solved, we might ask why this problem hasn't been solved so far, or if there are any studies of similar challenges being addressed. In response, we might consult literature or recall our own memory, hypothesizing that ``This could be the reason it hasn't been solved,'' or that ``This could be useful in solving the current challenge.'' We repeat this process innumerably to eventually construct an answer to the original question. Similarly, when planning verification, we implicitly pose many questions and formulate numerous auxiliary hypotheses.

To generate a plausible hypothesis, there must be sufficient grounds to believe it is valid. These grounds could be knowledge from our own memory, descriptions from newly researched literature, opinions from other researchers, or some belief, such as natural law should be simple. In addition, to examine the validity of the hypothesis, we might try simple tests. We sometimes even conduct preliminary experiments to assess the plausibility of a hypothesis. In other words, each time a plausible hypothesis is generated, it undergoes a sort of verification, whether implicit or explicit, and to varying degrees of simplicity.

In this way, to conduct research, we pose countless questions and hypotheses and conduct several simple  experiments to verify the plausibility of the hypothesis if necessary. We could say that research is a hierarchical composition of question construction, hypothesis generation, and hypothesis verification. 

These numerous question, hypotheses and verification stem from the fact that research contains a lot of uncertainties and they are required for gradual reduction of these uncertainties. Therefore, agents capable of conducting research should autonomously be able to generate numerous questions and hypotheses as needed and choose more plausible hypotheses through simple verification during the knowledge production process.

% This is because research is an endeavor facing the unknown, and this process contains a lot of uncertainties. By gradually reducing these uncertainties through trial and error, research progresses. This gradual reduction of uncertainty seems essential, especially when tackling difficult questions that no one in the world knows the answers to. Therefore, AI capable of conducting research should autonomously be able to generate numerous questions and hypotheses as needed and choose more plausible hypotheses through simple verification during the knowledge production process.

% 私たちは、一つの問いや仮説を生成するために、あるいは検証の計画や準備をするために、暗黙的なものも含めると無数の問いや仮説を生成しています。

% 例えば、ある解決されてない課題をどのように解くことができるか問うた場合、ではそもそもなぜこの問題はこれまで解かれてこなかったのだろうか、似たような課題に取り組んでいる事例はないだろうか、と問うかもしれません。これに対して文献を調べたり過去の知見を思い出したりして、これが原因で解けなかったのではないか、これは今回の課題の解決に使えるのではないか、といった仮説を立てるでしょう。これを無数に繰り返して、最終的に元々答えたかった問いに対する答えを構成します。また、検証の計画を立てる際にも、私たちは暗黙的に多くの問いを立てて無数の補助仮説を立てています。

% 確からしい仮説を生成するためには、その仮説が妥当であると信ずるだけの根拠がなければなりません。その根拠となるのはは自分の記憶にある知識かもしれませんし、新しく調べた文献の記述かもしれませんし、他の研究者の意見かもしれません。これに加えて、確からしい検証をするために、私たちは試してみる、すなわち簡単な検証をすることもあります。例えば、仮説を表現するトイモデルを作って挙動を調べてみるかもしれませんし、プレ実験をしてみるかもしれません。

% このように、私たちは一つの問いを作り、それに答える一つの仮説を作り、それを一度検証するために、無数の問いと仮説を立て、必要とあれば仮説の確からしさを簡単に検証するいくつもの実験を行います。これは、研究が未知に立ち向かう営みであり、その過程にはいくつもの不確定な要素が存在するからです。それらの不確実性を一歩一歩試行錯誤的に削減していくことで、一つの研究が進んでいくように思われます。このような漸進的な不確実性の削減は、特に誰も答えを知らないような難しい問いに挑戦する際には不可欠であるように思われます。従って、研究ができる AI もこのように、必要に際して問いや仮説を生成し、簡易的な検証によってより確からしい仮説を選択するということを自律的に行えるようになる必要があるでしょう。

\subsubsection{Countless Seemingly Unrelated Operations to Knowledge Production}
\label{section-countless-seemingly-unrelated-operations-to-knowledge-production}

Research consists of numerous operations that may seem unrelated to the production of knowledge at first glance. In Section \ref{section-experimentation}, we discussed that such tasks are necessary in the context of experimentation. While Latour illustrates these realities in his study \cite{latour1987science}, it should be undoubtedly clear to many researchers that daily academic activities are shaped by these operations, even without referring to such literature.

The construction of questions, the generation of hypotheses, and the verification of these hypotheses are the goals we aim to achieve and functions in the knowledge production process, not their implementations. To implement these functions, it is essential to perform operations like those mentioned above and to combine them appropriately to achieve the desired objectives. Combining these various operations appropriately is a challenging task, even when specialized for a specific research question \cite{coley2020autonomousII}. If we aim to create an agent that can autonomously execute the entire research process, starting from generating questions, the ability to produce these actions as flexibly as humans would be essential.

% 研究は、一見すると知識生産に関係がないような無数の操作によって成り立っています。セクション \ref{section-experimentation} では実験の場合を例として、このような作業が必要となることを述べました。 Bruno Latour は一つの研究室で行われる作業を人類学的に観察することで、こうした日常的実践が一見するとその意味がわからないような操作たちによって形作られていることを描き出していますが \cite{latour1987science}、このような文献を参照するまでもなく日々の学術活動が多くの非知的な操作によって形作られていることは多くの研究者にとって疑いのないことであると思います。

% 問いの構築や仮説の生成や仮説の検証は達成したい目的であり、知識生産過程における機能であって、その実装ではありません。これらの機能を実装するためには上述したような操作ができること、そしてそれらを適切に組み合わせて目標を達成するための作業をすることが不可欠となります。このような複数の異なる操作を適切に組み合わせることは、特定の研究課題に特化したとしてもなお難しい課題です \cite{coley2020autonomousII}。問いの生成から始めて研究の過程の全てを自律的に実行できるようなエージェントを仮に目指す場合、人間のように自在に行為を生成できるような能力を獲得することが不可欠です。

\subsubsection{Discovering New Questions}
% \textcolor{red}{手法から問題を考えることがある}

Researchers often set out to solve one question, only to find themselves discovering an entirely unrelated question in the process. This new question, unrelated to the original question and even its underlying purpose, may lead them to pivot their research focus and potentially make significant scientific discoveries. Since research is full of uncertainty, it's not uncommon to be unable to foresee everything from the start. Thus, this discovery and shift of question is not rare.

If an agent capable of conducting research were tasked with achieving a single objective, such serendipitous discoveries might not occur. This is because any new questions it finds, no matter how intriguing or scientifically important, may not be directly relevant to achieving its predefined goal. Therefore, to encourage the agent to uncover such unrelated questions, it might be necessary to set multiple objectives or a broader high-level goal that encompasses both original and newly found questions. 

Furthermore, it is not sufficient to just have a common high-level goal.
To switch from the current question to a new one, the agent would need to evaluate which of the two questions holds more value. Therefore, as discussed in Section \ref{section-deciding-what-knowledge-to-seek}, the decision-making process regarding the value of a question should not only determine whether to ask a particular question but also be capable of comparing multiple questions, including those that share higher-order objectives. How to realize such capabilities remains an open question.

% したがって、セクション \ref{section-deciding-what-knowledge-to-seek} で述べたような問いの価値に関する意思決定は一つのある問いを問うべきかだけではなくこのような高次の目的を共通するものも含めた複数の問いの間の比較もできるものでなければならないように思われます。

% 研究者は、ある問いを解くために別の問いを立てるだけではなく、その問いに答えようとする中で、最初の問いやその背後の目的とは全く関係ない別の問いを見つけることがあります。そして研究の途中でそちらの問いに取り組むことに切り替え、その結果大きな科学的発見を成し遂げることもあります。不確実性が高い研究という取り組みにおいては、最初から全てを見通せることは多くありません。したがって、このようなことが起こることは少なくありません。

% もし 研究ができる AI にある一つの目的を達成することを目指させるとしたら、このようなことは起き得ないでしょう。なぜなら、そこで見つかった問いはどれだけ面白くてもどれだけ科学的に重要でも、その目的を達成するために必ずしも重要とは限らないからです。したがって、AI にこのような問いの発見をさせるためには、複数の目標を持たせる、あるいは両方の問いを包括するようなより大きな（例えば「自然を理解する」のような）大きな目標を持たせる必要があるように思われます。加えて、現在やっている問いに取り組むのをやめて新しい問いに取り組む意思決定をするためには、AI はこれらの異なる二つの問いのどちらが価値があるかを比較しなければならないように思われます。

\subsubsection{Feedback from Verification Result}
% 化学自動化論文の内容もここに追加する
% how should new data acquired through experimental/computational validation be used to
% update models pretrained on literature data?

In research, it's not always common for the initial hypothesis to directly answer the question posed. Rather, the process typically involves revising the hypothesis based on the results of verification, followed by additional rounds of testing. This cycle of hypothesis revision and retesting is crucial in the journey toward finding answers to the posed questions, especially when seeking unknown answers, as mentioned earlier. Consequently, it seems necessary for an agent capable of conducting research to have the ability to revise its hypotheses based on the outcomes of these verifications.

As attempts to automate scientific discovery in a closed-loop manner, taking into account feedback from verification results, there are studies based on laboratory automation \cite{king2004functional} and scientific workflow \cite{gil2022will}. Such research has made a significant contribution by automating the core scientific activity of revising hypotheses based on verification results.

% こうした検証結果からのフィードバックも考慮した closed-loop な科学的発見の自動化を目指す試みとしては、laboratory automation \cite{king2004functional} や scientific workflow \cite{gil2022will} に基づく研究などがあります。このような研究は検証結果から仮説を修正するという科学の根幹の営みを自動化していくという上で極めて大きな貢献をもたらしたと言って良いでしょう。

% このような先進的な事例はあるものの、検証結果からのフィードバックを自律的に人間のようにできる機械の実現にはまだ多くの課題があるように思われます。例えば、検証結果から機械にフィードバックを出力させる場合、その検証結果を何に反映させるか、それを受けて何を修正すべきかは人間が事前に与えることがほとんどです。 

Despite such advanced examples, there still seem to be many challenges in realizing machines that can autonomously provide feedback from verification results like humans. For instance, when outputting feedback to a machine from verification results, what to reflect these results on and what to modify in response are mostly predetermined by humans. 

In reality, when the result for verification were negative, identifying the cause of the result is not that straightforward. This is because the verification relies on numerous implicit and explicit hypotheses and all of them can be the cause of the result \cite{sep-scientific-underdetermination}. The cause may be the proposed main hypothesis, a premise behind the hypothesis, an auxiliary hypothesis, an observation, an experimental instrument, or all of them. An agent that can conduct research must identify which of these possibilities is the cause. Once the candidates for the cause are determined, the agent has to generate a more plausible hypothesis based on the results of verification, as we have discussed so far.

Furthermore, to identify the cause, it would be necessary to appropriately interpret the data generated by experiments. However, what one reads from the data can change depending on the individual's beliefs, prior knowledge, theory, and what they expect to find \cite{hanson1965patterns}. Therefore, these verification results may be reinterpreted multiple times, and with each reinterpretation, the hypothesis that needs to be revised may change. Additionally, as mentioned in the previous section, humans sometimes come up with totally different questions based on verification results and stop the research for a while. Current machines still fall short of achieving these abilities of complex interpretation of verification results that humans are capable of. Ideally, agent capable of conducting research are expected to have such capabilities.
% 科学であれば、原因を特定するためには、実験によって生成されたデータを適切に解釈する必要があるでしょう。しかし、データから何を読み取るかは、その人の持つ信念や事前知識やそこから何を期待するかによって変わり得ます。したがって、この検証結果は何度も再解釈される可能性があり、その度に修正すべきだと思われる仮説が違ってくるかもしれません。研究ができる AI は理想的にはこのような可能性も視野に入れて検証結果を解釈していくことができるようになることが望まれるでしょう。


\subsection{Common Topics}
So far, I have conceptually discussed elements considered important in research and their combination. In this section, I would like to explore topics that are relevant to all these elements, as well as some topics that have not been covered in this paper.

% これまで、研究において重要であると思われる要素である、問いの構築、仮説生成、仮説検証について議論し、その後でそれらを組み合わせた場合に関連する話題について議論をしました。このセクションでは、これらすべての機能に関連しうるような話題や、これまでのセクションでは触れられなかった話題のうちのいくつかについて議論していきたいと思います。

\subsubsection{Language Models}
The rapid development of language models in recent years has led to numerous innovative achievements \cite{zhao2023survey}. It is unimaginable that future research agents will not utilize the insights of language models. In this section, I will look over some attempts at scientific discoveries using language models.

Since the advent of the Transformer \cite{vaswani2017attention} and its successor BERT \cite{devlin2018bert}, it has become common to pre-train language models on large-scale corpora. In particular, with the introduction of the concept of a \textit{foundation model}, pre-trained models that can be used for many downstream tasks \cite{bommasani2021opportunities}, there has been an acceleration in efforts to construct such foundational models. In the field of science too, there have been attempts to create scientific language models pre-trained on scientific texts and to build foundational models for science \cite{beltagy2019scibert,singh2022scirepeval,nadkarni2021scientific,cohan2020specter,gupta2022matscibert,taylor2022galactica,azerbayev2023llemma,xie2023darwin,luo2022biogpt,li2023llava}. Moreover, as scientific data is not just textual but requires multiple modalities, there have been efforts to create scientific foundation models pre-trained on such multimodal data \cite{singhal2023towards,takeda2023foundation,nguyen2023climax}.

When OpenAI developed GPT-3 \cite{brown2020language}, ChatGPT (GPT-3.5) \cite{ChatGPT}, and GPT-4 \cite{GPT4} (I will refer to them as GPTs), these models garnered significant attention for their ability to perform a wide range of intellectual tasks with considerable accuracy. Following this, there was an increase in research examining the scientific understanding of GPTs, as well as studies attempting to use GPTs directly for scientific tasks \cite{bordt2023chatgpt,white2022large}. Particularly, with the initiation of efforts to connect these GPTs to form pipelines or autonomous agents, studies also emerged that involved implementing scientific tasks through such agents \cite{wang2023survey}.

There have been various attempts to use large language models for automating all processes of knowledge discovery across various fields. In terms of research areas, this includes applications in natural sciences  \cite{ai4science2023impact,bran2023chemcrow,white2022large,hatakeyama2023prompt,jablonka202314,guo2023can,boiko2023emergent,charness2023generation,qin2023gpt,zheng2023large,qian2023can,wysocka2023large,lee2023benefits,nori2023capabilities,wang2023large,singhal2023large,yang2022gatortron,deng2023learning,merchant2023scaling}, applications in mathematics and engineering \cite{wu2023empirical,pursnani2023performance,zheng2023can,zhang2023automl}, and applications in social sciences \cite{wang2023survey,bail2023can,ziems2023can,park2023generative,horton2023large,koneru2023can}. Additionally, there are efforts applicable to all research fields, which involve using GPTs for processing academic documents \cite{alzaabi2023chatgpt}. Some of them include paper processing \cite{elicit,scispace,van2023chatgpt}, paper search \cite{elicit,scispace}, paper writing \cite{transformer2022can}, abstract generation \cite{gao2023comparing}, literature review generation \cite{aydin2022openai}, and peer review \cite{wexin2023can,liu2023reviewergpt,robertson2023gpt4,hosseini2023fighting}. 

In the process of automating research, there are examples ranging from models that generate hypotheses, to those that discover and create research topics and research questions \cite{oppenlaender2023mapping,lahat2023evaluating}, and even to those used in the entire research process, including experiments \cite{boiko2023emergent,charness2023generation,qin2023gpt}. The innovative performance of such language models and their rapid spread into scientific research have sparked much debate within the scientific community \cite{birhane2023science}.

These are just a few examples of the use of language models. Furthermore, research and development on language models are progressing rapidly on a daily basis. It is hoped that further exploration will be made into the potential applications of these technologies for automating research.

% 近年の言語モデルの急速な発展は数々の革新的な成果を生み出してきました \cite{zhao2023survey}。将来研究ができるエージェントが言語モデルの知見を活用しないことは考えられないでしょう。このセクションでは、言語モデルを使った科学的発見の試みについて議論します。

% 言語モデルは Transformer と続く BERT の登場以降、大規模コーパスによって事前学習をする試みが一般的となりました。特に、多くの下流タスクに使えるモデルという基盤モデルという概念が導入されると \cite{bommasani2021opportunities}、このような基盤モデルの構築を目指す動きが加速しました。科学の分野においても、科学的テキストで事前学習をした科学的言語モデルを作成する試みや科学の基盤モデルを作ることを目指す動きが出てきました \cite{beltagy2019scibert,singh2022scirepeval,nadkarni2021scientific,cohan2020specter,gupta2022matscibert,taylor2022galactica,azerbayev2023llemma,xie2023darwin,luo2022biogpt,li2023llava}。 また、科学的データはテキストデータだけではなく複数のモダリティのデータが必要となるので、そのようなマルチモーダルなデータで事前学習した科学的汎用モデルを作る取り組みも現れました \cite{singhal2023towards,takeda2023foundation,nguyen2023climax}。

% OpenAI が GPT-3 \cite{brown2020language}, ChatGPT (GPT-3.5) \cite{ChatGPT}, GPT-4 \cite{GPT4} を開発すると（以下 GPTs）、これらのモデルがかなりの範囲の知的タスクかなりの精度でこなすことができることで大きな注目を集めました。それを受けて、GPTs の科学的理解を調べる研究や GPTs をそのまま用いて科学的タスクの遂行を試みる研究が増加しました \cite{bordt2023chatgpt,white2022large}。特に、これらの GPTs をつなぎ合わせてパイプラインや自律的エージェントを構成する取り組みが始まると、科学的タスクをこのようなエージェントに実施させる研究も現れました \cite{wang2023survey}。

% それが科学的な基盤モデルを作る試みへとつながりました \cite{taylor2022galactica}。

% さまざまな分野の知識発見のあらゆる過程の自動化に大規模言語モデルを用いる様々な試みがあります。研究分野で言えば、化学や材料科学などの自然科学への適用 \cite{ai4science2023impact,bran2023chemcrow,white2022large,hatakeyama2023prompt,jablonka202314,guo2023can,boiko2023emergent,charness2023generation,qin2023gpt,zheng2023large,qian2023can,wysocka2023large,lee2023benefits,nori2023capabilities,wang2023large,singhal2023large,yang2022gatortron,deng2023learning,merchant2023scaling}、数学や工学への応用 \cite{wu2023empirical,pursnani2023performance,zheng2023can,zhang2023automl}
% 社会科学への応用 \cite{wang2023survey,bail2023can,ziems2023can,park2023generative,horton2023large,koneru2023can} などがあります。また、全ての研究分野に共通するものとして、学術文書の処理を GPT に行わせる取り組みもあります \cite{alzaabi2023chatgpt}。 

% 化学 \cite{bran2023chemcrow,jablonka202314,white2022large,hatakeyama2023prompt,jablonka202314,guo2023can} や材料科学 \cite{jablonka202314,jablonka202314,xie2023large,kang2023chatmof,merchant2023scaling}


% 特に、自動化する研究の過程としては、仮説の生成過程はもちろんこと、研究課題やリサーチクエスションの発見や生成 \cite{oppenlaender2023mapping,lahat2023evaluating} をさせるものから、実験も含めた研究の全過程に使用するような例まで登場しました \cite{boiko2023emergent,charness2023generation,qin2023gpt}。このような言語モデルの革新的な性能と急激な科学研究への広まりは、科学コミュニティに対して多くの議論を呼んでいます \cite{birhane2023science}。

% 参考
% 自律的エージェントを科学へ応用 \cite{wang2023survey}.

% LLMs are used for scholarly document processing \cite{alzaabi2023chatgpt}, some of which include paper processing \cite{elicit,scispace,van2023chatgpt}, paper search \cite{elicit,scispace}, paper writing \cite{transformer2022can}, abstract generation \cite{gao2023comparing}, literature review generation \cite{aydin2022openai}, and peer review \cite{wexin2023can,liu2023reviewergpt,robertson2023gpt4,hosseini2023fighting}. 

% 研究課題の発見 \cite{oppenlaender2023mapping}、リサーチクエスチョンの生成 \cite{lahat2023evaluating}

% LLM の科学的知識の理解を調べる研究があります。コンピューター科学
% \cite{bordt2023chatgpt} 化学 \cite{white2022large}

% 社会科学への応用があります \cite{wang2023survey,bail2023can,ziems2023can,park2023generative,horton2023large,williams2023algorithmic}.

% 科学の基盤モデルを作る試み \cite{taylor2022galactica}

% molecular data,  protein language models,  DNA and RNA などの事前学習済みモデルを紹介してる \cite{ai4science2023impact}

% generalist model \cite{tu2023towards}

% 科学に 特化した言語モデル\cite{beltagy2019scibert,singh2022scirepeval,nadkarni2021scientific,cohan2020specter,gupta2022matscibert,taylor2022galactica,azerbayev2023llemma}. 

% マルチモーダルな基盤モデル \cite{singhal2023towards,takeda2023foundation,nguyen2023climax}.

% 科学的言語モデル（事前学習済みモデル） \cite{xie2023darwin,luo2022biogpt}

% 科学実験 \cite{boiko2023emergent,charness2023generation,qin2023gpt}.

% 化学 \cite{bran2023chemcrow,jablonka202314,white2022large,hatakeyama2023prompt,jablonka202314,guo2023can}

% 材料科学 \cite{jablonka202314,jablonka202314,xie2023large,kang2023chatmof}

% サーベイ \cite{wang2023survey}

% molecular property prediction \cite{zheng2023large,qian2023can} (Physiology, Biophysics, Physical Chemistry, and Quantum Mechanics)

% buisiness and management \cite{williams2023algorithmic}

% biomedicine, medical science \cite{wysocka2023large,lee2023benefits,nori2023capabilities,wang2023large,singhal2023large,yang2022gatortron} (not factual base)

% 地球科学 \cite{deng2023learning}

% 数学 \cite{wu2023empirical}

% アシスタント \cite{lubiana2023ten}

% エンジニアリング \cite{pursnani2023performance}

% 網羅的 by microsoft \cite{ai4science2023impact}

% 機械学習 \cite{zheng2023can,zhang2023automl}

% Instrut Tuning for Science \cite{horawalavithana2023scitune}

% Science in the age of large language models \cite{birhane2023science}

\subsubsection{Incorporating Scientific Knowledge}

I have been discussing the challenges of enabling machines to conduct research, but it's important to note that in the first place it's nearly impossible even for humans to conduct research from complete zero. 

In the first place, we humans inherently possess brains and bodies that are suited to thinking about this world, shaped through the process of evolution and development. Moreover, before conducting research, we study the academic field we are interested in and acquire basic knowledge in that area. Therefore, it would be reasonable to assume that agents should also have previously acquired fundamental knowledge about the world before it starts conducting research.

The group of studies that incorporate such biases or scientific knowledge to handle scientific data on AI is called \textit{physics-informed machine learning} \cite{karniadakis2021physics}. The incorporated biases include the ability to handle partial differential equations (PDE), symmetry, and intuitive physics \cite{hao2022physics}. Karniadakis et al. \cite{karniadakis2021physics} and Hao et al. \cite{hao2022physics} systematically organize existing research in this field. As discussed in the previous section, efforts to impart scientific knowledge through pre-training on textual and multi-modal data also common.

Moreover, we humans continue to update our scientific knowledge continuously through study parallel to research, even after initially learning the basics. It is important for machines not only to embed knowledge through pre-learning and functional biases or to search during inference, but also to continuously update their knowledge through such learning processes.

Especially in the context of knowledge acquisition in research, it's crucial to recognize that the knowledge generated in research is always being updated. Therefore, an agent must not only assimilate new knowledge but also maintain the knowledge that has been generated, be aware of how previously learned knowledge is being revised, and reflect these modifications. While it still remains an open question, there are growing discussions on this topic \cite{kitano2021nobel,zenil2023future}.

% また、私たち人間は一度基礎を学習した後も研究と並行して勉強をすることで、自分の科学的知識を継続的にアップデートしています。事前学習や機能バイアスによる知識の埋め込みや、推論時の検索だけでなく、こうした学習による継続的な知識の更新を機械にさせることも重要でしょう。

% 特に、研究における知識獲得において重要な点として、研究において生み出された知識はそれ自体が常に更新されていくという点があります。したがって、エージェントは新しい知識を摂取するだけではなく、一度生み出された知識をメンテナンスし、過去に学んだ知識もどのように修正されているのかに気を配り、これらの修正を反映させることができなければなりません。こうしたことをどのように実現していくかの議論はありますが \cite{kitano2021nobel}、依然としてオープンクエスチョンです。

% これまで機械に研究をさせることの難しさについて議論してきましたが、そもそも人間に おいても完全なゼロから研究をするのはほぼ不可能です。人間も事前に研究したい分野の勉強をしてその分野の基本的な知識を獲得した上で、研究をします。したがって、AI も研究をする前にすでにこの世界に生み出されている基礎的な知識に関しては事前に獲得していることを想定するのが妥当でしょう。

% 仮説のアップデートの話

\subsubsection{Autonomy, Generality, and Open-Endedness}
As repeatedly stated, attempts to make machines generate questions, hypotheses, and validate these hypotheses already exist. The challenge lies in executing these tasks autonomously by machines with as little human intervention as possible. Closed-loop research automation represents a highly autonomous attempt at automating research, yet even in such cases, it is said that full automation of all processes of science has yet to be realized \cite{zenil2023,coley2020autonomous,coley2020autonomousII}. 

One of the biggest issues is to let machines autonomously generate even the objectives, problems, and questions of research by themselves \cite{coley2020autonomousII}. This is because, as repeatedly stated, if machines autonomously generate goals and questions, they must also autonomously generate and validate appropriate hypotheses in response. Therefore, machines must be able to execute hypothesis generation and validation in a versatile manner that can adapt to various scenarios.

In such situations, humans cannot provide specific methods for hypothesis generation, potential hypotheses, or the necessary information in advance. Therefore, machines must be able to extract appropriate information from an open-ended environment, similar to the one humans operate in, to perform hypothesis generation and validation. Research can be understood as a process of searching for information from the outer world of scientific information and processing it in the agent's inner cognitive world, as described in \cite{hope2022computational}. Assuming an open-ended environment equates to minimizing human constraints on the scope of this outer world, and allowing the agent itself to decide as much as possible what to extract from that outer world.

Considering these autonomy-related issues, how much autonomy should be expected of machines, and to what extent constraints can be set without overly suppressing the machine's potential capabilities for autonomous hypothesis generation and validation, remains an open question.

% One of the biggest issues is to let machine generate even the objectives, problems, and questions of research by themselves \cite{coley2020autonomousII}. なぜなら、繰り返し述べてきたように、目的や問いまでも機械に自律的に生成させる場合、それに対応して機械は自律的に適切な仮説を生成したり検証したりしなければならないからです。したがって、機械はさまざまな場合に対応できる汎用的な方法で仮説生成や検証を実行なければなりません。

% このような状況では人間が事前に具体的な仮説生成の方法や仮説の候補や必要な情報を与えることができません。したがって、機械は人間が置かれているのと同じようなオープンエンドな環境から適切に情報を引き出して仮説生成や検証を実行しなければなりません。研究は outer world
% of scientific information から情報検索をしてエージェントの inner cognitive world でこれらを処理する過程だと理解できますが \cite{hope2022computational}、この outer world の範囲を可能な限り人間が制約せず、その outer world から何を取得するかは可能な限りエージェント自身に決定させるような状況です。

% このような自律性の問題を鑑みて、機械にどの程度の自律性を求めるのか、どの程度の制約であれば機械の潜在能力を過剰に抑えつけることなく自律的な仮説生成や検証を行わせられるのかは、オープンクエスチョンです。

\subsubsection{Scientific Understanding}
So far, I have mainly discussed scientific discovery, but I have barely touched upon another important goal in science: scientific understanding. Since scientific discoveries can be made without understanding \cite{krenn2022scientific}, bringing new scientific understanding to humans requires additional demands beyond what has been discussed so far.

In humans, scientific understanding involves grasping theories, or hypotheses in this paper – what they are and why they hold. Therefore, among the elements of research I discussed, the additional demand seems to be necessary for hypothesis generation. Whether this demand concerns the representation of the generated hypotheses or the description of the process of generating them is unclear, but what additional requirements are needed in this process to bring about scientific understanding and how to realize them is an important issue.

Krenn et al. propose two conditions for us to say that an AI gains scientific understanding: 1. it can recognize qualitatively characteristic consequences of a theory without performing exact computations and use them in a new context, and 2. it can transfer its understanding to a human expert. As previously mentioned, the belief systems of humans and AI may differ, so whether AI having scientific understanding is necessary for bringing new scientific understanding to humans is unclear, but it is expected to be more helpful if it does. In any case, for bringing scientific understanding to humans, it seems necessary to have the ability to transfer understanding to a human in some way, as suggested as the second condition above. The explanation of machine prediction results has already been extensively researched and discussed as explainable AI \cite{arrieta2020explainable}, and its importance has already been widely pointed out in AI for Science research, so I will not delve further into it here.\footnote{
This might sound like a far-fetched conceptual idea, but to bring about human scientific understanding through machine-driven scientific discoveries, it might be worth considering not only improving the machine's capabilities but also expanding the range of human comprehension. I stop this discussion since it might lean towards not solidly grounded conjecture, but I believe it's worth discussion in scientific community.
}


% 私はここまで主に科学的発見について話してきましたが、科学におけるもう一つの重要な目的である科学的理解についてはほとんど触れてきませんでした。科学的発見は理解なしに行いうるので \cite{krenn2022scientific}、人間に新たな科学的理解をもたらすためには、これまで議論したものに加えて追加の要請が必要です。

% 人間において科学的理解とは理論すなわちこの論文で述べてきたところの仮説がどのようなものであるかなぜそれが成り立つのかなどについての理解です。したがって、この論文における仮説生成のところに追加の要請が必要となるであると考えられます。それが生成された仮説の表現に関する要請なのか、仮説の生成過程の記述に関する要請なのかは分かりませんが、科学的理解をもたらすためにこの過程にどのような追加の要請が必要でどのようにそれを実現すべきかは重要な課題でしょう。

% Krenn らはある AI が科学的理解を持つための条件として 1. if
% it can recognize qualitatively characteristic
% consequences of a theory without performing
% exact computations and use them in a new
% context and 2. it can transfer its understanding to a human
% expert. という２つの条件をあげています。前述したように、人間と AI の信念体系は異なり得ますので、AI が科学的理解を持つことが、人間に新しい科学的理解をもたらす上で必要かは分かりませんが、それがあればより役立つであろうことは期待されます。いずれにしても人間に科学的理解をもたらすためには、Krenn らがあげている人間に何らかの方法で理解を転移させることができることは必要であるように思われます。機械の予測結果の説明は説明可能AIとしてすでに多くの研究と議論がなされており \cite{arrieta2020explainable}、AI for Science の研究ですでにその重要性は広く指摘されていますので、ここではこれ以上深入りしません。

\subsubsection{Alignment}
Similarly to other AI research, alignment is an important topic in creating autonomous AI researchers as well. First and foremost, it is necessary to ensure that autonomous researchers do not harm humans. The more autonomy is sought in machines, the more important this issue becomes. Particularly, since knowledge itself is value-neutral and can be used for good or ill, as mentioned earlier, this solving this issue challenging. This problem requires ongoing discussion.

Furthermore, as I have repeatedly stated, aligning AI with human values and worldviews is important not only for safety reasons. For example, as mentioned in Section \ref{section-question-construction}, in order to produce knowle2dge meaningful to humans, agents also need to make value judgments aligned with human judgments about the quality of questions. Similarly, agents must judge what is unknown and what is comprehensible not from their perspective but from the human perspective. Especially, these value judgments are not always explicitly expressed in existing human-generated texts, and in that sense, there is a need to actively teach these value judgments. How this will be realized is a topic that should be discussed more in the future.

% 他の人工知能の研究と同様、alignment は自律的な人工研究者を作る上でも重要な話題です。まず何より、自律的な研究者の実現が人間にとって害を与えないようにしなければなりません。機械により自律性を求めるほどこの問題は重要になりますし、知識それ自体は前述したように価値中立であり悪用することも良く使われることもできますので、この問題については今後も議論が必要です。

% そして、繰り返し述べてきたように、安全のためという以外でも AI と人間の価値観や世界観を揃えることは重要です。例えば、セクション \ref{section-question-construction} で述べたように、人間にとって意味のある知識を産出させるためには、人間の問いの良さに対する価値判断にそろった価値判断をエージェントもする必要があります。同様に、エージェントは自分にとって何が未知かではなく、人間にとって何が未知かを判断しなければなりません。そして、直前のセクションで述べたように、人間にとっての理解をもたらすためには、エージェントは人間の視点に立って人間にとって何が理解可能であるかを判断しなければなりません。特に、これらの価値判断は必ずしも人間が生み出した既存のテキストに陽に表現されているものばかりではなく、その意味で積極的にこれらの価値判断を教える必要があるでしょう。これをいかにして実現していくかは今後より議論されていくことが望まれます。

% As discussed in Section 2, when realizing an AI that autonomously conducts research, the issue of alignment arises. 

% First and foremost, it is essential to consider ways to ensure that AI does not engage in research that could harm humans. However, this is a challenging issue. The problem of ensuring that AI does not harm humans is a difficult problem in AI Alignment. Furthermore, knowledge and technology produced by research are fundamentally value-neutral. That is, the knowledge can be used for good or ill. Therefore, even if AI were to research with harmful intentions, it would be challenging to judge from the actual research results.

% The remaining two issues arise in the ultra-long term when AI becomes fully autonomous in conducting research. The second issue is that to enable meaningful knowledge production for humans, there needs to be an alignment between the knowledge systems of AI and humans. As mentioned in Chapter 2, if knowledge and verification are relative concepts to society, research conducted autonomously by AI may become meaningless to humans. On the other hand, if we were to correct AI to follow human methods entirely, we might unnecessarily limit the machine's potential capabilities. Deciding how much human methodology and values to incorporate and how much freedom to allow the machine, and finding ways to achieve this, will be a significant challenge in creating research-capable AI.

% The third issue concerns the alignment between AI and nature, not between humans and AI. As mentioned in Chapter 2, the fact that humans have come to understand nature is likely not unrelated to our long history of interacting with nature. It seems there's no guarantee that artificial machines like AI, which lack such experiences, would lead to an understanding of nature through their autonomously generated knowledge.

% The latter two issues are problems that only arise when demanding extreme autonomy from machines and are not immediately problematic. However, when discussing the limitations and possibilities of knowledge production and natural understanding by agents independent of humans, they seem to become relevant issues.



% \subsubsection{Open-Endedness}
% One of the major challenges that can be a common issue for any process, as pointed out in prior research as well  \cite{coley2020autonomousII}, is how to execute these tasks in open-ended situations. For instance, in the automation of experiments, robots use experimental equipment selected, prepared, and set up by humans. However, humans do these tasks from scratch with their own hands. Humans do not use a given corpus of papers; instead, they search for and use them on their own. Candidates for hypotheses are not explicitly provided; humans begin by identifying potential hypotheses. Even when formulating questions that serve a particular goal, humans set that goal themselves. 

% In many cases in research automation, these elements are pre-determined by humans. How to let machines autonomously perform these tasks starting only with the same initial information given to humans is crucial in realizing an autonomous artificial researcher. Moreover, having this kind of freedom is essential to achieving a general artificial researcher as well. This is because if we impose constraints on AI to research only within specific research questions or hypothesis spaces defined by humans, it cannot become an AI capable of conducting arbitrary research. Therefore, a significant challenge is how to make AI acquire complex foundational skills and fundamental reasoning abilities to realize these capacities.

% \subsubsection{Generality}
% 汎用性がなぜいるかなどの説明？上の定義はそもそもそういうモチベーションから始まってるので、ここでわざわざ書かなくても良い。

% 特定の研究課題に特化すれば、問いの構築、仮説の生成、仮説の検証を実行できるような機械はすでに開発されています。これまでのセクションでこれらの概念の定義を改めて検討したのは、研究ができる AI とは特定の研究課題に特化した方法でこれらを実行するのではなく、どのような研究対象に対してもこれらを自律的に遂行できる AI であることが望まれるからです。このような汎用的な研究ができる AI をどのように実現するかというのが課題です？

% As we have introduced so far, there are several attempts to automate research through versatile approaches. For example, the automatic generation and discovery of hypotheses \cite{kang2022augmenting,chan2018solvent,wang2023learning,xu2023exploring} or questions \cite{lahat2023evaluating,liu2023creative,oppenlaender2023mapping,surita2020can} from research papers is an approach that can automate research across a wide range of academic fields, from the humanities to natural sciences. Additionally, efforts to create general-purpose robots  \cite{yachie2017robotic}, foundation or generalist models \cite{singhal2023towards,taylor2022galactica}, or to incorporate the inductive bias for understanding physics can be considered initiatives towards general-purpose system.

% However, most automation studies target specific challenges in particular research fields. It seems that the goal of creating an AI capable of conducting any research is not receiving much attention. As explained in Chapter 2, in order to create such intelligence, it would be necessary to understand the high level concept of research, question construction, hypothesis formulation, and hypothesis verification, and to be able to execute them appropriately depending on the subject at hand.

% \subsubsection{Autonomy}
% As mentioned in the previous section, there are several attempts to automate the entire research process. A seminal early works are Adam \cite{king2004functional}, and Eve \cite{williams2015cheaper}. These are closed-loop scientific discovery systems that autonomously execute everything from hypothesis generation to research planning, based on logic AI and robotics. Furthermore, there is closed-loop automation in some research on automation using scientific workflows \cite{gil2017towards}. These are highly autonomous research automation. Recently, there has also been a movement to create autonomous agents based on language models to tackle scientific problems \cite{wang2023survey}.

% However, most of studies on research automation have targeted  only specific tasks within a sub-process of the entire research process. For example, symbolic regression focuses on automating hypothesis generation, while experiment automation pertains to data generation for hypothesis creation and testing.

% Furthermore, even in the case of closed-loop research automation,  full automation of all processes of science is yet to be realized \cite{zenil2023,coley2020autonomous,coley2020autonomousII}. One of the biggest issues is that the objectives, problems, and questions of research are given by humans \cite{coley2020autonomousII}. We discussed in Chapter 3 that there are not many studies that have attempted to automate the construction of questions. And while we pointed out in Chapter 2 that automating the construction of questions can lead to an infinite regress from the perspective of autonomy, specifying the high-level goals underlying the questions remains a significant challenge \cite{coley2020autonomousII}. Also, even after the construction of the question, there is the issue that humans are providing machines with a search space that is far more restricted than what humans themselves are given. For example, generating hypotheses from an open-ended hypothesis space has not yet been realized \cite{zenil2023,coley2020autonomousII}, and to put it in extreme terms, while humans might prepare experimental equipment from scratch, machines are given those as a given. 

% To begin with, the realization of a fully autonomous artificial intelligence is still one of the major goals yet to be achieved, not just in research. Therefore, a lot more foundational research will likely be needed to accomplish this.

% Many automation studies primarily target specific tasks within a research process. For example, symbolic regression focuses on automating hypothesis generation, while experiment automation pertains to data generation for hypothesis creation and testing. However, as mentioned earlier, some studies, such as automated research workflows and self-driving labs, aim to automate the entire research process. 

% Coley et al. discuss the advancements in automating scientific discoveries in chemistry \cite{coley2020autonomous}. Their discussion is not limited to automating chemistry but extends to the broader context of automation of science. The paper delves into the insightful topics of automated discovery, including defining scientific discoveries and criteria for assessing their autonomy. In the subsequent paper, Coley et al. organized the existing automation studies based on which processes of scientific workflow are automated \cite{coley2020autonomousII}. In that paper, they point out several challenges for science automation, ranging from dataset handling to physical and computational autonomous validation. 

% Autonomous agent for scientific problem \cite{wang2023survey}

% , and in recent years, there are attempts to automate the entire process using language models.

% \subsubsection{Generality}


% \subsubsection{Scientific Workflow}
% The workflow whose process is a research process, tasks are research tasks that receive and output scientific data is called \textit{scientific workflow} \cite{ludascher2009scientific}. By running scientific workflow systems, research process is automatically executed.  Amidst the flourishing of computational and data-driven sciences with the advancement of computers, these efforts seem to have been conceived to better manage in silico experiments \cite{liew2016scientific}. 

% Among such initiatives, just like in the case of laboratory automation, there are efforts that have achieved closed-loop automation, which completely autonomously carries out the cycle of hypothesis generation and verification \cite{gil2017towards}. Gil has presented how machine learning can be incorporated into this scientific workflow \cite{gil2022will}. She also presents a perspective on what kind of AI should be developed in order for it to become a good partner for researchers.

% Additionally, there are attempts to design workflows that are reusable beyond individual workflows, in other words, workflows with high generality \cite{hardisty2020canonical}.

% どのような研究対象に対しても問いを立て、仮説を生成し、仮説を検証できるような人工知能を作るためには、これらを汎用的な方法で実行する必要があります。このように

% \subsection{Challenges}

 % \subsection{General and Autonomous Question Construction, Hypothesis Generation, and Hypothesis Verification}

 % In Chapter 2, we explained that in order to create an AI capable of conducting any research, it is deemed necessary to realize the formulation of questions, generation of hypotheses, and validation of these hypotheses as a combination of universal skills applicable to all research. In this section, we will revisit and organize the potential challenges in achieving an AI that can conduct each of these processes.


% \subsubsection{The Difficulty of General Hypothesis Verification}
% I recognize that the the way to verify a hypothesis is strikingly diverse, as it can significantly differ depending on the subject of research. For instance, if one wishes to study the behavior of rat, they may need to train the rat. On the other hand, if you want to test a theory of particle physics, you may have to construct and run a huge particle accelerator. In the field of history, the existence of historical records might serve as evidence, while in mathematics, the verification process revolves around the proofs themselves. Due to this high degree of flexibility, hypothesis verification can be the most challenging aspect to automate for realizing a ``general'' artificial researcher.

% \subsubsection{Feedback from Verification}
% In the first place, the act of verification is a highly challenging process. Firstly, as mentioned earlier, inductive approaches cannot verify hypotheses in the same way as deductive reasoning. Also, I notice that hypothetico-deductive method, which involves verifying claims derived from a hypothesis to confirm its validity, is still widely used today. However, verifying a deduced claim does not support the hypothesis because there may be many hypothesis that can result in the same deduced claim. In response to these, Karl Popper proposed that while hypotheses cannot be confirmed, they can be falsified \cite{sep-scientific-method}. However, in practice, the verification of hypotheses involves implicitly relying on numerous auxiliary hypotheses. When using experimental apparatus, it requires many assumptions to trust them. Even when an experiment fails, determining whether the hypothesis was incorrect or the experiment itself was flawed is not as straightforward as one might think. Thus, there is inherent uncertainty in attributing the results of verification to a specific cause \cite{chalmers2013thing,sep-physics-experiment,sep-scientific-underdetermination} as I have discussed in the section of hypothesis generation. Furthermore, all reasoning and observational evidence are inevitably influenced by some form of theories, individuals, or societal factors \cite{sep-science-theory-observation}. Therefore, it is necessary to carefully examine them to ensure that they are not distorted by unintended influences.


% \subsubsection{Question Construction}



% Realizing AI that construct a ``good'' question in a generic way is challenging. As discussed in Section \ref{section:the-relativity-of-knowledge-production-to-society}, research is relative to society and different criteria can be considered for what makes a ``good'' question. Thus, some human perspective on the ``goodness'' of a question must be incorporated. We need to discuss what we consider good, what we should prioritize, and how to incorporate the value to AI.

% \textcolor{red}{TODO}

% Moreover, determining inputs to the question construction module is not trivial. In hypothesis generation, the question is the primary input, whereas in verification, it's the hypothesis. However, question formation take any input. Once you seriously try to identify the origin of question, you will encounter infinite regress. This is a unique problem that arises when aiming for a general-purpose and autonomous artificial researcher. This is because the issue revolves around how much input can be assumed while still being considered autonomous, given that it can potentially take any input.

% \cite{wang2023skillqg}

% neural question generation \cite{pan2019recent}


% \subsubsection{Hypothesis Generation}



% \subsubsection{Hypothesis Verification}



% Creating AI that autonomously verifies hypotheses is challenging. While current models can mimic human verification, truly understanding the verification strategy demands more work. Sometimes, they even need to devise the verification measure themselves.

% The biggest challenge for autonomous verification is the need to freely move around in the real world or within a computer, and to manipulate objects within that world at will. We believe this to be one of the greatest barriers to full research automation. Laboratory automation have attempted to address this challenge in real world by developing robots. We will discuss the case within the computer in Section \ref{section:behaviour-inside-the-computer}.

% \subsubsection{AI Capable of Peer Review}

% Given the difficulty of these challenges, automating peer review could be a strategic starting point. This is because peer review is a universal process across diverse research fields and it assesses the validity and quality of problems, hypotheses, and verification methods, which is easier than generating them. Despite some progress, full automation is still elusive \cite{yuan2022can,schulz2022future}.


% \subsection{Behaviour inside the Computer}
% \label{section:behaviour-inside-the-computer}


% Lab Notebook?
% \subsection{Dataset of Research Process}
% It is important to establish the necessary infrastructure for research automation. The two pillars of research automation are the development of basic models that incorporate academic knowledge and the construction of data sets. The development of an infrastructure model that incorporates scientific knowledge has already been proposed in many places and is actually under development, so I will not emphasize its necessity here again. Also, regarding data sets, the construction of data sets for the acquisition of scientific knowledge has been done in various places as well, so I will not emphasize that here either.

% Instead, we propose here to construct a research process dataset. A research process dataset is behavioral log data that incorporates all possible tasks throughout the entire process of the study, from start to finish. Ideally, individual tasks should be labeled as to whether they correspond to question construction, hypothesis generation, or hypothesis testing. We believe that building such a data set is important because, as explained in the Literacy section of Chapter 2, the current paper is not a data log of the entire research process. This makes it difficult to be data-driven and end-to-end learning how to do research itself. I believe that building a research process will help solve these problems and increase the likelihood of more flexible intelligent agents.

% However, building a dataset of the research process seems daunting. This is because researchers who do not currently keep research logs would have to go to the trouble of recording their research process.\footnote{
% In an experimental laboratory in the natural sciences, it is common to take research notes, so it may not be that difficult to record more detailed processes as an extension of this practice. However, in the machine learning field, the culture of taking research notes does not seem to be that common. (We think it is common to keep logs of experiments, but it seems to be rare to describe the details, for example, where and how the data was obtained.) 
% } Therefore, it seems necessary to devise a way to make it easier for researchers to keep logs. It may be to manage the research process on GitHub, or to take research notes as in natural science research, but it is important to discuss how to achieve these things.

% Being able to construct a dataset of the research process would be ideal, but may not be immediately feasible. As an alternative, it seems important to create a dataset designed to automate question construction, hypothesis generation, and hypothesis testing. At its simplest, one might start by building a dataset of papers labeled with the parts that correspond to the question, hypothesis, and test, respectively. This would be a relatively simple but important step in achieving a generic artificial researcher.

% Alternatively, instruction tuning could be done by viewing question construction, hypothesis generation, and hypothesis testing as tasks, respectively. This would produce a language model that can execute question construction, hypothesis generation, and hypothesis testing with greater fidelity. This could be the foundation for a general-purpose, autonomous artificial researcher.





% In the medium to long term, it's essential to devise ways to ensure that AI doesn't engage in research that could be dangerous to humans. 

% In the long term, we must contemplate how to construct a knowledge system that are mutually translatable between human society and AI society. While these issues may not arise in the short term, it's crucial to engage in discussions now, looking towards the long-term future.

% \subsubsection{Understanding}

% Extensive discourse transpires concerning scientific discoveries. Yet, discussions pertaining to scientific comprehension remain relatively unexplored. Krenn et al. delve into the conundrum of what it entails for a machine learning agent to not only unearth scientific knowledge but also to comprehend it \cite{krenn2022scientific}. They adopt a human-centric stance, positing that an agent's ability to offer explanations comprehensible to human scientists signifies the existence of its scientific understanding.

% sun-rise \cite{leslie2023does}

\section{Ideas for Prototyping}
Realizing an intelligent agent that can conduct research is an exceptionally challenging goal that will likely take a long time to achieve. The challenges discussed so far are just the tip of the iceberg found in speculative discussions, and there are undoubtedly many more yet to be identified critical issues. Therefore, it seems crucial to start by identifying and addressing unknown challenges in the first place. A good starting point might be to develop a simplified prototype of an agent capable of research so that we can explore the challenges for our goal in the process of prototyping. In this section, I would like to discuss speculatively and briefly what could be considered as such prototyping.

\subsection{Prototyping Agents that Conduct Research}
% まず初めに、研究をするエージェントのプロトタイプとしてどのようなものが考えられるか検討するところから始めましょう。
% Let me start by considering what might be a prototype of an agent for conducting research.

\subsubsection{Requirements for Prototype}
As discussed in Section \ref{section-question-hypothesis-verification}, research, I believe, consists of constructing questions, generating hypotheses, and verifying these hypotheses. Thus, it seems appropriate for this prototype to consist of these functions as modules. The question construction module takes any input and produces a question. The hypothesis generation module takes this question as input and produces a hypothesis. The hypothesis verification module takes the hypothesis as input and provides verification results. The prototype would conduct research by flexibly combining these modules at various levels.

For the prototype agent to be autonomous, human design, implementation, and intervention should be minimized. Consequently, each module, aside from receiving minimal inputs, should autonomously gather information from the open-ended world, which humans interact with to get information for research. That is, the agent should interact with the physical world or the digital realm to get information necessary for research, as humans do.

% For instance, aside from the question input from the question construction module, the hypothesis generation module shouldn't have predetermined inputs.

Furthermore, for the system to be general, the internal workings of each module mustn't depend too much on specific research topics. For example, if the verification method is an experimentation for a specific physics research, it can't be used for psychological research. The human designed inner workings of each module should be as minimal as possible, limited to only what is necessary for the function of each module. 
% This is akin to an abstract class of research.

Creating a system that meets both autonomy and generality requirements while properly constructing questions, generating hypotheses, and verifying them only with this abstract class is infeasible, even in simpler scenarios. Hence, it might be necessary to impose some constraints on this abstract framework. Discussing the extent of these constraints, why they're needed, and how they can be eliminated will help elucidate the challenges in realizing a autonomous research agent. In the following, I will list up some candidates for potential constraints to provide a first step.

\subsubsection{Candidate Constraints in Prototyping}

In Section \ref{section-what-is-research}, I discussed the view that research can be considered as updating beliefs. I also discussed the possibility of autonomously constructing verification from its foundational concepts and autonomously contemplating the value of questions when conducting autonomous research. However, these ideas are too visionary and challenging to expect immediate, meaningful results for humans by prototyping. Therefore, it seems desirable as a prototype to aim for agents that can master the values system and verification methods humans have built so far.

% \subsubsection{Grand Goal is Given}
As said in Section \ref{section-question-construction}, constructing questions from open-ended situations is a too challenging task where even where to start from is not evident. Therefore, it seems prudent to start by determining in advance what the input for constructing the question should be, rather than assuming the unrestricted information sources. A candidate for the input is a high-level goal since it is 
assumed in many studies. Particularly, it would be desirable as a first step to provide high-level goals that are recognized as a research goal in a specific research field.

% As stated in Section \ref{section-question-construction}, not all research questions are necessarily constructed to achieve some grand goal. However, many studies build their questions by breaking down such goal. Therefore, if research can be conducted to construct questions from overarching goals, then a vast majority of human-conducted research, and notably ``meaningful'' research, potentially becomes feasible.

% \subsubsection{Research is Completed Entirely within a Computer}
One of the biggest bottlenecks in realizing a fully autonomous research agent is the necessity for excellence at complex low-level actions, as discussed in Section \ref{section-countless-seemingly-unrelated-operations-to-knowledge-production}. Especially, developing a robot capable of acting freely in the physical world like humans is an extremely challenging task. Therefore, for prototyping purposes, it seems reasonable to first consider research that does not require interaction with physical world but is confined within a computer. Of course, realizing an agent that can freely operate within a computer is also a very challenging issue, but it seems more feasible than an agent freely operating in the physical world. In fact, there have been attempts to make language models perform any operation on a computer \cite{openinterpreter,openai_chatgpt_plugins_code_interpreter_2023}, or operating a web browser \cite{nakano2021webgpt,act1}.

The purpose of prototyping is to materialize the concept, even if it's rudimentary, and identify challenges. Therefore, it seems desirable for prototyping to first limit the target environment to within a computer and wait for the advancement of foundational research for the realization of free activity in the physical world.

The examples mentioned here are merely a few ideas and are neither absolute nor comprehensive. Instead, it seems important in prototyping to discuss to what extent and what kind of constraints should be applied. It is expected that more appropriate constraints will become apparent as such discussions deepen in the future.

% \subsubsection{Verification is Limited to Humans'}
% The issue that allowing machines to conduct research entirely autonomously could result in constructing knowledge systems meaningless to humans arises when we try to let AI construct even verification from scratch. This is necessary if we want to truly say an AI can verify on its own. On the other hand, many people probably have no interest in generating knowledge that is meaningless to humanity. In the first place, even if such a thing were realized, humans might not be able to evaluate whether the AI has truly constructed a meaningful knowledge system for them. Also, I don't think human researchers always understand or construct verification from first principles. Therefore, it might seem harsh to demand these of AI. So, it seems preferable to first ensure that AI understands and can always use the verification methods that humans use. Specifically, we aim to make sure AI can always proficiently use experiments, statistical hypothesis testing, proofs, etc. By doing so, I believe there's a possibility to realize an AI that conducts highly generalized, autonomous research that is meaningful to humans.

% \textcolor{red}{参考}
% There are ongoing initiatives to enable language models to operate browsers \cite{nakano2021webgpt,act1}. While full browser operations might seem ambitious, there are already endeavors to allow language models to conduct searches \cite{mialon2023augmented}. If we achieve browser automation, it will greatly advance research automation involving web operations. Moreover, efforts like the open interpreter \cite{openinterpreter} aim to automate any computer action. This direction holds promise for automating all research confined within a computer. Although these studies are gaining traction in the machine learning domain, they're not always linked to research automation. We advocate recognizing this as a pivotal challenge in the realm of research automation.

\subsubsection{Implementing Each Module with Large Language Models}

Considering the necessity for generality and the remarkable performance of LLMs, it would be inevitable to instantiate each module as a LLM. In reality, as stated in previous sections, studies to construct automated research pipeline as LLM pipeline have emerged. I believe we should start from prototyping agents as such LLM pipelines. Particularly, I believe that we should create an autonomous research agent, in line with attempts to realize autonomous agents using language models \cite{wang2023survey,xi2023rise}.

Here is one provisional idea modeled after a typical autonomous agent. The research agent start from formulating a question given a high-level goal input by human. Once the question is posed, the agent then automatically generates hypotheses that could answer this question and subsequently verifies them. Once the final verification results are produced, they are interpreted in light of the original objective and research question, leading to the generation of the next question. However, as described below, the agent will iteratively and hierarchically repeat the processes of question construction, hypothesis generation, and hypothesis verification to execute each of these subprocesses.
% まず初めに、人間が目標を入力して、それを元に問いを立てるところから出発します。エージェントが問いを立てたら、次にエージェントは自動的にその問いの答えの候補となる仮説を生成し、最終的にこれを検証します。最終的な検証結果が出力されたらそれを当初の目的とリサーチクエスチョンに照らして解釈し、次の問いの生成などに向かいます。

The agent is assumed to perform essentially four actions: 1. formulating questions, 2. determining whether the task is completed, 3. verifying hypotheses, and 4. executing any low-level action on a computer. The processes of formulating questions, generating hypotheses, and verifying them are primarily realized by performing low-level actions on a computer.

If the agent chooses to generate a question, it temporarily suspends the current task, such as hypothesis verification, and always starts generating a hypothesis for that question. Once the generation of hypotheses for that question is deemed complete, the agent chooses whether to verify them or not, and after verification, it updates the hypotheses based on the results. Regardless of whether the hypotheses were verified, the agent then resumes the higher-level process that was previously interrupted, using the outcome of the low-level process. In this manner, the agent repeats the lower-level question construction, hypothesis generation, and verification until the highest-level hypothesis is generated. However, when the highest-level hypothesis, hypothesis to the original question, is generated, the agent always starts verifying that hypothesis.
% エージェントは大きく分けて、1. 問いを立てる、2. タスクが終了したかを判定する、3. コンピュータ上の任意のアクションを実行する、の基本的には3つの行動を取ると想定します。そして、この問いを立てる過程や仮説を生成するや検証をする過程は基本的にはコンピュータ上の任意のアクションを取ることで実現します。ただし、エージェントが問いを生成することを選択した場合、現在取り組んでいる仮説生成などのタスクを一時中断し、新しくその問いに対する仮説を生成することを開始します。その問いに対する仮説生成が終了したと判断されたら、それを検証するかしないかを選択し、検証を終えたら検証結果を受けて仮説を更新します。検証をしたにせよしなかったにせよ、これらによって生成された仮説の出力結果を受けて、先ほど中断していた上位の仮説生成の過程を再開します。このようにして、最上位の仮説が生成されるまで下位の問いの構築と仮説生成及び検証を繰り返します。ただし、最上位の仮説が生成された場合だけは、必ずその仮説の検証を開始します。

To ensure this system is general to be adaptable to many types of research questions, prompts given to these language models should consist only of general instructions. For instance, an instruction like ``generate a hypothesis for the following question'' is so general that it can be used for any research questions. Naturally, merely providing such instructions won't automatically yield research outcome from scratch, so there may be a need to provide additional as general as possible auxiliary instructions; one of the main purposes of prototyping is to explore them. 

For open-ended operations within a computer space, ideally, the LLMs should only be given access to nearly all operations on the computer. As mentioned above, efforts to develop language models capable of taking any action in such environments have already begun \cite{openai_chatgpt_plugins_code_interpreter_2023,openinterpreter}. Minimal access to web browsers, search engines, or shells might be acceptable, but provision of custom corpora or predefined hypothesis spaces should be avoided. If research can be autonomously conducted under such conditions, it would indeed signify that the system is capable of independent research.

% I worked with a research group attempting to automate research, and together, we created a simple mock-up expressing such a concept \textcolor{red}{CITATION}. We assumed a given question and examined how much GPT-4 could generate and validate hypotheses using only the most general prompts possible. While this initiative is still in its early stages and is limited to very basic problem settings, based on our findings here, I hope to eventually develop a system that more closely resembles human research capabilities.

% 言語モデルすごいし、言語モデルでやってくの考えたいよね。汎用的なのを言語モデルでやってみるならどんなになるだろう？→できるだけ汎用的な指示ということになるよね！みたいな。言語モデルが研究ができるというのはどう調べるか←汎用的な指示というのが一つのテストとして使う？

\subsubsection{Agents that Conduct Machine Learning Research}
To give a high-level goal, we should determine which research field's what type of objectives to provide. It seems desirable for this research field to to meet the aforementioned constraints and to be suitable for prototyping.

I believe that machine learning research is good for such prototyping. Firstly, some machine learning research can be fully completed on a computer, meeting the aforementioned constraints. Secondly, it has a shorter research cycle compared to other fields, allowing for faster feedback cycles. Thirdly, machine learning is essential for the realization of research-capable agent and also currently serves as a foundational technology in many research fields. Thus, automation of it will advance our original goal itself, while contributing the automation across many research fields at the same time. Finally, there already have been efforts for automation, such as AutoML \cite{hutter2019automated,bischl2023hyperparameter,lindauer2020best,white2023neural} and MLOps \cite{kreuzberger2023machine}. Especially in recent years, there have been attempts to perform these tasks using language models \cite{vijay2023prompt,zheng2023can}. These accumulated achievements will likely further assist in creating agents that can conduct machine learning research.

In summary, I believe it would be beneficial to start with the prototyping of autonomous agents consisting of language models given as generic instructions as possible, capable of conducting certain types of machine learning research. Such efforts have already begun, but I hope that more people will join in and further accelerate this movement.

% We believe that automating machine learning research may be suitable to start with in terms of these decision axes. First, let's discuss bootstrapping. Many of the challenges to automating research will be how to get machines to acquire from experience what they are currently hardcoding and doing in the real world. Learning from experience is exactly what machine learning does, and in this sense, many of the challenges in realizing autonomous artificial researchers can be formulated as machine learning research challenges.

% Next, let us discuss feasibility. In the first place, many machine learning studies are conducted entirely on computers. As mentioned earlier, the greatest difficulty in achieving general automation lies in the interaction with the real world. Technologies related to real-world interaction are used for hypothesis verification rather than the verification itself. This requires advancements in robotics research. Therefore, to pursue the automation of the entire research process, it may be best to set aside fields that require interaction with the real world and initially focus on automating research that can be done solely on PCs. 

% Also, many attempts to automate machine learning processes have already been made. For example, in MLOps, various pipelines for automating tasks such as experiment management and training in machine learning have been proposed and put into practical use. AutoML, which is a field of machine learning research, has also produced numerous innovations in automating many of the tasks involved in machine learning. Moreover, the culture of machine learning and related engineering fields already has a wealth of knowledge and insights regarding automation. This means that we do not have to devote many resources to automating research domain-specific tasks. This allows us to focus on more essential questions in our quest to become general-purpose artificial researchers, such as ``How do we allow people to test hypotheses?'' Furthermore, many studies in machine learning and related research areas are open-source. Consequently, it is considered easier to retrieve information from papers compared to other fields. 

% Finally, we would like to discuss the impact on other sectors. As you are already aware, many research fields are currently using machine learning technologies. The AI for Science initiative, which aims to automate the scientific field, also uses machine learning technology. Therefore, the automation of machine learning research and better knowledge production will accelerate all of these efforts. For these reasons, we believe it is a good approach to start by automating a specific research project in the machine learning domain.

% \subsubsection{What Type of Research in Machine Learning Should We Start with and How?}
% There are many different types of machine learning research, but where should we start with automation? Even though we aim to automate the construction of questions, what types of research should we guide them to do?

% It seems that a example of the research appropriate as one a starting point is that on the zero-shot prompt proposal. First, the hypothesis (or proposal) in this study is the specific text of the prompt. This is much less expensive to implement, whereas many empirical machine learning proposals require composing an algorithm or architecture. Validation requires the automation of the task of preparing existing data and models, and this is certainly a difficult task. However, this is an extremely common task in machine learning research and is not unique to this research project. The ability to automate this task would benefit a significant amount of machine learning research. The validation criterion is also generic, as it is a typical validation criterion that compares the proposed group with the control group. We think we will first build a prototype by adjusting the LLM prompts, and the fact that there is no strict mathematical or logical manipulation, which language models are not good at, is another aspect that makes this research easy to do.

% With this in mind, one research project in which the author of this paper is participating is in the process of building a prototype of the pipeline of research for the prompt proposal \footnote{
% Link to the pipeline: \href{https://github.com/t46/mock-pipeline}{https://github.com/t46/mock-pipeline}
% }. It is currently still in the pilot stage and some parts are hard-coded, but will be updated as needed.

% What we have described here is just one example and a suggestion. We hope that more similar initiatives will emerge in other studies.


% We propose to start by building a research pipeline, connecting the modules of the knowledge production system. The research pipeline is a software system that takes input and generates knowledge as output, encompassing the sequence of processes involved in research. Since this process does not require human intervention, it can be considered as an autonomous research system. We propose this system to be composed of the sub-processes of ``question construction,'' ``hypothesis generation,'' and ``hypothesis verification.'' This creates a general system that is potentially applicable to any research. These sub-processes can be likened to abstract classes in programming. Each process automatically formulates appropriate questions, generates hypotheses, and performs verification based on the input. 

% Initially, we will assume a specific research problem, and this research problem can be a simple one. And the inner workings of detailed hypothesis testing and hypothesis generation can be guided (but not hard-coded) to achieve the desired results. Anyway, the high-level concept is to create the minimum necessary to automatically execute each process of question construction, hypothesis generation, and hypothesis testing. Then, by gradually making the contents of each module autonomous and gradually loosening the restrictions on the research problem, we will lead to a general-purpose and autonomous artificial researcher.

% \subsubsection{Guided but Not Hard-Coded}

% It is important to note, however, that even in the prototype stage, the internal implementation of question construction, hypothesis generation, hypothesis testing, etc., should be ``guided'' and not ``hard-coded'' as much as possible. In machine learning, induction is the process of adding words to the prompt that make it easier to output the expected answer, and hardcoding is the process of actually inserting the desired processing into the algorithm. For example, if a statistical hypothesis test is expected to be used as a means of testing a hypothesis, rather than having a human write a program that contains a process for performing a statistical hypothesis test, we would instead instruct to the machine learning model with prompting, ``Statistical hypothesis testing is one of the leading methods in verification. The hypothesis is A. Verify this.'' This is a very important point to emphasize.

% This is a very important point, so let me emphasize it. The reason this is important is that we do not want to automate a particular hypothesis testing process, but rather we want the machine to test the hypothesis itself. Only when you make sure that the machine decides on its own the appropriate verification method according to the hypothesis, will you be able to provide collateral evidence that the machine itself is able to verify the hypothesis. If this can be done not only in hypothesis testing, but also in all aspects of question construction and hypothesis generation, we can call it a prototype of a general-purpose, autonomous artificial researcher.

% \subsubsection{Why Pipeline?}

% There are two reasons why we think it is a good idea to start by building such a research process pipeline. The first is that this is one simplified representation of a generic and autonomous research system. Research is a very complex task, so when we try to automate validation, we inevitably focus on automating individual tasks. In addition, many research automation efforts are aimed at making things better, which often leads to a strong dependence on the domain, for example, in automating hypothesis generation. However, as emphasized above, what we want to achieve is not specific hypothesis generation or verification, but the ability to generate and verify hypotheses themselves. This system emphasizes that point, and once realized, it will be an example of what a general-purpose, autonomous artificial researcher could look like. The creation of such an example will serve as a guidepost for more people to become versatile and autonomous artificial researchers.

% Second, building on this would further clarify the challenges in achieving a general-purpose and autonomous artificial researcher. In this paper, we have discussed the challenges that would be necessary to realize a general-purpose, autonomous artificial researcher. However, we believe that this is a very difficult task and that there are many areas where we do not even know what the problems really are. Therefore, it is important to first identify what the problems are in the first place and where the uncertainties lie. When we move toward such a complex problem, we start with a simple example to understand the structure of the problem. For example, we build toy models in physics, concrete examples in mathematics, and prototypes in programming. The research process pipeline falls under such simple examples in autonomous artificial researchers. In the process of trying to achieve this, we will discover what are the bottlenecks and what are the essentials. In this way, I think it is important to build a research process pipeline in order to first increase the resolution of the problem and clarify the issues.

% \subsubsection{Where to Start?}
% It is advisable to start by representing a specific research as a pipeline. Initially, creating a concrete system helps clarify the actions involved in actual research and makes the specific challenges to be addressed more tangible. When dealing with projects with high uncertainty, it is crucial to concretize the problems to be solved. Specifically, the goal is to programmatically represent the actions that researchers perform as comprehensively as possible. It is acceptable to consider certain aspects as constants if their execution is too challenging to represent as a program. Then, running the system should reproduce the original research. The next step is to progressively automate the processes and constants provided by humans to enhance autonomy. Naturally, automating a specific research pipeline alone does not guarantee the development of an autonomous pipeline. However, this approach allows for the identification of research automation challenges and paves the way for their resolution through research and development. Importantly, it is essential to express individual tasks as components or sub-processes of question construction, hypothesis generation, or hypothesis verification. This is similar to inheriting an abstract class, ensuring that the automation of these processes is achieved as individual tasks are automated.

% In practice, it becomes evident that fully automating an entire research is highly challenging. Therefore, before automating specific research, it may be advantageous to start by creating simplified toy models and aiming to build systems that can execute them automatically. For example, certain parts that require obtaining and using a real dataset can be replaced with appropriately created sample datasets. The approach is similar to that of specific research pipelines, addressing research challenges while aiming to increase autonomy and generality.

% \textcolor{red}{Remarks about Autores PJ}

% \subsection{Which Field of Research to Start with?}
% We suggested that we might start by automating specific research areas and research tasks. So what research areas should we start with? As it turns out, we think it might be a good idea to start by automating machine learning research. There is, of course, a bias due to the fact that the authors of this paper are machine learning researchers and that we are writing this paper primarily for machine learning researchers, but aiming to automate machine learning research makes a lot more sense than that. To illustrate this, let me first introduce some of the perspectives involved in decision making in the area of research to be automated.

% \subsubsection{How to Choose Research Area}
% The first perspective is how much automation of that research area will help achieve a versatile and autonomous artificial researcher. We believe that it would be a good idea to automate research areas that would accelerate the automation of research. For example, if there is a problem to be solved in order to generate a hypothesis, the problem itself could be set as a research problem and automation of this research could be realized. If we can automate such a task, we have not only achieved our goal of automating the entire research process, but we have also solved the problem of research automation. Such bootstrapping will accelerate the automation of the research process and allow it to reach its goals more efficiently. \footnote{
% Inspired by the feedback from Hiroshi Yamakawa
% }

% The second aspect is feasibility. Since the objective of this project is to create a prototype, it is an important policy to start with the least difficult to realize. There are various levels of difficulty, but the most important is whether the level of difficulty is high, especially in areas other than those essential to the automation of a general-purpose research process. For example, it would be more feasible to generate hypotheses from papers now that language models have been developed than to actually construct and conduct a experiment and generate hypotheses from the observations, in the sense that it would be fully automated. Also, if we were to start with automation using a language model, it would be better not to include tasks that the language model is not good at. As emphasized above, it is better to start where it is as easy as possible here, because focusing on automation of the parts that depend on individual research tasks is not important for the goal of acquiring generalizable knowledge to achieve a general-purpose artificial researcher.

% The third aspect is whether the field has an impact on many studies. First of all, an area that has an impact on many studies is one that is used as an elemental technology in those studies. This would be appropriate as a research area to automate for general-purpose artificial researchers, in the sense that it is a general-purpose technology. And if areas that affect many studies can be automated, it will also accelerate the knowledge production of those studies. The efficiency of knowledge production for humanity as a whole will increase, and research automation projects will also benefit from the knowledge produced by them. It would also increase the population of people involved, which may lead more people to pay attention to research automation. This will spawn new flows of people, money, and knowledge, and as a result, projects are expected to move forward more quickly.


\subsection{Prototyping Agents that Conduct Peer Review}
In order to identify challenges for realizing agents capable of conducting research, aiming to automate the peer review process of academic papers might also be a good initial step. There are several reasons why it may be suitable. I'd like to explain them in the following section.

\subsubsection{Why Agents that Conduct Peer Review?}

First and foremost, the elements necessary for peer review are closely related to those required by a research-capable agent. This is because peer review involves judging essential aspects of research, such as the soundness of the verification.

Secondly, automating the peer review may be relatively less challenging than realizing an agent capable of conducting research. The reason is that while peer review only requires judging whether the necessary elements for research are present, to realize a research-capable agent, it's not just about judgment but also about being able to compose those elements. It seems desirable to start by tackling simpler problems first as a prototype to highlight challenges.

% To create an AI that can research, one must generate studies from scratch. In contrast, automating peer reviews involves automating the evaluation of already completed research. Typically, it is expected that generative tasks are easier to automate than classification or judgment tasks. As previously mentioned, understanding the essence of research is necessary for automating peer reviews. Hence, the challenges that arise during this automation process are expected to be beneficial for creating an AI capable of conducting research.

Thirdly, peer review is a widely practiced convention regardless of the research field. Therefore, the insight found during peer review automation can be beneficial to realize a general research agent. 
% Third, peer review is a discipline-agnostic practice. Therefore, automating it is expected to be important in gaining insights to realize a general-purpose artificial researcher. 

% Fourthly, compared to the general automation of other processes such as constructing questions, there is already a substantial accumulation of prior research on the automation of peer reviews.

% Fourth, there is more prior research in automating peer review than in automating generic hypothesis testing or hypothesis generation. Therefore, it is an area where the hurdles for starting a new research project are relatively low. 

Fourthly, peer review is mostly completed through text manipulation alone. There is no need for interactions with the physical world or the computer realm that are necessary for autonomously conducting research. While searches to investigate prior research might be necessary, tasks like executing experiments are, at the very least, not required. Thanks to the advancement of LLMs, we are now capable of handling text at a significant level. Therefore, we can purely focus on challenges related to the evaluation of research. This is advantageous when identifying challenges to achieve our objective.

% Fifth, peer review is almost always completed by text manipulation. With the development of language models, the cost of doing this has come down considerably. 

Finally, peer review requires a judgment of value, such as the ``significance'' of a question. As mentioned above, alignment is one of the biggest challenges. To solve this problem, it matters to first understand how humans make value judgments in research. And peer review is a rare example where such values are explicitly assessed. In this sense, the automation of peer reviews could be a good start point.

% One major barrier to automating peer review is the perceived lack of sufficient data for peer review. First, in many research fields, peer review is done in a closed manner and there is no access to peer review data. This makes it difficult to automate peer review in a data-driven way in those fields. However, at least in the field of machine learning, there are many peer-reviewed comments that are open to the public, so this is not so much of a problem in the machine learning field.

% Second, the quality of peer review comments varies. Especially in the machine learning field, the number of reviewers is insufficient for the number of conference submissions. As a result, reviewers sometimes have to review papers in fields in which they do not specialize. This undermines our credibility as the gold standard for peer review comments and evaluations. But even if there were no such circumstances, peer review would still vary from person to person in the first place. This is because there is no clear-cut correct answer to the non-epistemic value judgment of what constitutes ``importance'' and the epistemic value judgment of what constitutes ``validity'' of verification. Currently, each researcher merely makes subjective decisions according to his or her own axis of judgment. In fact, it is known that machine learning research has shown that peer review results vary.
% \textcolor{red}{(citation needed)}

% However, this second point is a difficulty that occurs inherently in the process of peer review, and it is a difficulty that must be resolved in order to realize automation of research. Rather, the main issue is how to make machines acquire the value judgments that are currently tacit knowledge. Therefore, it would be useful to first analyze and discuss these value judgments, at least among humans, and then proceed to form some kind of consensus. \textcolor{red}{TODO:(move to challenge)}

\subsubsection{Peer Review Automation}

There is a bunch of studies that have tried to automate the peer review process. Researchers have tried to automate review generation \cite{yuan2022can,yuan2022kid,wang2020reviewrobot}, paper screening \cite{schulz2022future}, research paper assessment \cite{kousha2022artificial}, reviewer assignment \cite{zhao2022reviewer}, and more. As in other fields, recent years have seen research on the automation of peer review using large language models such as GPTs \cite{wexin2023can,liu2023reviewergpt,robertson2023gpt4,hosseini2023fighting}. For traditional research on the automation of peer review,  Kousha et al. \cite{kousha2022artificial} and \cite{lin2021automated1} Lin et al. have conducted comprehensive literature reviews. 

The existence of such efforts is important in the context of the aforementioned prototyping. It is desirable that further discussions deepen on how to realize AI capable of peer review, while referencing the insights gained from these attempts.

\section{Conclusion}
In this paper, I conducted a speculative examination of the concept of an intelligent agent that can conduct research. I began by discussing what it would mean to conduct research, implying that research could be seen as the act of updating beliefs in hypotheses. I then discussed the construction of questions, generation of hypotheses, and verification of hypotheses, which are seen as essential elements in research. After discussing the additional topics, I pointed out the importance of highlighting challenges in realizing such agents and shared some simple ideas for prototyping.

The discussions in this paper are all speculative. The definition of research discussed is provisional, the challenges and implications mentioned are just a fraction of the vast possibilities, and the prototyping ideas are akin to simple toys. Also, the literature cited is far from exhaustive, with many important works not covered. My capacity to adequately evaluate each reference might have been insufficient, leading to one-sided assessments or errors. The paper is planned to be updated in the future, and these shortcomings will be addressed in these updates. Any feedback or corrections are highly appreciated.

The reason for publishing this paper in its current, idea-stage form, despite its many insufficiencies, is to provide a starting point for thinking about the concept of a research-capable intelligent agent. I hope this paper will be of some help to researchers aiming to realize such agents and will contribute to more vibrant discussions in the future.

% この論文では、研究ができる知的エージェントという概念について思索的な検討を行いました。まずはじめに、研究をするということはどのようなことと言えそうかを議論しました。認識論の議論を手がかりに、研究とはある答えがわからない仮説が真であるという信念を更新する行為とみなすことができるのではないかという議論をしました。次に、研究において不可欠な要素であると思われる、問いの構築、仮説の生成、仮説の検証について議論しました。これらの特徴とそれを機械が実行することについての示唆について議論したのち、これらを組み合わせた場合やこれらに共通して言える課題やトピックについて話しました。最後に、このようなエージェントの実現を目指すために課題をあぶり出すことの重要性を指摘し、そのためのプロトタイピングの簡単なアイデアを共有しました。

% この論文で展開した議論はいずれも speculative な議論です。この論文で議論した研究の定義は暫定的なものであり、得られた課題や示唆も膨大に考えられるもののうちのほんの一部の側面のみであり、プロトタイピングのアイデアも簡単なおもちゃのようなものです。また、本論文で紹介した文献は私が触れられなかった重要な文献は山ほどあり到底網羅的ではありません。今回の論文が言及した範囲が広すぎるため各文献を適切に評価するには私の能力が不足しており、私の各文献に対する評価も一面的であったり誤りが含まれていたかもしれません。また、今回は触れられなかった重要な論点はいくつもあります。この論文は今後もアップデートをしていく予定で、これらの不足している点についてはアップデートしていきたいと思っています。もし何かお気づきの点がありましたら、ぜひご指摘いただけますと幸いです。

% このようにまだ多くの不十分な点を抱えたアイデア段階でこの論文を公開することにしたのは、研究ができる知的エージェントという概念について是非考えていく一つのきっかけを提供できればとの思いからです。研究ができる知的エージェントの実現を目指す研究者たちの少しでも助けになり、今後の議論がより一層盛り上がっていく一助となれば幸いです。

% In this paper, we explored what needs to be done to create intelligence capable of autonomously conducting any research. Firstly, we examined the definition of what constitutes research. We then proposed the idea that research might be the act of producing new knowledge for a society and that producing knowledge might be updating the collective beliefs of a society. As a result, we discussed that the core of research lies in formulating questions, generating hypotheses, and verifying those hypotheses. We also discussed the implications provided by the relativity of the research subject to society. Next, we briefly introduced examples of initiatives trying to automate research. While there has been significant progress, we explained that there are still barriers to realizing a general-purpose and autonomous artificial researcher. Lastly, based on these discussions, we debated the challenges we believe are crucial in realizing a general-purpose and autonomous artificial researcher. As a first step, we proposed building a prototype of an autonomous research pipeline driven solely by general instructions.